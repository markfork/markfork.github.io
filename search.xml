<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[《心法》- 读后感]]></title>
    <url>%2F2018%2F09%2F25%2F%E5%BF%83%E6%B3%95-%E8%AF%BB%E5%90%8E%E6%84%9F%2F</url>
    <content type="text"><![CDATA[2018年自己买了很多书，一来想在工作之余通过读书提升自己，二来害怕工作等同于生活，以致于无力感，空虚感常常侵袭心头。买书看书算是自我救赎的一种方式吧。今天要分享的是《心法》一书。 #作者简介 稲盛和夫，1932年1月21日－）是日本企业家，京瓷、第二电电（今KDDI）创办人，现为日本航空名誉会长（董事长）、公益财团法人稻盛财团理事长。 #关于自序 ##一个问题 作者的自序中抛出了一个当下社会出现的普遍问题：尽管人们在物质上的富裕生活已经实现(回顾当下，可以吃饱喝足)，但仍有很多人感觉不满，心怀不安，内心空虚。 ##一个答案作者给出了答案，产生这个问题的原因在于人们没有认真思考自己应有的生活方式和思维方式，忘记了“知足”，忘记了关爱他人，采取了利己主义的人生态度。 ##一个观点同时阐述了自己对于人生结果的观点：由于人生观的不同，思维方式的不同，因而人生的结果也大相径庭。秉持哪种思维方式度过人生属于个人自由，但由于思维方式的不同，人生也将迥然不同，换句话说，想要度过一个幸福美满的人生，就需要有与之相适应的思维方式。那么这种思维方式究竟是什么，本书给出了答案。 #关于章节 本书分为21个章节，对于我来说都是感兴趣的一些东西，每个章节都是作者都会阐述与人生观相关联的一些论点，每个论点中都有比较有意思的小故事，着实拓宽眼界。我比较喜欢与个人相关的论点，所以着重推荐以下几章1234567891011121.关于意识2.关于欲望3.关于人的本性4.关于自由5.关于人生的目的6.关于命运和因果报应的法则7.关于人生试炼8.关于烦恼和憎恶9.关于逆境10.关于情和理11.关于勤奋12.关于制作 今天讲讲意识 关于意识“精神医学”这一领域出现之后，“意识”这个概念才开始被医学界所认知，但是在这以前，关于“心”的研究，只限于心理学的范围，并没有进入医学的范畴。 ####一个现象-精神压力是导致胃溃疡的原因之一 胃壁是人的内脏器官中最强韧的部位，它能承受强烈胃酸的侵蚀，但人在焦虑的心理状态下常常会感觉到胃部隐隐作痛，检查之后，往往会发现是胃溃疡导致的疼痛感。为什么会这样呢。因为“担心，焦虑”这种意识，使得形成胃壁的细胞对胃酸的抵抗力变弱，在强烈的胃酸也就是盐酸的作用下，细胞遭到了破坏。就是说，意识可能破坏细胞本身，这个说法我觉得一点也不错。 ####一个现象-松下幸之助担心经营问题而尿血 被称为“经营之神”的松下幸之助先生曾因为担心经营上的问题，而导致尿血。所以不止是胃部，我们人身上的细胞多达几十亿个细胞，都会在我们意识的作用下，活跃起来或者衰弱下去，所以意识对于人的身体健康影响极大。 在提倡以科学的眼光，理性的分析，严谨的逻辑分析事物本质的时代，大肆宣言“意识”对人发展的积极态度似乎是及其不合理的。使得，我以前也是反对大军的一员。 但科学跟意识其实是密不可分的，试问，莱特兄弟为什么要造飞机，莫不是因为“希望人可以在天空中飞翔”的这个念头，才导致意识跃动，最后才发明了飞机，这么说来的话，科学开始的时候也是一种意识。 ####意识怎么来的 从大脑生理学的角度将，意识、意志、思维、都是由脑细胞产生出来的，作者认为除了脑细胞的产生，还包括与生俱来的意识和意志，那是人在刚刚出生时就已经具备的东西。 有个大家似乎都遇到过的事情，比如我们身边的小孩，在生长发育的过程中，有时会发生不可思议的事情， 在生物学上，随着孩子的生长和脑细胞的发达，孩子开始有了智慧，能够开口说话，但刚刚开始学会说话之急，他们突然会开口说出一些父母和周围的大人们从没有交过他们的话，“三岁左右的小孩，怎么会那么年少老成?”，父母很惊讶，这样的现象并不少见。 作者给出的见解是，小孩除了有脑细胞的发育而产生的意识以及有经过学习而获得的知识之外，还有小孩原本就有的东西，后者让小孩说出了让大人惊奇的话。 ####原本就有的东西 作者认为人类的根源中存在着宇宙的意志。在这种意志的作用下，会发生“轮回转生”。人们在过去时代经验过的意识会被承袭下来，这就是所谓的”原本就有的东西”。-说实在的，我刚开始也不怎么相信。 现世积累的经验、知识、作为意识被集成，寄宿于A和B这一对父母的精子与卵子结合而成的生命之中，这种意深藏不漏，不会轻易表现出来。但是，由于某种契机，它又会像间歇泉一样喷涌而出。小孩讲出没人教过的话，很可能就是因为这个原因。 作者阐述的这些有关于意识的现象，以及意识的形成，感觉很奇妙，看不见摸不着，但它确实存在，很奇怪吧。 ####何谓意识体 作者认为在宇宙原有的意志之上，加上过去世代造就的人格，再加上现世积累的经验，三者的综合，就可以称为意识体。“意识体”在肉体灭亡-一般称为“死”-的时候，从肉体中脱离出来。 脱离现世来说，意识不会消亡，而会被继承，这是一件很可怕的事情，假如当我们迎来死亡的时候，有人问我现世干了什么，我的回答是，20岁之前为到社会上打拼积累知识，20-60岁努力工作，原始积累，娶妻生子，买套房子，60-80拖着病态的身体在弥留世间。要知道这些东西在死后都是带不走的，你留给下世的意识体又是什么呢？ 所以在现世生存的同时，我们更应该提升自己的人格，提升人格，用作者的话来说就是提升心性。因此不管事业成功还是失败，不管患病还是健康，所有得以一切都是宇宙的造物主为了提高我们的心性赐予我们的修炼场所-佛教称之为修行的道场。我们在现世的一切体验，都是宇宙造物主为了塑造我们的人格，变着手法，给与我们的考验和锤炼而已。 ####共勉的话如果你是创业失败的人，或生活不如意的人，或者是已经小有成就的人，我觉的下面的这些话我们可以共勉！ 对于开始创业的人来说，最大的期待莫过于事业走上轨道，公司不断壮大。那么如果事业失败、公司倒闭，他就是人生的败者吗？我认为不是。失败乃是造物主为了提升他的心性而给予他的严酷考验，看他能不能再痛苦的深渊中再度崛起。 有的人经受不住这种考验被失败和痛苦压倒，精神崩溃，或自暴自弃，甚至靠偷盗他人的财务借以苟延残喘；有人甚至走向极端，以自杀告终。但也有人从正面接受失败的悲剧，更加努力，不懈奋斗，由此提升自己的人格。 不仅失败是考验，其实成功也是一种考验。造物主故意让你成功，借以测试你的人格。 成功了就得意忘形，傲慢不逊，这种人因成功而堕落，俗不可耐。另一种人却领悟到成功并不是只依靠自己个人的力量，因而更加努力，在这过程中继续提升自己的人格。 成功也好，失败也好，都是宇宙的造物主给予的考验，造物主正在注视着你，看你如何应对这些考验。不管成败，都能凭借造物主提供的考验机会塑造自己美好心灵的人，这才是真正的胜者。相反，经不住这种考验的人就是败者。 美国著名残障教育家海伦.凯勒背负着“失明、失聪、失语”三重苦难，一般说她如果埋怨父母，怨恨命运甚至怨恨上帝。与她会相同命运的人或许悲叹：“我不曾做过坏事，为什么单单让我遭遇不幸？”，他们诅咒周围的一切，以致含恨而终。但海伦.凯勒却毫无怨言，不仅如此，她还以无比顽强的毅力克服了难以想象的困难，她怀着大爱去帮助比自己更不幸的人，最终她塑造了伟大的人格。 作者还举例了残障作家乙武洋匡先生写的《五体不满足》的书，你会发现乙武先生的个性充满阳光。他的父母很了不起，而他本人的灵魂更是光芒四射。一切都向善的方向思考，顽强奋斗，绝不服输！ 释迦摩尼用“诸行无常”来描述人生。一切事物都是无偿的，千变万化的，新的考验会不断降临，因此，释迦摩尼说“人生即苦”。 ####写在后面 关于意识这一章节比传统心灵鸡汤更具说理性，哲学性，作者用通俗的语言，故事像我们讲述了，意识体、人生即苦、一切的磨难都是我们提升心性的修炼场。保持良好的心态应对万事无常的现世，通过意识，让我们身体的每个细胞跳跃起来，远离消极、远离拖延、远离自暴自弃、远离妄自菲薄、远离怨天尤人、“尽人事、待天命”，在现世好好修炼。 修炼场上希望与你相遇！]]></content>
      <categories>
        <category>随想</category>
      </categories>
      <tags>
        <tag>心法 读后感</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[社招回顾]]></title>
    <url>%2F2018%2F09%2F25%2F%E7%A4%BE%E6%8B%9B%E5%9B%9E%E9%A1%BE%2F</url>
    <content type="text"><![CDATA[章节 社招初衷 社招准备 社招感想 福利彩蛋 1.社招初衷1.1 自我检验1234不得不说，这两年个人属于蛰伏期，从大学创业失败，到潜心学习积累，这其中的孤独、无望只有自己能体会的到。这两年个人的积累主要包括Java并发编程、MySQL 学习、若干中间件相关的知识－包括Redis 缓存、Nginx接入层中间件。面试过程中Java 并发编程、MySQL相关方面的理论与实操帮助了我很多。是的，我面试的第一个目标就是检验自己积累的东西是否是业界所认可的。 1.2 检验-不打无准备之仗之真理12初入职场，我告诉自己，不要给自己设限，不设限的前提是要提前做好准备。所以我给自己定了两年计划，要像海绵一样充分吸水。 1.3 公司发展前景1我的前东家经营上遇到了些问题，我真心祝愿它能够再站立起来。 2.社招准备 种一棵树最好的时间是十年前，而后是现在。12我要感谢两年前的自己选择了前者，从一开始我就给自己定了目标，积累期就需要好好做事，好好学习，好好成长，抛弃之前所拥有的、失去的，自己是一个新人。 2.1 社招准备资料 现在将我社招准备的思维导图分享出来，主要是针对Java面试的，这其中涵盖了基础（操作系统、linux运维命令、网络协议 TCP、HTTP、HTTPS、常用算法）、语言 （Java集合、Java异常、Java语言特性-反射、注解）、设计模式、框架、中间件、项目的准备，我将这个思维导图也分享给了部门的小伙伴，说实在的我很乐意去做这件事，从这其中我可以帮助到别人，我可以体验到自己的价值所在。我觉得这也符合释迦摩尼所说的布施。总之就是正向反馈吧！ 社招准备链接地址:社招准备资料如果有问题或者好的建议，请跟我联系 微信 ltdo111。 2.2 心态调整 所有的事情都会有一个起因、发展、与结果。请参考我的读书笔记 心法。 3. 社招感想 其实简单总结下即，为期一个半月的面试，让我增长了社招面试经验，这其中遇到了好人、牛人、贵人。 3.1 好人篇 Y hai bin，是我初入部门的师父，在求职过程中，他也经常给我一些非常有用的建议，比如说 “嗨，小伙，自信点，这样评级会高”、“嗨，薪资方面一定要坚持” C xiao ying ，我们部门的助理，也是我的老乡，后来谈薪资的时候，她告诉我，“你要强势一点，这家不行，还有下家”，我觉得这个底气确实很棒，舍我其谁的感觉。 D hui 老哥，我们部门同事，一位和善的、经验丰富的师傅，找工作那段时间其实很焦虑，老哥给了我很多正向的鼓励，他问我这两年下来有什么想说的，我告诉他正向反馈很重要。一个能给予别人善意的、真诚的鼓励的人，我是非常尊敬的。 猎头 L duo duo ，duo duo 是我最近认识的猎头，我觉得她跟其他猎头不一样，不是功利的。即便是我没有接受她的职位邀请，她还是不遗余力的给予我帮助，给予我鼓励，了解我面试的过程、流程。当然为了表示诚意，我也将我认识的朋友推荐给了她。 阿里新制造 - M yu feng 老哥，是我的二面面试官，也就是未来的leader,面试的过程当中给我了很多建议：1231.当前你还存在知识盲区，如AOP 实现除了动态代理，还有静态编译2.权限设计要参考 RBAC3.并发编程 中 两个线程循环打印A B 50次，想起来容易，但是写起来有需要注意的细节 还有很多很多未写到的人，总之，谢谢你们给我善意的正向的帮助。 3.2 牛人篇 我社招第一个面试官是蚂蚁金服-L LIN ，这位老哥问的问题真的是风格轻奇，问我，“你觉得MySQL的主从复制 与 Redis的主从复制有什么区别”，懵。问我，“你觉得为什么JVM 新生代的回收要采用复制算法”，懵。大家可以想想第二个问题的原因。最后给我的建议是，低头走路，抬头看路，知其然而知其所以然，所以然的答案不是考察你对原理的背诵能力，而是真正理解，OK？ 3.3 贵人篇 第一位贵人是我老东家的间接领导，H ming long，初识之时，觉得他看起来很年轻，说实话有点担心。但我之后的工作，他会不遗余力的提供资源，提供建议，给予我正向鼓励，不仅懂管理、懂产品、懂技术、牛人哦，很感谢也很幸运能遇上这么好的领导。 第二位贵人是我新东家的leader，Z FU CHUN，腾讯9年扫地僧，我面试过程当中他会给我非常多的引导。最终的面试建议是，你的网络编程还需要加强、数据结构与算法方面还需要加强、最后比较重要的一点就是遇到自己不会的问题一定要发散思维，大胆去想，错了没关系。 最后的福利，leader也尽最大的努力帮我争取。 Leader 很牛，以下为佐证，他在腾讯公开课上有两门课程： 《听张富春讲多核编程》 https://ke.qq.com/course/192009 《跟腾讯架构大师学：网络框架与后台架构》 https://ke.qq.com/course/213315 感兴趣的同学可以去听一下。 福利彩蛋 职位:腾讯 OMG 广告后台高级开发工程师;Base:根据地深圳,其他地域均可。场景:海量数据，To B，To C，场景极具挑战性。基础要求:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;熟悉常用数据结构与算法;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;熟悉常用网络协议，熟悉网络编程;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;熟悉操作系统，有线上排查问题经验;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;熟悉MySQL,Oracle;熟悉c，JAVA，GoLang，c++其中一种语言均可;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可内推，欢迎各位优秀开发道友私信&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;期待关注我的开发小哥哥，小姐姐们私信我，机会很好，平台对标抖音，广告生态平台，类似Facebook 广告平台，希望你们用简历砸我哦~&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;联系方式 微信 ltdo111 本篇结语凡事皆有极困难之时，打得通的，便是好汉！愿道友们共勉！ 我是markfork，打造个人知识ip，请不要吝啬你的梦想！]]></content>
      <categories>
        <category>随想</category>
      </categories>
      <tags>
        <tag>社招 随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈敏捷开发]]></title>
    <url>%2F2018%2F09%2F10%2F%E6%B5%85%E8%B0%88%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[章节 什么是敏捷开发（What） 为什么使用敏捷开发 （Why） 如何使用敏捷开发 （How） 采用敏捷开发的产品开发效果 1.什么是敏捷开发（What） 1.1 敏捷开发是一种价值观与原则1敏捷开发是一种价值观与原则，指导我们更加高效的开发 1.2 敏捷开发以用户需求为核心12敏捷开发以用户需求为核心，采用迭代(时间周期)、增量(循序渐进，功能模块)的方式开发软件，目的在于快速覆盖、响应市场需求 1.3 大项目划分为小项目1大项目划分为小项目，分别完成，独立运行，如微服务的开发过程，就是将系统独立进行开发。 1.4 敏捷开发特征1.4.1 迭代式开发 （主体是时间周期）12项目按照时间周期进行迭代，比如A功能优先级比较高，则在第一个迭代周期内优先开发A功能，并上线。第二个迭代周期开发B功能。 1.4.2 增量交付 （主体是功能模块） 瀑布式开发模型：需求评审、概要设计、详细设计、开发、单元测试、集成测试、上线。如微软的Vista系统，从1997年立项到2005年才问世，但是用户反馈并不好，Vista操作系统的开发就是采用瀑布模型。 增量式开发:则代表产品是在每个周期结束时被逐步交付使用的。如微软在吸取Vista操作系统采用传统的瀑布式开发流程之后，发现操作系统并不能完全覆盖用户的需求。在2005-2007两年时间内 通过内部推行的敏捷开发原则，上线了win7，获得市场的一致好评。 1.4.3 开发团队和用户反馈推动产品开发12敏捷开发提倡用户参与到产品或项目开发的整个流程当中，通过用户反馈使得产品更加符合用户频繁变动的需求。 1.4.4 持续集成12采用敏捷开发的产品在产品初期会上线基本功能，之后的功能是根据收集到的用户反馈进行开发的，实现功能模块的持续集成。 1.4.5 开发团队自我管理123传统的开发模式，注重文档约束，而敏捷开发原则的推行原则要求团队内部交流便利、文化相对开发，除去必要的文档约束，如Api接口文档，最注重的是团队成员的高效交流，以此来提高产品、项目的开发效率、开发质量。 1.5 敏捷开发原则 1.5.1 快速迭代1小版本更新发布，更快覆盖当前 市场、用户 需求。 1.5.2 需求评审12345需求评审阶段，要求PM、所有相关开发人员参与到需求评审当中需求评审阶段：需求可行性分析、确定需求功能范围、PM对需求中存在异议的细节进行解释。 1.5.3 编写story、验收标准1PM 编写story、验收标准 1.5.4 多沟通1PM、开发人员之间需要多沟通、减少不必要的文档。 1.5.5 做好原型1需求评审完毕后，PM与UE UI 人员进行紧密沟通，完成指导开发人员开发的UE、UI 1.5.6 及早考虑测试1测试人员在这个阶段需要根据需求中划分的功能点，设计测试用例。 2.为什么使用敏捷开发（Why） 2.1 覆盖快速变化的市场、用户需求，快速响应变化需求12在用户需求不断变化的情况下能够保证软件开发质量，把大的时间点变成小的时间点。 2.2 把团队中职责定义清楚，发挥最大效率3.如何推行敏捷开发 (How)上图为本人所在部门采用的敏捷开发原则，功能迭代时间大致为两周一个版本。 4.采用敏捷开发的产品开发效果 敏捷开发大大提高了我们部门的开发效率，开发人员各自关注自己负责的功能模块，并且通过高效的沟通，在保证产品质量的前提下，实现了产品的快速迭代！产品名称 斐讯路由！]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
      <tags>
        <tag>敏捷开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring MVC 运行流程解析(含源码分析)]]></title>
    <url>%2F2018%2F06%2F26%2FSpring%20MVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[章节目录 Spring MVC DispatcherServlet 与 HttpServlet 关系类图 Spring MVC 源码分析Request 请求映射、执行、视图解析流程 总结-Spring MVC 运行流程图 1.Spring MVC DispatcherServlet 与 HttpServlet 关系类图1.1 什么是DispatcherServlet源码注释如下所示： Central dispatcher for HTTP request handlers/controllers, e.g. for web UI controllers or HTTP-based remote service exporters. Dispatches to registered handlers for processing a web request, providing convenient mapping and exception handling facilities. 译文如下： DispatcherServlet 是HTTP请求处理程序/控制器的中央调度程序（将请求映射到具体处理器(handler)上 ），例如用于Web UI控制器或基于HTTP的远程服务导出器（webService），调度器会将请求路由至已经注册好的具体的hadler,使得handler可以处理执行相关的web请求，提供了请求与处理器之间的映射关系功能，其实就是路由映射功能。 1.2 什么是HttpServlet HttpServlet 是处理相关基于Http请求的处理程序，请求的相关信息被封装成 HttpServletRequest对象，其中Service() 方法通过获取 HttpServletRequest 中的方法名 如 GET、 POST、PUT等 request-method信息的获取，去invoke具体的doGet()、doPost()、doPut()方法，最终将执行完业务逻辑获取到的处理数据通过HttpServletResponse对象返回给客户端。所以最终request请求结果还是从HttpServlet中的service()返回的 那么这两者之间有什么关系呢？如下图所示DispatcherServlet与HttpServlet之间的类图关系：其中最重要的是FrameworkServlet。源码注释如下： Base servlet for Spring’s web framework. Provides integration with a Spring application context, in a JavaBean-based overall solution. 译文如下: Spring web 框架中的基础Servlet，将Spring 相关的ApplicationContext 集成进来。方便我们在后期使用Spring IOC 容器中注册的各种属性的类对象。 FrameworkServlet 整合Spring WebApplicationContext 对象源码如下：12345678910111213141516171819202122232425262728293031323334 /** * Initialize and publish the WebApplicationContext for this servlet. * &lt;p&gt;Delegates to &#123;@link #createWebApplicationContext&#125; for actual creation * of the context. Can be overridden in subclasses. * @return the WebApplicationContext instance * @see #FrameworkServlet(WebApplicationContext) * @see #setContextClass * @see #setContextConfigLocation */ protected WebApplicationContext initWebApplicationContext() &#123; WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); WebApplicationContext wac = null; if (this.webApplicationContext != null) &#123; // A context instance was injected at construction time -&gt; use it wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac; if (!cwac.isActive()) &#123; // The context has not yet been refreshed -&gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &#123; // The context instance was injected without an explicit parent -&gt; set // the root application context (if any; may be null) as the parent cwac.setParent(rootContext); &#125; configureAndRefreshWebApplicationContext(cwac); &#125; &#125; &#125; ... return wac;&#125; 其中获取web应用程序上下文的代码段为：12WebApplicationContext rootContext =WebApplicationContextUtils.getWebApplicationContext(getServletContext()); FrameworkServlet 对 extends 自 HttpServlet 的service()方法进行了override() super.service()即调用HttpServlet中的Service()方法可以看到Service()方法根据request.method 去调用具体的doxxx()方法，这里FrameworkServlet 对 doxxx()方法也进行了override()。 如下为FrameworkServlet 中123![override doGet()](https://upload-images.jianshu.io/upload_images/2836699-bb9d2dc518de145a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)其中的`processRequest()`方法源码如下所示： /** * Process this request, publishing an event regardless of the outcome. * &lt;p&gt;The actual event handling is performed by the abstract * {@link #doService} template method. */ protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { long startTime = System.currentTimeMillis(); Throwable failureCause = null; LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext(); LocaleContext localeContext = buildLocaleContext(request); RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes(); ServletRequestAttributes requestAttributes = buildRequestAttributes(request, response, previousAttributes); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor()); initContextHolders(request, localeContext, requestAttributes); try { doService(request, response); } catch (ServletException ex) { failureCause = ex; throw ex; } catch (IOException ex) { failureCause = ex; throw ex; } catch (Throwable ex) { failureCause = ex; throw new NestedServletException(&quot;Request processing failed&quot;, ex); } finally { resetContextHolders(request, previousLocaleContext, previousAttributes); if (requestAttributes != null) { requestAttributes.requestCompleted(); } if (logger.isDebugEnabled()) { if (failureCause != null) { this.logger.debug(&quot;Could not complete request&quot;, failureCause); } else { if (asyncManager.isConcurrentHandlingStarted()) { logger.debug(&quot;Leaving response open for concurrent processing&quot;); } else { this.logger.debug(&quot;Successfully completed request&quot;); } } } publishRequestHandledEvent(request, response, startTime, failureCause); } } 12* 其中最重要的是doService()方法，这个doService()方法被声明为抽象方法，在DispatcherServlet 做具体实现。源码实现如下： protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception { if (logger.isDebugEnabled()) { String resumed = WebAsyncUtils.getAsyncManager(request).hasConcurrentResult() ? “ resumed” : “”; logger.debug(“DispatcherServlet with name ‘“ + getServletName() + “‘“ + resumed + “ processing “ + request.getMethod() + “ request for [“ + getRequestUri(request) + “]”); } // Keep a snapshot of the request attributes in case of an include, // to be able to restore the original attributes after the include. Map&lt;String, Object&gt; attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) { attributesSnapshot = new HashMap&lt;String, Object&gt;(); Enumeration&lt;?&gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) { String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(&quot;org.springframework.web.servlet&quot;)) { attributesSnapshot.put(attrName, request.getAttribute(attrName)); } } } //为请求设置具体的属性。 // Make framework objects available to handlers and view objects. request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) { request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); } request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); try { //调用doDispatch()，将请求分配给具体的handler去处理。实际上第二节会具体分析doDispatch()方法 doDispatch(request, response); } finally { if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) { // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) { restoreAttributesAfterInclude(request, attributesSnapshot); } } } } 1234**1.3 Spring Web 对Request的执行流程**所以请求的整个执行流程依据之前的HttpServlet知识积累(未debug)可以大致总结如下(第二节会debug源码，用来验证我们总结的这个流程)即： 1.请求到达dispatcherServlet，(非初次请求,初次请求会涉及dispatcherServlet初始化，调用init()方法)。2.dispatcherServlet 执行service()方法，因Dispatcher类继承FrameworkServlet，所以调用父类的service()方法。3.service()调用FrameworkServlet 中具体的doxxx()方法4.FrameworkServlet 具体的 doxxx()方法调用processRequest()方法。5.processRequest()方法调用dispatcherServlet 的 doService()方法。6.dispatcherServlet 的 doService()方法调用doDispatch()方法。12345678**注意**:上述根方法-service()方法被**servlet容器** Servlet container显示调用。#### 2.Spring MVC 源码分析Request 请求映射、执行、视图解析流程&gt;简单的helloword级别的web项目,搭建方式可以略过。主要是debug开始的地方我们需要确定，因为有HttpServlet源码分析的积累，那么我们直接在DispatcherServlet中的Service方法中打断点就可以了，因为DispatcherServlet继承了FrameworkServlet，FrameworkServlet对HttpServlet中的service()方法进行了override，所以程序入口断点应该打在FrameworkServlet 中的service() 方法，接下来就是实操演示：**注意：本源码分析的是Spring 4.1版本****2.0 debug的目的** 了解 request 到具体 handler 的执行流程。``` 2.1 FrameworkServlet 中 service() 打断点 2.2 开启debug模式 2.3 开始debug 执行父类service()方法 执行doGet()方法 执行processRequest()方法 执行doService()方法 执行doDispatch方法 获取请求对应的handler 继续debug hm.getHandler(request)看看这其中发生了什么？通过SimpleUrlHandlerMapping, 发现并不能获取到 对应的 handler(HandlerExcutionChain对象)，继续foreach通过EndpointHandlerMapping, 发现并不能获取到 对应的 handler(HandlerExcutionChain对象)，继续foreach 最终我们通过RequestMappingHandlerMapping对象获取到了对应的handler对象。可以看下handler对象是什么东东？所以handlerExcutionChain 对象 包含有handler对象、interceptor对象。 到此我们通过requestMappingHandlerMapping 获取到了请求对应的handler。 接下来需要以handler为参数获取真正处理请求的handlerAdaptor 接下来执行 handlerAdaptor 中 handler()方法返回mv，需要注意的是，返回mv 其实是对Controller 中业务方法的调用其实使用到了反射。 注意在返回mv之前 通过handlerExcutionChain对象可以调用applyPreHandler 方法，可以在返回mv之前做预先处理工作。 返回mv之后，可以通过handlerExcutionChain对象可以调用applyPreHandler 方法对返回的mv做修改。我们只需要实现 handlerInterceptor类并实现配置就可以了。 最后一步执行视图渲染的工作，这一步是在dispatcherServlet中完成的。 最终请求结果注意：由于返回结果为String 类型的value,不涉及视图解析，所以render 方法并没有执行。 3.总结-Spring MVC 运行流程图 对上述流程图的解释： 用户发起请求到前端控制器（Controller） 前端控制器没有处理业务逻辑的能力，需要找到具体的模型对象处理（Handler），到处理器映射器（HandlerMapping）中查找Handler对象（Model）。 HandlerMapping返回执行链，包含了2部分内容： ① Handler对象、② 拦截器数组 前端处理器通过处理器适配器包装后执行Handler对象。 处理业务逻辑。 Handler处理完业务逻辑，返回ModelAndView对象，其中view是视图名称，不是真正的视图对象。 将ModelAndView返回给前端控制器。 视图解析器（ViewResolver）返回真正的视图对象（View）。 (此时前端控制器中既有视图又有Model对象数据）前端控制器根据模型数据和视图对象，进行视图渲染。 返回渲染后的视图（html/json/xml）返回。 给用户产生响应。]]></content>
      <categories>
        <category>Servlet</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java WEB-Servlet]]></title>
    <url>%2F2018%2F06%2F14%2FJava%20WEB-Servlet%2F</url>
    <content type="text"><![CDATA[章节目录 什么是Servlet Servlet 、ServletContext、Servlet Container、web 容器之间的区别 Servlet、ServletConfig、GenericServlet、HttpServlet、自定义Servlet 之间的联系 HttpServlet 源码解析 Servlet 是否是线程安全的-线程非安全 1.什么是Servlet1.1 定义首先看Servlet接口源码中对于Servlet的定义 A servlet is a small Java program that runs within a Web server. Servlets receive and respond to requests from Web clients, usually across HTTP, theHyperText Transfer Protocol. 译文如下： Servlet 是运行在Web服务器上的小型Java程序，Servlet 接受并响应来自Web 客户端的请求，通常请求通过HTTP协议进行请求传输。 总结如下：1231.Java Servlet 运行在 Web 服务器（Web 容器）之上，即1个Web服务器上可部署运行多个Servlet。2.Servlet 的功能是－接收来自客户端发送的 HTTP 请求，并在接收 HTTP 请求之后做相关处理，处理完成之后将数据响应给客户端。 2. Servlet 、ServletContext、Servlet Container、web 容器之间的区别2.1 servlet1servlet 用来接收、处理请求，并返回数据。 2.2 ServletContext ServletContext （Servlet上下文对象）是web应用服务器启动之后创建的对象，且只在web应用服务器启动时创建一次，所有的Servlet 可以共享并修改在ServletContext设置的共享变量。 源码注释如下所示 Defines a set of methods that a servlet uses to communicate with its servlet container, for example, to get the MIME type of a file, dispatch requests, or write to a log file. 译文如下： ServletContext 中定义了让单独的Servlet与Servlet容器进行交互的一系列操作方法，如获取文件的 MIME type，如text/htm、image/gif，getRequestDispatcher操作(重定向操作)301-永久重定向 对应 forward()、302-临时重定向对应redirect()、或者写日志文件操作。 2.3.Servlet Contanier1Servlet 容器，可以在其之上搭载多个Servlet，类似于Servlet是子弹、Servlet 容器是枪。 2.4.web 容器 web 容器 即 web服务器，Servlet 容器搭载于Web 容器之上，请求过来之后，先到达至web服务器，web服务器将请求传递至Servlet容器，Servlet容器根据一定的匹配规则，如Servlet-Mapping 将 请求传递至对应的Servlet处理程序，这便是请求的部分传递过程。即 request-&gt;web container-&gt;servlet container-&gt;servlet。 3.Servlet、ServletConfig、GenericServlet、HttpServlet、自定义Servlet 之间的联系3.1 相关类图接下来，各个击破:3.2 Servlet 接口如下图所示Servlet 接口中声明的public 方法: Servlet 中定义了5个方法： init(ServletConfig):Servlet在容器启动时不进行实例化所以不调用init()方法，只有当第一个请求通过Servlet 中 Service()方法进行处理时才进行实例化，且只实例化一次，该方法被Servlet Container 调用。 getServletConfig():获取与当前Servlet 绑定的 ServletConfig 对象，ServletConfig 对象包含 web.xml 配置文件中配置的 ServletName、initParameter等信息。通过ServletConfig 对象可以获取到ServletContext对象，所以ServletConfig 对象是 不同 Servlet 之间共享Servlet 容器信息 的桥梁。 service():接受客户端请求对象、执行业务操作、利用响应对象响应客户端请求。 getServletInfo():返回Servlet相关信息，如Servlet 名称、作者、版本等信息。 destroy():当容器监测到一个Servlet 服务从容器中被移除，容器调用该方法、释放资源、该方法只能被调用一次。 3.3 Servlet 生命周期 初始化 阶段调用 init() 方法 响应客户端请求 阶段调用 service() 方法 终止 阶段调用destroy方法 3.4 Servlet、ServletConfig、GenericServlet、HttpServlet 顶层接口Servlet、ServletConfig、 GenericServlet 实现 implements 上述两个顶层接口、 ServletConfig 中声明 getServletContext方法、 Servlet 中声明 getServletConfig 方法、 HttpServlet extend GenericServlet； 所以在Servlet 中获取servletContext对象的方法有以下两种方式：方式一1ServletContext servletContext = getServletContext(); 方式二1ServletContext servletContext = getServletConfig().getServletContext()l; 4.HttpServlet 源码解析4.1 HttpServlet实例域HttpServlet 是继承自 GenericServlet 的抽象类实例域定义如下图所示： GET : 获取由请求 URL 标识的资源 POST : 向 Web 服务器发送无限制长度的数据 PUT : 存储一个资源到请求的 URL DELETE : 删除由 URL 标识的资源 HEAD : 返回 URL 标识的头信息 OPTIONS : 返回服务器支持的 HTTP 方法 TRACE : 返回 TRACE 请求附带的头字段 4.2 对应的服务方法 doGet():调用服务器的资源，并将其作为响应返回给客户端。doGet() 操作会将url 中显式传递的参数 传递给 Servlet，Servlet 通过 getRequestParam(paramName) 获取相关参数，这在系统的安全方面可能带来一些问题, 比如说, 用户登录时, 表单里的用户名和密码需要发送到服务器端, doGet() 调用会在浏览器的 URL 里显示用户名和密码. doPost() : 它用于把客户端的数据传给服务端, 使用它可以以隐藏方式给服务器端发送数据. Post 适合发送大量数据. doPut() : 调用和 doPost() 相似, 并且它允许客户端把真正的文件存放在服务器上, 而不仅仅是传送数据. doDelete() : 它允许客户端删除服务器端的文件或者 Web 页面．它的使用非常少． doHead() : 它用于处理客户端的 Head 调用,并且返回一个 response. 当客户端只需要响应的 Header 时,它就发出一个Header 请求.这种情况下客户端往往关心响应的长度和响应的 MIME 类型. doOptions(): 它用于处理客户端的 Options 调用,通过这个调用, 客户端可以获得此 Servlet 支持的方法.如果 Servlet 覆盖了 doPost() 方法, 那么将返回: Allow: POST, TRACE, OPTIONS, HEAD doTrace：处理 TRACE 请求 4.3 HttpServlet 实现 Servlet 中的Servlet方法123456789101112131415161718@Override public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException &#123; HttpServletRequest request; HttpServletResponse response; try &#123; request = (HttpServletRequest) req; response = (HttpServletResponse) res; &#125; catch (ClassCastException e) &#123; throw new ServletException(&quot;non-HTTP request or response&quot;); &#125; //HttpServlet 重载 的Service() 方法，使用到了编译时多态，因为参数类型不一样。 service(request, response); &#125;&#125; 4.4 HttpServlet 重载的 Service() 方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; // 从 HTTP 请求中取得这次请求所使用的 HTTT 方法 String method = req.getMethod(); // 如果这次请求使用 GET 方法 if (method.equals(METHOD_GET)) &#123; // 取得这个 Servlet 的最后修改的时间 long lastModified = getLastModified(req); if (lastModified == -1) &#123; // servlet doesn&apos;t support if-modified-since, no reason // to go through further expensive logic //-1 代表这个 Servlet 不支持最后修改操作，直接调用 doGet() 进行处理 HTTP GET 请求 doGet(req, resp); &#125; else &#123; long ifModifiedSince; try &#123; // 如果这个 Servlet 支持最后修改操作，取得请求头中包含的请求的最后修改时间 ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); &#125; catch (IllegalArgumentException iae) &#123; // Invalid date header - proceed as if none was set ifModifiedSince = -1; &#125; // 如果请求头中包含的修改时间早于这个 Servlet 的最后修改时间，说明这个 Servlet 自从客户上一次 HTTP 请求已经被修改了 , 设置最新修改时间到响应头中 if (ifModifiedSince &lt; (lastModified / 1000 * 1000)) &#123; // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less maybeSetLastModified(resp, lastModified); doGet(req, resp); &#125; else &#123; resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123; long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123; doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123; doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123; doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123; doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123; doTrace(req,resp); &#125; else &#123; // // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // String errMsg = lStrings.getString(&quot;http.method_not_implemented&quot;); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); &#125; &#125; 5.Servlet 是否是线程安全的Servlet 是线程非安全的。这是单例模式的通病。 因为servlet对象是单例模式的创建型对象，在一次Servlet Container 启停过程中，整个 Servlet 生命周期内只维持一个Servlet对象，而对于每一个请求应用服务器都会从线程池中excute 一个线程去执行一个runnertask（request请求）所以如果在一个Servlet中定义了实例域，那么就会产生多线程并发修改共享变量的线程安全问题，解决这个问题的办法是对多线程对共享变量的操作采用同步操作，或者采用ThreadLocal 将每个线程与其自身的变量绑定在一起。]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>Java WEB</tag>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java虚拟机内存模型]]></title>
    <url>%2F2018%2F06%2F11%2FJava%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[章节 JVM结构 运行时数据区（Java run time data area） 方法区－线程共享 堆区 －线程共享 Java栈 －线程私有 native 本地方法栈－线程私有 PC寄存器 － 线程私有 类加载器子系统 ClassLoader 概述 类加载时机 ClassLoader 分类 ClassLoader 工作原理 装载 链接 初始化 执行引擎 1. JVM结构1231、JVM 主要由类加载器、Java运行时数据区、执行引擎以及本地方法接口组成。2、Java 运行时数据区由 方法区、堆、Java栈、PC寄存器、本地方法栈组成。3、本地方法栈、PC寄存器、Java栈是由每个线程私有的；方法区、堆是所有java线程共享的。 2.运行时数据区2.1 Java 栈123451.Java栈与线程关联在一起，new Thread() 后会为当前线程创建对应的Java栈。2.每个Java 栈中会包含多个栈帧，每个栈帧与每个运行中的方法对应起来。3.运行一个方法创建一个栈帧，方法运行结束，栈帧弹出栈顶。``` **2.1.1 局部变量区** 局部变量区 包含 方法参数、和局部变量、基本类型变量、对象引用。1**2.1.2 操作数栈** 进行入栈出栈基本操作。在计算时，操作数栈出栈，计算完毕后再入栈。1**2.1.3 帧数据区** 1.记录 存储类的相关信息的常量池的 指针 ，便于解析。2.帮助方法正常返回：恢复调用该方法的栈帧、设置PC寄存器指向调用方法对应的下一条指令、把返回值压入调用方法的栈帧中的操作数栈中。1**2.2 本地方法栈** 本地方法栈类似于Java栈，主要存储本地方法调用状态。本地方法栈为JVM调用native方法服务。12**2.3 PC寄存器/程序计数器** 记录当前线程即将执行的下一条指令的地址。1**2.4 方法区** 类型信息和类的静态变量都存储在方法区中方法区中每个类存储了以下数据：1.类及其父类的全限定名2.类的类型 class or interface3.访问的修饰符 （public abstract final）4.实现的接口的全限定名的列表5.字段信息6.方法信息7.静态变量8.常量池9.ClassLoader 引用10.Class引用1**注意：**可见类的所有信息都存储在方法区中，由于方法区是线程共享的，所以必须保证线程安全。 举例：两个类要同时加载一个尚未被加载的类，那么一个类会请求它的ClassLoader去加载需要的类，另一个类只能等待而不会重复加载。1**2.4.1 常量池** 常量池本身是方法区中的一个数据结构：1、常量池中存储了如字符串(有些地方称之为字符串池)、final 变量值，类名和方法名常量。2.常量池中数据在编译器就被确定，保存在.class文件中。 分为两类： 字面量：final变量、字符串 引用量：类名、方法名、类和接口的全限定名3.方法区对应持久代(Permanent Generation)，默认大小16M,最大值64M。大小通过参数来设置，-XX:permSize 指定初始值，-XX:MaxPermSize 指定最大值。1**2.5 堆** 1.堆是JVM管理的内存中最大的一块，是被所有Java线程共享的， 不是线程安全的，在JVM启动时创建。2.堆用于存储对象实例以及数组值。3.堆中有指向方法区中常量池中类信息的指针4.堆中存放了指向方法表的指针5.堆中实例数据包含了对象锁 monitor 对象，1**2.5.1 分代管理模式-新生代、老年代** 1.新生代（New Generation）大多数情况下对象被分配在新生代，新生代由Eden Space 和两块相同大小的Survivor Space 组成。 后两者主要用于Minor GC 时的对象复制。2.老年代 （Old Generation/Tenuring Generation）在新生代存活时间较久的对象会被转入老年代，老年代进行垃圾回收的频率没有新生代高。123#### 3.类加载器子系统（Class Loader）**3.1 类加载器概述** 类加载器子系统负责加载编译好的.class 字节码文件，一般情况下类在编译成.class 文件之后，立即被装入内存，使JVM可以实例化或以其他方式使用加载后的类。JVM的类加载子系统支持在运行时的动态加载(Java 反射)，动态加载可以节省内存空间。12345678910111213141516**3.2 类加载的时机**|类加载时机|含义|举例||-----|-----|-----||静态加载| 静态加载类，在编译时刻就需要加载所有可能使用到的类|如 new Word()||动态加载|属于延迟加载的模式，在java反射中会用到，首先节省内存，另外一个是动态加载类，这种方式在动态工厂方法中也会用到，这个生成类的util类只需要被加载一次就可以了|如 class.forName this.getClass() Class.class 三种方式实现运行时加载|**3.3 ClassLoader 分类*** 1.启动类加载器 （Bootstrap ClassLoader），java rt.jar 负责加载java 核心类* 2.扩展类加载器 （Extension ClassLoader），负责加载一些扩展功能的jar包* 3.系统类加载器 (System ClassLoader )，负责加载启动参数中制定的ClassPath 中的jar 包及目录。我们自己写的Java类也是由该ClassLoader加载的。* 4.用户自定义类加载器 （UserDefined Classloader）：用户自定义类的加载规则，可以手动控制加载过程中的步骤。**3.4 ClassLoader的工作原理**类加载分为三个过程：装载、链接、初始化**3.4.1 装载** 通过类的全限定名和Classloader 加载类，主要是将指定的.class文件加载至jvm当中，类加载之后，jvm内部使用类的全限定名＋ClassLoader实例ID 标明类。2.ClassLoader 实例 与 类实例位于堆中，他们的类信息位于方法区中3.装载过程使用“ 双亲委派模型”,当一个ClassLoader要加载类时，他会先请求他的双亲ClassLoader，即整个加载类的请求不断上抛，直到启动类加载器。只有其双亲ClassLoader无法加载指定的类时，它才会自己加载类。4.不同类加载器之间是无法交互的，即使是同一个类，被不同的ClassLoader加载，他们也无法感知彼此的存在。1**3.4.2 链接** 1.验证：校验.class文件的正确性，确保改文件是符合规范定义的2.准备：为类分配内存，同时初始化类中的静态变量赋值为默认值。3.解析：主要把类的常量池中的符号引用解析为直接引用。123**3.4.3 初始化**定义：初始化类中的静态变量，并执行类中的static代码，构造函数。初始化类的时机 1.通过new关键字、反射、clone、反序列化机制实例化对象2.调用类的静态方法3.使用类的静态变量或对其赋值4.通过反射调用类的方法5.初始化该类子类，其父类必须已经被初始化6.具有main方法的类。```]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java虚拟机</tag>
        <tag>内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发机制底层实现原理－读写锁（ReentrantReadWriteLock）]]></title>
    <url>%2F2018%2F06%2F11%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E8%AF%BB%E5%86%99%E9%94%81(ReentrantReadWriteLock)%2F</url>
    <content type="text"><![CDATA[章节目录 ReentrantReadWriteLock 特性 读写锁接口示例 读写锁的实现分析 读写状态设计 写锁的释放与获取 读锁的释放与获取 锁降级 1. ReentrantReadWriteLock 特性1.1 读写锁定义1读写锁维护了一对锁，一个读锁，一个写锁，通过分离读锁写锁，使得并发性相比一般的排他锁有了很大提升。 1.2 读写锁使用场景121.读写锁比较适用于读多写少的应用场景。2.读写锁在统一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程、其他写线程均被阻塞。 1.3 读写锁的优点1231.保证写操作对读操作的可见性2.在读多写少的情况下的并发性的提升3.读写锁简化可读写交互场景的编程方式 2.读写锁接口示例如下为使用读写锁操作缓存的示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package org.seckill.lock;import java.util.HashMap;import java.util.Map;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantReadWriteLock;public class ReadWriteCache &#123; //充当cache static Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); //实例化读写锁对象 static ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(); //实例化读锁 static Lock r = reentrantReadWriteLock.readLock(); //实例化写锁 static Lock w = reentrantReadWriteLock.writeLock(); //获取缓存中值 public static final Object get(String key) &#123; r.lock(); try &#123; return map.get(key); &#125; finally &#123; r.unlock(); &#125; &#125; //写缓存中值，并返回对应value public static final Object set(String key, Object obj) &#123; w.lock(); try &#123; return map.put(key, obj); &#125; finally &#123; w.unlock(); &#125; &#125; //清空所有内容 public static final void clear() &#123; w.lock(); try &#123; map.clear(); &#125; finally &#123; w.unlock(); &#125; &#125;&#125; 如上所示:123456789101.Cache组合一个非线程安全的HashMap做为缓存实现，同时使用读写锁的读锁和写锁来保证Cache是线程安全的。2.在读操作get(String key)方法中，需要使用读锁，这使得并发访问该方法时不会被阻塞。3.写锁put(String key,Object object)方法和clear()方法，在更新HashMap时必须提前获取写锁，当获取写锁后，其他线程对于读锁和写锁的获取都被阻塞，只有写锁释放之后，其他的读写操作才能继续操作，也就是说写锁其实是排他锁、互斥锁。4.最终，读锁提升了读操作的并发性，也保证了每次写操作对所有后续读操作的可见性，同时简化了编程方式，对应1.3 3.读写锁的实现分析3.1 读写状态设计12345671.读写锁同样依赖自定义同步器实现同步功能2.ReentrantLock 中同步状态表示锁被一个线程重复获取的次数。3.读写锁自定义同步器需要在同步状态上维护多个读线程和一个写线程的状态。4.读写锁同步器采用在一个4字节的整形变量上使用 按位切割 的方式来维护读写线程的同步状态。高16位用来表示读，低16位用来表示写。5.写状态增加1，表示当前线程获取写锁，则 Status = S(当前同步状态)+1,当读状态加1时，Status = S+(1&lt;&lt;16) 3.2 写锁的获取与释放如下源码所示：12345678910111213141516171819202122232425262728293031323334protected final boolean tryAcquire(int acquires) &#123; /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); int c = getState(); //获取独占锁(写锁)的被获取的数量 int w = exclusiveCount(c); if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) //1.如果同步状态不为0，且写状态为0,则表示当前同步状态被读锁获取 //2.或者当前拥有写锁的线程不是当前线程 if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; &#125; 3.3 读锁的释放与获取12345678910111213protected final int tryAcquireShared(int unused) &#123; for(;;) &#123; int c = getState(); int nextc = c + (1&lt;&lt;16); if(nextc &lt; c) &#123; throw new Error(&quot;Maxumum lock count exceeded&quot;); &#125; if(exclusiveCount(c)!=0 &amp;&amp; owner != Thread.currentThread()) return -1; if(compareAndSetState(c,nextc)) return 1; &#125;&#125; 如果其他线程获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程安全，依靠CAS保证增加读状态，成功获取锁。 3.4 锁降级锁降级是指当前把持住写锁，再获取到读锁，随后释放(先前拥有的)写锁的过程。 锁降级过程中的读锁的获取是否有必要，答案是必要的。主要是为了保证数据的可见性，如果当前线程不获取读锁而直接释放写锁，假设此刻另一个线程获取的写锁，并修改了数据，那么当前线程就步伐感知到线程T的数据更新，如果当前线程遵循锁降级的步骤，那么线程T将会被阻塞，直到当前线程使数据并释放读锁之后，线程T才能获取写锁进行数据更新。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>读写锁（ReentrantReadWriteLock）</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发机制底层实现原理－重入锁]]></title>
    <url>%2F2018%2F06%2F11%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E9%87%8D%E5%85%A5%E9%94%81%2F</url>
    <content type="text"><![CDATA[章节目录 什么是重入锁 底层实现-如何实现重入 公平与非公平获取锁的区别与底层实现 1.什么是重入锁1.1 重入锁的定义1重入锁ReentrantLock，支持重入的锁，表示一个线程对资源的重复加锁。 1.2 重入锁的特性121.重进入2.非/公平性获取锁 1.3 自定义同步器Mutex 的缺陷123当线程调用Mutex的lock()方法获取锁之后，再次调用lock()方法，该线程将会被自己阻塞，原因是Mutex在实现tryAcquire(int acquires)方法时没有考虑占有锁的线程再次获取锁的场景。 1.4 ReentrantLock &amp; synchronized 关键字1231.synchronized 关键字支持隐式的重进入2.ReentrantLock 在调用lock() 方法时，已经获取到锁的线程，能够再次调用lock()方法获取到锁而不被阻塞，即可支持重入 1.4 公平性获取锁 公平性 含义 公平性获取锁 在绝对时间上，先对锁进行获取请求的请求一定先被满足，那么这个锁就是公平的 非公平性获取锁 无上述限制 事实上 公平锁机制往往没有非公平性机制获取锁的效率高，因为会牵扯到频繁的上下文切换，但公平锁可以减少饥饿发生的概率，等待越久的请求越能得到优先满足。 2. 底层实现-如何实现重入重进入是指任意线程在获取到锁之后能够再次获取该锁，而不被阻塞，改特性实现需要解决以下两个问题： 线程再次获取锁 1线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。 锁的最终释放 12 线程重复n次获取了锁，随后在第n次释放锁，锁的释放要求锁对于被获取递增的次数进行递减操作，当计数==0时表示锁已经成功释放。 2.1 可重入锁的源码非公平性获取同步状态(锁)的 nonfairTryAcquire() 方法123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; 该方法增加了再次获取同步状态的处理逻辑:通过判断当前线程是否为获取锁的线程来决定获取操作是否成功，如果是获取锁的线程的再次请求 则将同步状态值计数器进行递增并返回true，表示获取同步状态成功。 释放同步状态(锁)123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; 如果该锁被获取了n次，那么前n-1此tryRelease(int release) 方法必须返回false，而只有同步状态完全释放了，才能返回true。 3.公平与非公平获取锁的区别与底层实现3.1 公平性获取锁的底层实现公平性获取锁即按照客观时间顺序，FIFO方式获取同步状态具体源码如下所示12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; 公平性获取同步状态的与非公平性获取同步状态的区别在于hasQueuedPredecessors()方法的使用，即加入了当前节点是否有前驱节点的判断，如果该方法返回true,则表示有线程比当前线程更早的加入到同步队列（更早的请求获取锁），因此需要等待前驱线程获取并释放锁之后才能继续获取锁。 非公平性获取锁的实现 公平性获取锁保证了锁的获取顺序按照FIFO原则，不会出现线程“饥饿”的现象，但代价是进行大量的线程切换。 非公平性锁虽然可能造成线程饥饿，但是有极少的线程切换，保证了其更大的吞吐量。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>重入锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发机制底层实现原理－队列同步器(AbstractQueuedSynchronizer)]]></title>
    <url>%2F2018%2F06%2F11%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E9%98%9F%E5%88%97%E5%90%8C%E6%AD%A5%E5%99%A8(AbstractQueuedSynchronizer)%2F</url>
    <content type="text"><![CDATA[章节目录 Lock接口与Synchronized的区别及特性 队列同步器的接口与自定义锁示例 队列同步器的实现分析 1.Lock接口与Synchronized的区别及特性 特性 描述 尝试非阻塞性的获取锁 当前线程尝试获取锁（自旋获取锁），如果这一时刻锁没有被其他线程获取到，则成功获取并持有锁 能被中断的获取锁 已获取锁的线程可以响应中断，当获取到锁的线程被中断时，可以抛出中断异常，同时锁会被释放 超时获取锁 在指定的截止时间之前获取锁，如果截止时间到了仍然没有获取到锁，则返回 注意：Lock接口的实现基本上都是通过聚合了一个同步器的子类来完成线程访问控制的 队里同步器的接口与定义锁示例队列同步器定义：123队列同步器，是用来构建锁与其它同步组件的基础框架，基本数据结构与内容是：1、int state -&gt; state 标示同步状态；2、内置的FIFO来完成获取同步状态的线程的排队工作。 队列同步器使用方式1234567891、子类通过继承同步器并实现它的抽象方法来管理同步状态；2、实现过程中对同步状态的更改，通过setState()、setState(int newState)、compareAndSetState(int expect,int newUpdateValue)来进行操作，保证状态改变时原子性的、安全的；3、实现同步器的子类被推荐为自定义同步组件的静态内部类；4、同步器可以支持独占式的获取同步状态(ReentrantLock)、也可以支持共享式的获取同步状态(ReentrantReadWriteLock) 对于同步器与锁的关系可以这样理解： 在锁的实现中聚合同步器，利用同步器实现锁的语义。 锁面向使用者，它定义了使用者与锁的交互接口，隐藏了实现细节。 同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步器状态管理、线程排队、等待与唤醒等底层操作。 2.队列同步器的接口与自定义锁示例2.1 模板方法模式123同步器的设置是基于**模版方法模式**,使用者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。 2.2 重写同步器指定的方法1234getState():获取当前同步状态setState(int newState):设置当前同步状态compareAndSetState(int expect,int update): 使用CAS设置当前的状态，该方法保证状态设置的原子性 2.3 同步器可重写的方法 方法名称 描述 protected boolean tryAcquire(int arg) 独占式获取同步状态，实现该方法需要查询当前状态并判断同步状态是否符合预期，然后再进行CAS设置同步状态 protected boolean tryRelease(int arg) 独占式释放同步状态，等待获取同步状态的线程将有机会获取同步状态（公平性获取锁） protected int tryAcquireShared(int arg) 共享式获取同步状态，返回&gt;=0的值，标示获取成功，反之获取失败 protected boolean tryReleaseShared(int arg) 共享式释放同步状态 protected boolean isHeldExclusively() 当前同步器是否在独占模式下被线程占用，一般该方法表示是否被当前线程所独占 2.4 独占锁示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package org.seckill.lock;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.AbstractQueuedSynchronizer;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;/** * 利用了模板方法模式 */public class Mutex implements Lock &#123; private static class Sync extends AbstractQueuedSynchronizer &#123; //是否处于占用状态 @Override protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; //当状态为0时获取锁 @Override protected boolean tryAcquire(int arg) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; //释放锁，将当前状态设置为0 @Override protected boolean tryRelease(int arg) &#123; if (getState() == 0) &#123; throw new IllegalMonitorStateException(); &#125; setExclusiveOwnerThread(null); setState(0); return true; &#125; //返回一个condition,每个condition中都包含了一个condition队列 Condition newCondition() &#123; return new ConditionObject(); &#125; &#125; //仅需要将操作代理到Sync上即可 private Sync sync = new Sync(); public void lock() &#123; sync.acquire(1);//调用tryAccquire &#125; //当前已获取锁的线程响应中断，释放锁，抛出异常，并返回 public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; public boolean tryLock() &#123; return sync.tryAcquire(1);//尝试立即获取锁 &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout));//尝试超时获取锁 &#125; public void unlock() &#123; sync.release(1);//释放锁 &#125; public Condition newCondition() &#123; return sync.newCondition(); &#125;&#125; 总结-实现同步组件的方法123451. 独占锁Mutex 是一个自定义同步组件，它允许同一时刻只允许同一个线程占有锁。2.Mutex中定义了一个私有静态内部类，该类继承了同步器并实现了独占式获取和释放同步状态。3.在tryAcquire(int acquires)方法中，经过CAS设置成功(同步状态设置为1)，则代表获取了同步状态，而在tryRelease(int releases) 方法中只是将同步状态重置为0。 3 队列同步器的实现分析3.1 同步队列数据结构 同步器依赖内部的同步队列，即一个FIFO的队列，这个队列由双向链表实现。节点数据从 队列尾部插入，头部删除。 node 数据结构1234567struct node &#123; node prev; //节点前驱节点 node next; //节点后继节点 Thread thread; //获取同步状态的线程 int waitStatus; //等待状态 Node nextWaiter; //等待队列中的后继节点&#125; 等待队列 后续篇章介绍到condition会有相关记录。 3.2 无法获取到同步状态的线程节点被加入到同步队列的尾部1234本质上是采用 compareAndSetTail(Node expect,Node update)，当一个线程成功的获取了同步状态(或者锁)，其他线程将无法获取到同步状态，转而被构造成为节点并加入到同步队列中，而这个加入队列的过程必须要保证线程安全。所以采用了基于CAS的方式来设置尾节点的方法。，需要传递当前节点认为的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。 3.3 成功获取同步状态12同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，会唤醒后继节点，而后继节点将会在获取同步状态成功时，将自己设置为首节点。 3.4 独占式同步状态获取与释放 前驱节点为头节点且能够获取同步状态的判断条件和线程进入同步队列 来获取同步状态是自旋的过程。 设置首节点是通过获取同步状态成功的线程来完成的acquireQueued(node,args)完成的 独占式获取同步状态的流程图]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>队列同步器(AbstractQueuedSynchronizer)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型-撸一个数据库连接池]]></title>
    <url>%2F2018%2F06%2F11%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%8D%E6%92%B8%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[章节目录 等待超时模式的使用场景 可以掌握的技能 等待/通知 消费者/生产者模式 CountDownLatch、AtomicInteger、静态内部类、LinkedList、动态代理的使用 1.等待超时模式场景 当我们调用方法时，这个方法返回的资源比较重要，比如获取数据库连接池中连接句柄。但是这个资源的返回随着业务量的增加，那么获取资源(连接池连接)的时间就会增加，那么调用一个方法时就要等待一段时间(一般来说是给定一个时间段)，如果该方法能够在一段时间内获取到结果，那么将结果立刻返回，反之，超时返回默认结果。 等待/通知的经典范式，即加锁、条件循环、处理逻辑3个步骤，这种范式没办法做到超时等待，对经典范式做很小的改动，就可以实现超时等待。 等待超时模式伪代码：1234567891011public synchronized Object get(long mills) throws InterruptedException &#123; Object result = null; long future = System.currentTimeMills() + mills; long remaining = mills; while (result == null &amp;&amp; remaining &gt; 0) &#123; wait(remaining);//释放锁，阻塞 mills 毫秒 remaining = future - System.currentTimeMills(); &#125; return result;//如果超时之后获取到result则不返回null&#125; 超时等待的作用就是不会永远阻塞调用者，但是 超时之后被唤醒，知识将线程从等待队列移动至阻塞队列，继续向下进行返回result还是要重新获取锁，如果一直获取不到锁，那么result也不会打印。只是增加了灵活性。 2.可以掌握的技能实战使用等待超时模式撸一个简单数据库连接池，在示例中模拟： 从连接池获取连接 RunnerThread 使用连接 RunnerThread 释放连接 RunnerThread注意：客户端获取(消费)连接的过程被设定为等待超时、等待/通知两种模式ConnectionPool.java-数据库连接池1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package org.seckill.DBConnection;import java.sql.Connection;import java.util.LinkedList;/** * 数据库连接池对象 */public class ConnectionPool &#123; //链表list（池）维护 connection 连接对象 private LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;(); //构造方法 初始化池中连接 public ConnectionPool(int initialSize) &#123; if (initialSize &gt; 0) &#123; for (int i = 0; i &lt; initialSize; i++) &#123; pool.addLast(ConnectionDriver.createConnection());//创建initialSize个代理Connection对象 &#125; &#125; &#125; //释放connection ,相当于-生产者 public void releaseConnection(Connection connection) &#123; if (connection != null) &#123;//有效归还连接 synchronized (pool) &#123; pool.addLast(connection); //生产者动作完毕后，需要唤醒所有消费者 pool.notifyAll(); &#125; &#125; &#125; //获取connection句柄，相当于消费者，采用超时等待与等待/通知两种策略 public Connection fetchConnection(long mills) throws InterruptedException &#123; synchronized (pool) &#123; if (mills &lt; 0) &#123;//非超时等待模式，采用等待/通知模式 while (pool.isEmpty()) &#123; pool.wait();//本示例中不演示这种模式下获取连接的情景 &#125; return pool.removeFirst(); &#125; else &#123;//超时等待模式 long future = System.currentTimeMillis() + mills; long remaining = mills; while (pool.isEmpty() &amp;&amp; remaining &gt; 0) &#123; pool.wait(remaining); remaining = future - System.currentTimeMillis(); &#125; Connection connection = null; if (!pool.isEmpty()) &#123; connection = pool.removeFirst();//返回头结点对象 &#125; return connection; &#125; &#125; &#125;&#125; ConnectionDriver.java-动态生成Connection代理对象12345678910111213141516171819202122232425262728293031package org.seckill.DBConnection;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.sql.Connection;/** * 数据库连接驱动， * 动态代理获取实现java.sql.Connection 接口的代理对象 */public class ConnectionDriver &#123; static class ConnectionHandler implements InvocationHandler &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if (method.getName() == &quot;commit&quot;) &#123; Thread.sleep(100); &#125; return null; &#125; &#125; //获取Connection的动态代理类 public static final Connection createConnection() &#123; return (Connection) Proxy.newProxyInstance( ConnectionDriver.class.getClassLoader(),//类加载器 new Class&lt;?&gt;[]&#123;Connection.class&#125;,//Connection实现的接口列表，包含Connection接口 new ConnectionHandler());//与代理对象绑定的handler &#125;&#125; ConnectionPoolTest.java–测试类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package org.seckill.DBConnection;import java.sql.Connection;import java.util.concurrent.CountDownLatch;import java.util.concurrent.atomic.AtomicInteger;public class ConnectionPoolTest &#123; //线程池中初始化10个连接 static ConnectionPool connectionPool = new ConnectionPool(10); //保证所有的ConnectionRunner 能够同时开始 static CountDownLatch start = new CountDownLatch(1); //main线程将等待所有的Connection Runner结束后才开始执行 static CountDownLatch end; public static void main(String[] args) throws Exception &#123; //ConnectionRunner 线程数量，可以修改线程数量进行观察 int threadCount = 50; end = new CountDownLatch(threadCount); int count = 20;//每个线程进行20次fetchConnetion动作 AtomicInteger got = new AtomicInteger(); AtomicInteger notGot = new AtomicInteger(); for (int i = 0; i &lt; threadCount; i++) &#123; Thread thread = new Thread(new ConnectionRunner(count, got, notGot), &quot;ConnectionRunnerThread&quot;); thread.start(); &#125; start.countDown();//使所有线程同时运行 end.await();//主线程等待所有线程运行完 System.out.println(&quot;总的请求次数&quot; + threadCount * count); System.out.println(&quot;获取到的连接总数&quot; + got); System.out.println(&quot;未获取到的连接总数&quot; + notGot); &#125; static class ConnectionRunner implements Runnable &#123; int count;//每个线程fetchConnetion的次数 AtomicInteger got;//记录fetchConnection 成功的次数 AtomicInteger notGot;//记录fetchConnetion 未成功的次数 public ConnectionRunner(int count, AtomicInteger got, AtomicInteger notGot) &#123; this.count = count; this.got = got; this.notGot = notGot; &#125; public void run() &#123; try &#123; start.await();//等待 所有ConnectionRunner 初始化成功且处于Runnable状态,同时开始运行，由主线程控制的 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; while (count &gt; 0) &#123; try &#123; //从连接池中获取连接，如果1000ms内无法获取到，将会返回null。 Connection connection = connectionPool.fetchConnection(1000); if (connection != null) &#123; try &#123; connection.createStatement(); connection.commit(); &#125; finally &#123; //归还连接 connectionPool.releaseConnection(connection); got.incrementAndGet();//对获取次数状态进行更改 &#125; &#125; else &#123; notGot.incrementAndGet();//对未获取次数状态进行更改 &#125; &#125; catch (Exception e) &#123; &#125; finally &#123; count--;//运行次数递减 &#125; &#125; end.countDown(); &#125; &#125;&#125; 运行结果 1.设置RunnerConnection threadCount数为10 2.设置RunnerConnection threadCount数为20 3.设置RunnerConnection threadCount数为50 4.设置RunnerConnection threadCount数为100 可以看到随着 runnerConnection 连接线程数的递增，连接的稳定性是越来越低的。但用户调用不会长时间阻塞到connect fetch 上，而是按时返回。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>线程间通信-超时等待模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程基础-ThreadLocal的使用]]></title>
    <url>%2F2018%2F06%2F11%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80-ThreadLocal%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[章节目录 ThreadLocal 简介 ThreadLocal 使用 1.ThreadLocal 简介什么是ThreadLocal12ThreadLocal 为线程变量，是一个以ThreadLocal对象为key,任意对象为值的存储结构，这个结构被附带到线程上。 ThreadLocal的作用1通过set(T)来设置一个值，在当前线程下通过get()方法获取到原先设置的值。 2.ThreadLocal 使用 题目：设计一个方案统计每个接口的响应时间 思路： 采用AOP(面向切面编程)，可以在方法调用前的切入点执行begin()方法，在方法调用后的切入点执行end()方法。 每个请求本质上是线程执行的过程，那么问题就变为统计每个线程执行过程的耗时。 采用工具类+实力方式会产生过多工具类对象 采用静态方法方式，如果不同步共享变量会产生并发获取系统时间的问题，统计不准确。 采用同步方式统计接口响应时间，接口性能会下降。 那么有没有一种方式是将不通接口响应时间值绑定到 不同线程上的方式，并且获取方法一致，但是时间值是每个线程特定可见的，答案就是使用ThreadLocal Profilerbegin() 获取接口执行时间点、end()获取从begin()方法调用开始到end()方法被调用时的时间差，单位毫秒。123456789101112131415161718192021222324252627package org.seckill.Thread;public class Profiler &#123; private static final ThreadLocal&lt;Long&gt; TIME_THREADLOCAL = new ThreadLocal&lt;Long&gt;()&#123; //第一次get()方法调用时会进行初始化，这个是在set()方法没有被调用的情况下发生，每个线程调用一次 protected Long initialValue() &#123; return System.currentTimeMillis(); &#125; &#125;; //设置初始运行时刻 public static final void begin()&#123; TIME_THREADLOCAL.set(System.currentTimeMillis()); &#125; public static final long end()&#123; return System.currentTimeMillis()- TIME_THREADLOCAL.get(); &#125; public static void main(String[] args) &#123; Profiler.begin(); Interrupted.SleepUnit.second(1); System.out.println(&quot;cost time &quot;+Profiler.end()); &#125;&#125; 运行结果：]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>ThreadLocal的使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型-线程间通信]]></title>
    <url>%2F2018%2F06%2F11%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80-%E7%BA%BF%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[章节目录 volatile 与 synchronized 关键字 等待/通知机制 等待/通知经典范式 管道输入/输出流 Thread.join() 的 使用 1. volatile 与 synchronized 关键字 线程开始运行，拥有自己的栈空间，就如同一个脚本一样，按照既定的代码一行一行的执行，直到终止。如果每个运行中的线程，仅仅是孤立的运行，那么没有价值，或者说价值很少，如果多个线程能够 相互配合 完成工作，这将带来巨大的价值。 1.1 Java 线程操作的共享变量是对共享内存变量的一份拷贝1234Java支持多个线程同时访问一个对象或者对象的成员变量，由于每个线程可以拥有这个共享变量的一份拷贝(虽然对象以及成员变量分配的内存是在共享内存中，但是每个执行的线程还是可以拥有一份拷贝，这样做的目的是加速程序的执行)。这是现代多核处理器的一个显著特性，所以在程序执行过程中，（未同步的程序代码块），一个线程看到的变量并不一定是最新的。 1.2 volatile 关键字-线程间通信123关键字volatile可以用来修饰字段(成员变量)，就是告知任何对该变量的访问均需要从共享内存中获取，而对它的改变必须同步刷新到共享内存，它能保证虽有线程对共享变量的可见性。 12345举个例子，定义一个程序是否运行的成员变量，boolean on = true; 那么另一个线程可能对它执行关闭动作(on = false)，这涉及多个线程对变量的访问，因此需要将其定义为 volatile boolean on = true，这样其他线程对他进行改变时，可以让所有线程感知到变化，因为所有对共享变量的访问(load)和修改(store)都需要以共享内存为准。但是过多的使用volatile是不必要的，因为它会降低程序执行的效率。 1.3 synchronized 关键字-线程间通信123关键字 synchronized 可以修饰方法 或者以同步块的形来进行使用，它主要确保多个线程在同一时刻，只能有一个线程执行同步方法或同步块，它保证了线程对变量访问的可见性、排他性。 如下所示，类中使用了同步块和同步方法，通过使用javap 工具查看生成的class文件信息来分析synchronized关键字实现细节，示例如下:123456789101112131415package org.seckill.Thread;public class Synchronized &#123; public static void ls(String[] args) &#123; synchronized (Synchronized.class) &#123; &#125;//静态同步方法，对Synchronized Class对象进行加锁 m(); &#125; public static synchronized void m()&#123; &#125;&#125; 执行 javap -v Synchronized.class输出如下所示：1234567891011121314151617181920212223242526public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: ldc #2 // class org/seckill/Thread/Synchronized 2: dup 3: astore_1 4: monitorenter 5: aload_1 6: monitorexit 7: goto 15 10: astore_2 11: aload_1 12: monitorexit 13: aload_2 14: athrow 15: invokestatic #3 // Method m:()V 18: returnpublic static synchronized void m(); descriptor: ()V flags: ACC_PUBLIC, ACC_STATIC, ACC_SYNCHRONIZED Code: stack=0, locals=0, args_size=0 0: return 对上述汇编指令进行解读 对于同步代码块(临界区)的实现使用了monitorenter 和 monitorexit 指令。 同步方法则是依靠方法修饰符上的ACC_SYNCHRONIZED。 另种同步方式的原理是 对一个充当锁的对象的monitor 进行获取，而这个获取过程是排他的，也就是同一时刻只能有一个线程获取到由syntronized 所保护的对象的监视器。 任何一个对象都拥有自己的监视器，当这个对象由同步块或者这个对象的同步方法调用时，执行方法的线程必须先获取到对象的监视器才能进入到同步块或者同步方法中，那么没有获取到监视器（执行改方法）的线程将会被阻塞在同步块和同步方法的入口处，进入blocked 状态。 如下是对上述解读过程的图示： 2.等待/通知机制等待通知相关方法 方法名称 描述 wait() 调用lock.wait()（lock是充当锁的对象）的线程将进入waiting状态，只有等待另外线程的通知或者线程对象.interrupted()才能返回，wait()调用后，会释放对象的锁 wait(long) 超时一段时间，这里的参数是毫秒，也就是等待n毫秒，如果没有通知就超时返回 wait(long,int) 对于超时间的更细粒度控制，可以达到纳秒级别 notify() 通知一个在锁对象上等待的线程，使其从wait()方法返回，而返回的前提是该线程获取到了对象的锁（其实是线程获取到了该对象的monitor对象的控制权） notifyAll() 通知所有等待在充当锁的对象上的线程 对等待通知机制的解释 等待通知机制，是指一个线程A调用了充当锁的对象的wait()方法进入等 waiting 状态 另一个线程B调用了对象的O的 notify() 或者 notifyAll() 方法，线程A接收到通知后从充当锁的对象上的wait()方法返回，进而执行后续操作，最近一次操作是线程从等待队列进入到同步阻塞队列。 上述两个线程通过充当锁的对象 lock 来完成交互，而lock对象上的wait()／notify/notifyAll()的关系就如同开关信号一样，用来完成等待方和通知方的交互工作 如下代码清单所示，创建两个线程 WaitThread &amp; NotifyThread，前者检查flag是否为false，如果符合要求，进行后续操作，否则在lock上wait，后者在睡眠一段时间后对lock进行通知。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package org.seckill.Thread;public class WaitNotify &#123; static boolean flag = true; static Object lock = new Object();//充当锁的对象 public static void main(String[] args) &#123; //新建wait线程 Thread waitThread = new Thread(new WaitThread(),&quot;waitThread&quot;); Thread notifyThread = new Thread(new NotifyThread(),&quot;notifyThread&quot;); waitThread.start();//等待线程开始运行 Interrupted.SleepUnit.second(5);//主线程sleep 5s notifyThread.start(); &#125; //wait线程 static class WaitThread implements Runnable &#123; public void run() &#123; synchronized (lock) &#123; //判定flag while (flag) &#123; try &#123; System.out.println(Thread.currentThread().getName() + &quot;获取flag 信息&quot; + flag); //判定为true 直接wait lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(Thread.currentThread().getName() + &quot;获取flag 信息 为&quot; + flag); &#125; &#125; &#125; static class NotifyThread implements Runnable &#123; public void run() &#123; synchronized (lock) &#123; while (flag) &#123; System.out.println(Thread.currentThread().getName() + &quot;获取flag 信息 为&quot; + flag+&quot;可以运行&quot;); lock.notify();//唤醒wait在lock上的线程，此时wait线程只能能从waiting队列进入阻塞队列，但还没有开始重新进行monitorenter的动作 // 因为锁没有释放 flag = false; Interrupted.SleepUnit.second(5); &#125; &#125; synchronized (lock)&#123;//有可能获取到lock对象monitor,获取到锁 System.out.println(Thread.currentThread().getName()+&quot; hold lock again&quot;); Interrupted.SleepUnit.second(5); &#125; &#125; &#125;&#125; 运行结果如下所示： 对如上程序运行流程的解释如下所示：上图中”hold lock again 与 最后一行输出”的位置可能互换，上述例子说明调用wait()、notify()、notifyAll需要注意的细节 使用wait()、notify() 和 notifyAll() 时需要在同步代码块或同步方法中使用，且需要先对调用的锁对象进行加锁（获取充当锁的对象的monitor对象） 调用wait() 方法后，线程状态由running 变为 waiting，并将当前线程放置到等待队列中 notify()、notifyAll() 方法调用后，等待线程依旧不会从wait()方法返回，需要调用notify()、notifyAll()的线程释放锁之后，等待线程才有机会从wait()方法返回 notify() 方法将waiting队列中的一个等待线程从waiting队列 移动到同步队列中，而notifyAll() 则是将等待队列中所有的线程全部移动到同步队列，被移动的线程状态由waiting status change to blocked状态 从wait() 方法返回的前提是获得了调用对象的锁等待/通知机制依托于同步机制，其目的就是确保等待线程从wait()方法返回时能够感知到通知线程对变量做出的修改 3.等待/通知经典范式等待/通知经典范式该范式分为两部分，分别针对等待方(消费方)、和通知方(生产方)等待方遵循如下原则: 获取对象的锁 如果条件不满足，则调用对象的wait() 方法，被通知后仍要检查条件 条件满足则执行对应的逻辑对应伪代码123456syntronized (lock) &#123; while( !条件满足 )｛ lock.wait(); ｝ //对应的处理逻辑&#125; 通知方遵循如下原则: 获取对象锁 改变条件 通知所有等待在锁对象的线程12345syntronized(lock) &#123; //1.执行逻辑 //2.更新条件 lock.notify(); &#125; 4.管道输入输出流 管道输入 / 输出流和普通的文件输入/输出流 或者网络输入/输出流的不同之处在于它主要用于线程之间的数据传输，而传输的媒介为内存。 管道输入 / 输出流主要包括如下4种具体实现：PipedOutputStream、PipedInputStream、PipedReader 、PipedWriter 前两种面向字节，后两种面向字符对于Piped类型的流，必须先进行绑定，也就是调用connect()方法，如果没有输入/输出流绑定起来，对于该流的访问将抛出异常。 5.Thread.join() 的 使用如果使用了一个线程A执行了thread.join ,其含义是线程A等待thread线程终止之后才从thread.join()返回。如下笔试题：有A、B、C、D四个线程，在main线程中运行，要求 执行顺序是A-&gt;B-&gt;C-&gt;D-&gt;mian变种-&gt;main等待A、B、C、D四个线程顺序执行，且进行sum，之后main线程打印sum解法1-join()其实就是插队123456789101112131415161718192021222324252627282930313233343536373839404142package org.seckill.Thread;public class InOrderThread &#123; static int num = 0; public static void main(String[] args) throws InterruptedException &#123; Thread previous = null; for (int i = 0; i &lt; 4; i++) &#123; char threadName = (char) (i + 65); Thread thread = new Thread(new RunnerThread(previous), String.valueOf(threadName)); previous = thread; thread.start(); &#125; previous.join(); System.out.println(&quot;total num=&quot; + num); System.out.println(Thread.currentThread().getName() + &quot;terminal&quot;); &#125; static class RunnerThread implements Runnable &#123; Thread previous;//持有前一个线程引用 public RunnerThread(Thread previous) &#123; this.previous = previous; &#125; public void run() &#123; if (this.previous == null) &#123;// num += 25; System.out.println(Thread.currentThread().getName() + &quot; terminate &quot;); &#125; else &#123; try &#123; previous.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;// num += 25; System.out.println(Thread.currentThread().getName() + &quot; terminate &quot;); &#125; &#125; &#125;&#125; 解法2-wait/notify123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package org.seckill.Thread;//wait/notifypublic class InOrderThread2 &#123;// static int state = 0;//运行标志// static Object lock = new Object(); public static void main(String[] args) &#123;// RunnerThread runnerThreadA = new RunnerThread();// RunnerThread runnerThreadB = new RunnerThread();// RunnerThread runnerThreadC = new RunnerThread();// RunnerThread runnerThreadD = new RunnerThread();// Thread threadA = new Thread(runnerThreadA, &quot;A&quot;);// Thread threadB = new Thread(runnerThreadB, &quot;B&quot;);// Thread threadC = new Thread(runnerThreadC, &quot;C&quot;);// Thread threadD = new Thread(runnerThreadD, &quot;D&quot;); RunnerThread runnerThread = new RunnerThread(); Thread threadA = new Thread(runnerThread, &quot;A&quot;); Thread threadB = new Thread(runnerThread, &quot;B&quot;); Thread threadC = new Thread(runnerThread, &quot;C&quot;); Thread threadD = new Thread(runnerThread, &quot;D&quot;); threadD.start(); threadA.start(); threadB.start(); threadC.start(); &#125; static class RunnerThread implements Runnable &#123;// private boolean flag = true; static int state = 0;//运行标志 static Object lock = new Object(); public void run() &#123; String threadName = Thread.currentThread().getName();// while (flag) &#123;// synchronized (lock) &#123;// if (state % 4 == threadName.charAt(0) - 65) &#123;// state++;// flag = false;// System.out.println(threadName + &quot; run over&quot;);// &#125;// &#125;// &#125; synchronized (lock) &#123; while (state % 4 != threadName.charAt(0) - 65) &#123; try &#123; lock.wait(); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; state++; System.out.println(threadName+&quot; run over &quot;); lock.notifyAll(); &#125; &#125; &#125;&#125; 等待/通知范式做线程同步 是非常方便的。 解法3-循环获取锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package org.seckill.Thread;//wait/notifypublic class InOrderThread2 &#123; static int state = 0;//运行标志 static Object lock = new Object(); public static void main(String[] args) &#123; RunnerThread runnerThreadA = new RunnerThread(); RunnerThread runnerThreadB = new RunnerThread(); RunnerThread runnerThreadC = new RunnerThread(); RunnerThread runnerThreadD = new RunnerThread(); Thread threadA = new Thread(runnerThreadA, &quot;A&quot;); Thread threadB = new Thread(runnerThreadB, &quot;B&quot;); Thread threadC = new Thread(runnerThreadC, &quot;C&quot;); Thread threadD = new Thread(runnerThreadD, &quot;D&quot;);// RunnerThread runnerThread = new RunnerThread();// Thread threadA = new Thread(runnerThread, &quot;A&quot;);// Thread threadB = new Thread(runnerThread, &quot;B&quot;);// Thread threadC = new Thread(runnerThread, &quot;C&quot;);// Thread threadD = new Thread(runnerThread, &quot;D&quot;); threadD.start(); threadA.start(); threadB.start(); threadC.start(); &#125; static class RunnerThread implements Runnable &#123; private boolean flag = true;//每个线程的私有变量// static int state = 0;//运行标志// static Object lock = new Object(); public void run() &#123; String threadName = Thread.currentThread().getName(); while (flag) &#123;//主动循环加锁 synchronized (lock) &#123; if (state % 4 == threadName.charAt(0) - 65) &#123; state++; flag = false; System.out.println(threadName + &quot; run over&quot;); &#125; &#125; &#125;//// synchronized (lock) &#123;// while (state % 4 != threadName.charAt(0) - 65) &#123;// try &#123;// lock.wait();// &#125;catch (InterruptedException e)&#123;// e.printStackTrace();// &#125;// &#125;// state++;// System.out.println(threadName+&quot; run over &quot;);// lock.notifyAll();// &#125; &#125; &#125;&#125; 开销是极大的、难以确保及时性 解法4-CountDownLatch12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package org.seckill.Thread;import java.util.concurrent.CountDownLatch;public class InOrderThread3 &#123;// static int state = 0;//运行标志// static Object lock = new Object(); public static void main(String[] args) throws InterruptedException&#123; CountDownLatch countDownLatchA = new CountDownLatch(1); CountDownLatch countDownLatchB = new CountDownLatch(1); CountDownLatch countDownLatchC = new CountDownLatch(1); CountDownLatch countDownLatchD = new CountDownLatch(1); RunnerThread runnerThreadA = new RunnerThread(countDownLatchA); RunnerThread runnerThreadB = new RunnerThread(countDownLatchB); RunnerThread runnerThreadC = new RunnerThread(countDownLatchC); RunnerThread runnerThreadD = new RunnerThread(countDownLatchD); Thread threadA = new Thread(runnerThreadA, &quot;A&quot;); Thread threadB = new Thread(runnerThreadB, &quot;B&quot;); Thread threadC = new Thread(runnerThreadC, &quot;C&quot;); Thread threadD = new Thread(runnerThreadD, &quot;D&quot;);// RunnerThread runnerThread = new RunnerThread();// Thread threadA = new Thread(runnerThread, &quot;A&quot;);// Thread threadB = new Thread(runnerThread, &quot;B&quot;);// Thread threadC = new Thread(runnerThread, &quot;C&quot;);// Thread threadD = new Thread(runnerThread, &quot;D&quot;); threadA.start(); countDownLatchA.await();//主线程阻塞，待countDownLatch 减为0即可继续向下运行 threadB.start(); countDownLatchB.await(); threadC.start(); countDownLatchC.await(); threadD.start(); countDownLatchD.await(); System.out.println(Thread.currentThread().getName()+&quot; run over &quot;); &#125; static class RunnerThread implements Runnable &#123;// private boolean flag = true;// static int state = 0;//运行标志// static Object lock = new Object(); CountDownLatch countDownLatch; RunnerThread(CountDownLatch countDownLatch)&#123; this.countDownLatch = countDownLatch; &#125; public void run() &#123; String threadName = Thread.currentThread().getName(); System.out.println(threadName+&quot; run over&quot;); countDownLatch.countDown();// while (flag) &#123;// synchronized (lock) &#123;// if (state % 4 == threadName.charAt(0) - 65) &#123;// state++;// flag = false;// System.out.println(threadName + &quot; run over&quot;);// &#125;// &#125;// &#125;//// synchronized (lock) &#123;// while (state % 4 != threadName.charAt(0) - 65) &#123;// try &#123;// lock.wait();// &#125;catch (InterruptedException e)&#123;// e.printStackTrace();// &#125;// &#125;// state++;// System.out.println(threadName+&quot; run over &quot;);// lock.notifyAll();// &#125; &#125; &#125;&#125; countDownLatch 的使用场景 ：比如系统完全开启需要等待系统软件全部运行之后才能开启。最终的结果一定是发生在子(部分)结果完成之后的。也可作为线程同步的一种方式Thread join() 源码12345public final synchronized void join() throws InterruptedException &#123; while (isAlive) &#123; wait(0); &#125;&#125; 当被调用thread.join() 的线程(thread)终止运行时,会调用自身的notifyAll()方法，会通知所有等待该线程对象上完成运行的线程，可以看到join方法的逻辑结构与等待/通知经典范式一致，即加锁、循环、处理逻辑3个步骤。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>线程间通信、wait()、notify()</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 数据库规范--索引篇]]></title>
    <url>%2F2018%2F06%2F11%2FMySQL%E9%83%A8%E9%97%A8%E5%9F%B9%E8%AE%AD%EF%BC%8D%E7%B4%A2%E5%BC%95%E7%AF%87%2F</url>
    <content type="text"><![CDATA[章节目录 MySQL索引学习路径 MySQL索引介绍 索引分类 索引建立技巧 小试牛刀-索引使用预判 explain工具使用 1.MySQL索引学习路径 2.MySQL索引介绍 3.索引分类参考 MySQL数据库索引原理与分 https://www.jianshu.com/p/e1dce41a6b2b 聚簇索引&amp;非聚簇索引 唯一索引 覆盖索引 联合索引 索引建立技巧 小试牛刀上述查询语句的经过查询优化器的解析生成的查询计划 会使用到 idx_abcd 索引中所有字段。 explain工具参考 索引建立与注意事项 https://www.jianshu.com/p/aedf4c0972e8]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>索引篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 数据库规范--入门篇]]></title>
    <url>%2F2018%2F06%2F11%2FMysql%E9%83%A8%E9%97%A8%E5%9F%B9%E8%AE%AD%EF%BC%8D%E5%85%A5%E9%97%A8%E7%AF%87%2F</url>
    <content type="text"><![CDATA[前言: 为规范内部MySQL数据库开发流程,所以准备了如下培训教程，现将之前的培训PPT分享出来。当前入门篇为理论知识部分。 章节目录 MySQL学习路径 MySQL介绍 MySQL基础架构 MySQL存储引擎 1.MySQL学习路径 2.MySQL介绍 3.MySQL基础架构 基础架构-逻辑层详解 MySQL查询过程 4.MySQL 存储引擎 存储引擎－InnoDB 存储引擎－MyISAM]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>入门篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程基础-理解中断]]></title>
    <url>%2F2018%2F06%2F11%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80-%E7%90%86%E8%A7%A3%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[章节 什么是中断 中断线程的方法 线程中断状态的判断以及何时被中断的线程所处 isInterrupted() 状态为 false？ 1.什么是中断线程标识位1中断可以理解为线程的一个标识位属性，它标识一个运行中的线程是否被其他线程进行了中断操作。 2.中断线程的方法12其他线程通过调用该线程的 interrupt() 方法对其进行中断操作。其实就是其他线程对该线程打了个招呼，要求其中断。 3. 线程中断状态的判断1线程通过方法isInterrupted()方法来进行判断是否被中断。 如下两种情况需要注意： 1.如果被中断的线程已经处于终结状态，那么调用该线程对象的 thread.isInterrupted() 返回的仍是 false。2.在Java API中可以看到，许多抛出 InterruptedException 的方法，（其实线程已经终结了，因为遇到了异常）如Thread.sleep( long mills) 方法）这些方法在抛出InterruptedException 异常之前，JVM会将中断标识位清除，然后抛出InterruptedException，此时调用isInterrupted()仍会返回false。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package org.seckill.Thread;import java.util.concurrent.TimeUnit;public class Interrupted &#123; public static void main(String[] args) throws InterruptedException&#123; Thread sleepThread = new Thread(new SleepRunner(),&quot;sleepRunner&quot;); sleepThread.setDaemon(true);//支持性线程 Thread busyThread = new Thread(new BusyRunner(),&quot;busyRunner&quot;); busyThread.setDaemon(true); sleepThread.start(); busyThread.start(); TimeUnit.SECONDS.sleep(5); sleepThread.interrupt(); busyThread.interrupt(); System.out.println(&quot;sleep Thread interrupted status is:&quot;+sleepThread.isInterrupted()); System.out.println(&quot;busy Thread interrupted status is:&quot;+busyThread.isInterrupted()); SleepUnit.second(500); &#125; /** * 沉睡中的线程-静态内部类 */ static class SleepRunner implements Runnable &#123; public void run() &#123; while (true) &#123; SleepUnit.second(10); &#125; &#125; &#125; /** * 不停运行，空耗cpu的线程-静态内部类 */ static class BusyRunner implements Runnable &#123; public void run() &#123; while (true) &#123; &#125; &#125; &#125; /** * 静态内部工具类 */ static class SleepUnit &#123; public static void second(int seconds) &#123; try &#123; TimeUnit.SECONDS.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 运行结果：我们可以发现 sleep线程的 isInterrupted 状态为false，其中断标识位被清除了。busy 线程属于正常中断所以isInterrupted 状态为 true,中断标识位没有被清除。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>理解中断</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程基础-线程简介]]></title>
    <url>%2F2018%2F06%2F11%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80-%E7%BA%BF%E7%A8%8B%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[章节目录 1.线程定义 2.使用多线程的优势 3.线程优先级 4.线程的状态 5.Daemon 线程 1.线程定义进程与线程的区别121.进程是cpu进行资源分配的独立单位，指的是程序在数据集合上的一次运行过程。2.线程是cpu 进行调度的最小单位，在一个进程中会创建多个线程。 线程拥有的独立资源12栈中数据是线程独享的，包括局部变量、程序计数器等堆中数据是线程共享的，如线程同时操作堆中某对象的某属性。 Java程序运行的实质1一个程序的运行不仅仅是main()方法的运行，而是main线程和多个其他线程共同运行 2.使用多线程的优势1.充分利用更多的处理核心2.更快的响应时间12345 例如，一笔订单的创建，它包括插入订单数据，生成订单快照，发送邮件通知买家和记录货品销售数量等， 用户从单击“订购按钮&quot; 开始，就要等待这些操作全部完成才能看到订购成功的结果，但是这么多的业务操作，如何才能够跟快的完成？ 在上面的场景中,我们可以使用多线程技术，即将数据一致性不强的操作派发给其他线程处理，好处是响应用户请求的线程能更快的处理完成，缩短了响应时间，提升了用户体验。 3.线程优先级thread.setPriority(10),线程优先级从1-10顺序排列 4.线程的状态Java线程在运行的声明周期中可能处于如下表所示的6中状态，在给定的一个时刻，线程只能处于其中一个状态。 状态名称 说明 new 初始状态，线程被构建，但是还没有调用start()方法 runnable 运行状态，Java线程将操作系统中的就绪与运行两种状态统称为”运行中” block 阻塞状态，表示线程等待资源可用，如i/o 或者阻塞于锁 waiting 等待状态，表示线程进入等待状态，进入该状态表示当前线程需要等待其他线程做出一些特定动作(通知或中断) time_waiting 超时等待状态，该状态不同于waiting,它是可以在指定的时间自行返回的 terminated 终止状态，表示当前线程执行完毕 如下图所示，为java线程状态变迁图: 1.线程创建之后，调用start()方法，状态变更为可运行状态，待资源准备就绪后，开始运行。2.线程执行 lockObject.wait() 方法,线程进入等待状态。3.进入等待状态的线程依靠其他线程的通知才能返回到运行状态。4.超时等待相当于在等待状态基础上增加超时限制，超时时间到达会自动返回到运行状态。5.线程调用同步方法，在没有获取锁的情况下，线程会进入到阻塞状态。6.线程在执行Runable 的run()方法后，进入终止状态。 Daemon线程支持性线程，被用作程序中后台调度以及支持性工作。当一个Java虚拟机中不存在非Daemon线程时，JVM将退出。可以通过调用Thread.setDaemon(true)将线程设置为Daemon线程。Daemon属性需要在启动线程前执行，不能在启动线程之后启动。 注意:Daemon线程被用作完成支持性工作，但在Java虚拟机退出时，Daemon线程中的finally不一定会执行。如下代码所示：123456789101112public class Daemon &#123; static class DaemonRunner implements Runnable &#123; public void run()&#123; try&#123; TimeUnit.Second.sleep(10);//沉睡10s &#125;finally&#123; System.out.println(&quot;Daemon thread finally run&quot;);//执行类似资源回收动作 &#125; &#125; &#125;&#125; 当JVM中已经没有非Daemon线程，虚拟机就要退出。JVM中所有Daemon线程需要立即终止，因此finally块并没有执行。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>线程简介</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx特性-常用操作命令]]></title>
    <url>%2F2018%2F06%2F11%2FNginx-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-ab%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[章节目录 1.nginx 性能优化的点 2.当前系统性能的评估 3.ab 压力测试工具使用 1.nginx 性能优化的点当前系统结构瓶颈12可用方案：观察指标-top、压力测试-substatus、线上系统可以支撑的并发。清除当前架构、当前业务，每个服务可以支撑多少并发,多少QPS。 了解业务模式1接口业务类型、系统层次化结构 是代理、动静分离、业务服务器？ 性能与安全 2.当前系统性能的评估系统监测、日志分析 ab接口压力测试 业务量还没有大幅度增长之前，就需要对接口的响应能力做一个压测，防止业务量增加的时候出现问题。 ab接口压力测试工具在评估好当前业务的系统压力需求情况下面，工具检测当前的系统负载能力是否能满足对应的压力测试需求。 3.ab 接口压力测试工具使用安装1yum install httpd-tools 使用1234ab -n 1000 -c 100 http://www.baidu.com/-n 总的请求数-c 并发数-k 是否开启长连接 实战演示1.请求静态页面 http://eshop-cache04:82/test_proxy.html1ab -n 1000 -c 100 http://eshop-cache04:82/test_proxy.html -n 1000 总请求数1000-c 100 单个时刻并发数100资源： http://eshop-cache04:82/test_proxy.html测验结果]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>服务器中间件</tag>
        <tag>nginx-ab压力测试工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型-锁的内存语义.md]]></title>
    <url>%2F2018%2F06%2F11%2FJava%20%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B-%E9%94%81%E7%9A%84%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89%2F</url>
    <content type="text"><![CDATA[章节目录 1.锁的释放-获取建立的 happens-before 关系 2.锁的释放-获取的内存语义 1.锁的释放-获取 建立的happens-before 关系 锁是Java并发编程中最重要的同步机制。锁除了让临界区互斥执行之外，还可以让释放锁的线程向获取同一个锁的线程发送消息。 如下所示，下面是锁释放-锁获取的示例代码1234567891011class MonitorExample &#123; int a = 0; public synchronized void writer() &#123; //1 a++; //2 &#125; //3 public synchronized void reader()&#123; //4 int i = a; //5 .... //6 &#125;&#125; 假设线程A执行writer()方法，随后线程执行reader()方法。根据happens-before 规则，这个过程包含happens-before 关系可以分为3类：12341.程序次序规则，1 happens-before 2，2 happens-before 3；4 happens before 5,5 happens-before 62.根据监视器锁规则，3 happens-before 43.根据happens-before 的传递性，2 happens-before 5 如下图所示，为锁的释放与锁的获取的happens-before 关系图 2.锁的释放-获取的内存语义线程释放锁的内存语义1当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中 线程 获取锁的内存语义12当线程获取锁时，JMM会将该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。 volatile 写-读内存语义 &amp; 锁释放与获取的内存语义1234volatile 写-读内存语义 &amp; 锁释放与获取的内存语义 是相同的1.线程A释放一个锁，即线程A向接下来获取这个锁的某个线程发送（A线程对共享变量做修改的）消息。2.线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量做修改）的消息。3.线程A释放锁，随后线程B获取锁，这个过程实质上是线程A通过主内存向线程B发送消息。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>锁的内存语义</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型-volatile内存语义.md]]></title>
    <url>%2F2018%2F06%2F11%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B-volatile%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89%2F</url>
    <content type="text"><![CDATA[章节目录 1.volatile 的特性 为什么volatile修饰变量的写操作不是原子性的？ 2.volatile 写-读建立的 happens-before 关系 3.volatile 写-读的内存语义 1.volatile 的特性首先应该明确的一点是：当声明共享变量为volatile后，对这个变量的读/写(分为单元素读写，与复合写操作)。不同的读写模式下，volatile变量对写操作的原子性体现是不一样的。 理解volatile特性的一个好办法是把对volatile变量的单个读/写，看成是同一个锁对这些单个读/写操作做了同步，示例代码如下所示：1234567891011121314class VolatileFeaturesExample &#123; volatile long vl = 0L; public void set(long l)&#123; vl = l; &#125; public void getAndIncrement() &#123; vl++; &#125; public long get()&#123; return vl; &#125;&#125; 假设有多个线程调用上述程序中的3个方法，这个程序语义和下面的程序语义等价12345678910111213141516class VolatileFeaturesExample &#123; long vl = 0L; public synchronized void set(long l)&#123; vl = l; &#125; public void getAndIncrement() &#123; long temp = get(); temp +=1L; set(temp); &#125; public syntronized long get()&#123; return vl; &#125;&#125; 解释 如这两个程序所示，一个volatile 变量的单个读/写操作，与一个普通变量的读/写操作都是使用同一个锁来同步，他们之间的执行效果相同。 锁的happens-before规则(保证前一个操作结果对后一个操作立即可见)保证释放锁和获取锁的两个线程之间的内存可见性。这很好的解释了对于一个volatile变量的读，总能看到任意线程对这个volatile变量最后的写入。 锁的语义决定了临界代码区的执行具有原子性。这意味着，即使是64位的long型和double型变量，只要它是volatile变量，对该变量的单个读/写就具有原子性，如果是多个volatile操作，或这是volatile++这种复合操作，这些操作在整体上是不具有原子性的。 volatile 自身特性：12341.内存可见性：对一个volatile变量的读，总能看到任意线程对这个volatile变量 最后的写入（内存可见性保证）2.原子性：对任意单个volatile变量的单独的读写操作，都具有原子性。但对于 volatile++这种复合操作不具有原子性。 2.volatile 写-读建立的 happens-before 关系JMM基于共享内存模型实现线程之间的通信1从jdk1.5 开始 volatile 变量的写-读可以实现线程之间的通信。 volatile &amp; synchronized内存语义12从内存语义来说，volatile的写-读与锁的释放-获取有相同的内存效果：volatile写和锁释放有相同的内存语义；volatile读与锁的获取有相同的内存语义。 下面为volatile变量示例代码：12345678910111213141516class VolatileExample &#123; int a = 0;//其实是线程共享变量 volatile boolean flag = false; public void writer()&#123; a = 1; //1 flag = true; //2 &#125; public void reader()&#123; if(flage)&#123; //3 int i = a; //4 ...... &#125; &#125;&#125; 假设线程A 执行 writer() 方法之后，线程B 执行reader() 方法。根据happens-before 规则，这个过程建立的happens-before规则可以分为三类：1.根据程序次序规则，1 happens before 2;3 happens before 4.2.根据volatile规则，2 happens-before 33.根据happens-before c传递性规则 1 happens-before 4 图形化形势如下图所示： A线程在写一个volatile变量后，B线程读同一个volatile变量。A线程在写volatile之前所有的可见共享变量，在B线程读到同一个volatile变量之后，将立即变得对B线程可见。 4. volatile 写-读的内存语义 volatile 写内存语义 1当写一个volatile变量时，JMM会把该线程对应的本地内存的变量中的变量值强制刷新到主内存。 volatile 读的内存语义1当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 volatile内存语义 总结 线程A 写一个volatile 变量，实质上是线程A 向接下来读取这个volatile变量的某个线程发出了(其对共享变量所做修改的)消息。 线程B 读一个volatile 变量，实质上是线程B 接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改）消息。 线程A 写一个volatile 变量，随后线程B读这个volatile变量。这个过程实质上是线程A通过主内存向线程B发送消息。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java高并发秒杀业务Api-系统优化]]></title>
    <url>%2F2018%2F05%2F12%2FJava-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%A7%92%E6%9D%80-%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%EF%BC%88%E9%87%8D%E8%A6%81%EF%BC%89%2F</url>
    <content type="text"><![CDATA[章节目录 秒杀系统请求流程图 系统性能瓶颈分析与优化思路 1.秒杀系统请求流程图如上图所示：红色部分表示系统可能发生高并发的点12341.用户并发请求秒杀商品详情页信息2.用户并发获取系统时间3.用户并发请求地址暴露接口4.执行秒杀操作 详情页与动态请求的关系 2.系统瓶颈分析与优化2.1 CDN的理解1234CDN(内容分发网络)，加速用户获取数据的系统部署在离用户最近的网络节点上命中CDN不需要访问后端服务器,减轻后端服务器的压力，对用户快速响应。互联网公司自己搭建或者租用 2.2 获取系统时间 2.3 秒杀地址接口分析 2.4秒杀操作优化分析 还有一个问题是，一行数据竞争：热点商品，大量更新请求竞争更新同一行数据。 2.5 其他方案分析 2.6 为什么不用 mysql 解决 是什么让mysql低效 瓶颈分析gc一般持续40-50ms 优化方向-减少行级锁持有时间 延迟分析延迟分析很关键系统并发越高，垃圾回收会越频繁。异地机房 如何判断Update更新库存成功121.update没有报错2.客户端确认update影响行数 把SQL全部放置在mysql上执行会更快。减少java 客户端GC以及通信之间的网络干扰。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>秒杀</tag>
        <tag>MVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java高并发秒杀Api-web-层]]></title>
    <url>%2F2018%2F05%2F12%2FJava%E9%AB%98%E5%B9%B6%E5%8F%91%E7%A7%92%E6%9D%80Api-web-%E5%B1%82%2F</url>
    <content type="text"><![CDATA[##章节目录 前端交互设计 Restful Spring MVC理论 整合配置MVC框架 bootstrap+jquery 前端交互设计 Restful接口什么是Restful Restful 是接口设计规范 一种优雅的URI表达方式 资源的状态和状态转移 获取的是资源的状态，删除的时候，其实是更改资源的状态 put、post、delete Restful示例 不同的请求方法代表着对资源的不同操作类型。操作类型应与资源的接下来发生的状态状态转移对应起来 GET 请求是幂等性的 URL设计 Spring MVC理论理论部分围绕handler开发 Spring mvc 的运行流程解释：用户请求-&gt;前端控制器-&gt;寻找对应处理请求的handler，默认为DefaultAnnotationHandlerMapping-&gt;DefaultAnnotationHandlerAdapter-&gt;寻找处理请求的Controller-&gt;请求生成ModelAndView至中央控制器-&gt;中央控制器将数据转发给InternalResourceViewResolver去解析-&gt;解析完成的数据及页面结构，组合后，被生成资源，返回给用户。 HTTP请求映射的原理默认使用DefaultAnnotationHandlerMapping-&gt;handler方法 注解映射技巧 @RequestMapping 注解(1) 支持标准标准的URL(2) Ant风格URL(3) 带{xxx}占位符的URL 请求方法细节处理(1) 请求参数绑定(2) 请求方式限制(3) 请求转发与重定向(4) 数据模型赋值(5) 返回json数据(6) cookie的访问 整合配置Spring MVC配置文件1234567891011121314151617181920212223242526272829&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot; metadata-complete=&quot;true&quot;&gt; &lt;!-- 修改servlet版本为3.1 --&gt; &lt;!-- 配置DispatcherServlet--&gt; &lt;servlet&gt; &lt;servlet-name&gt;seckill-dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 配置SpringMVC需要加载的配置文件 Spring-dao.xml, spring-service.xml, spring-web.xml MyBatis -&gt; Spring -&gt; SpringMVC --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/spring-*.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;seckill-dispatcher&lt;/servlet-name&gt; &lt;!-- 默认匹配所有的请求--&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; Spring MVC 配置 spring-web.xml123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd&quot;&gt; &lt;!--配置Spring MVC--&gt; &lt;!--1:开启Spring MVC注解模式--&gt; &lt;!--简化配置 (1):自动注册DefaultAnnotationHandlerMapping、AnnotationMethodHandlerAdapter url-&gt;handler 映射 (2):默认提供一系列功能、数据绑定、数字与日期format @NumberFormat @DateTimeFormat xml json 默认读写支持 --&gt; &lt;mvc:annotation-driven/&gt; &lt;!--servlet-mapping 映射路径 /--&gt; &lt;!--静态资源配置，默认servlet配置--&gt; &lt;!-- 1:加入对静态资源的处理：js、png 2:允许使用&quot;/&quot;作为映射 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!--配置jsp 显示 view Resolver--&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.JstlView&quot;/&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt; &lt;/bean&gt; &lt;!--扫描web相关的bean--&gt; &lt;context:component-scan base-package=&quot;org.seckill.web&quot;/&gt;&lt;/beans&gt; SecKillController 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package org.seckill.web;import org.seckill.domain.SecKill;import org.seckill.dto.Exposer;import org.seckill.dto.SecKillResult;import org.seckill.service.SecKillService;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.ResponseBody;import java.util.List;@Controller@RequestMapping(&quot;/seckill&quot;) //url:/模块/资源/&#123;id&#125;/细分public class SecKillController &#123; private final Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private SecKillService secKillService; /** * 获取秒杀商品list * * @param model * @return */ @RequestMapping(value = &quot;/list&quot;, method = RequestMethod.GET) public String list(Model model) &#123; //1.获取列表页面 List&lt;SecKill&gt; secKillList = secKillService.getSecKillList(); model.addAttribute(&quot;list&quot;, secKillList); //2.返回页面并携带model 数据list.jsp + model = ModelAndView return &quot;list&quot;; &#125; /** * 接收参数、参数验证、业务逻辑调用并处理 * 获取秒杀商品详情 * * @param model * @param secKillId * @return */ @RequestMapping(value = &quot;/&#123;secKillId&#125;/detial&quot;, method = RequestMethod.GET) public String detial(Model model, @PathVariable(&quot;secKillId&quot;) Long secKillId) &#123; if (secKillId == null) &#123;//请求重定向到list页面 return &quot;redirect:/seckill/list&quot;; &#125; SecKill secKill = secKillService.getSecKillById(secKillId); if (secKill == null) &#123; return &quot;forward:/seckill/list&quot;; &#125; model.addAttribute(&quot;seckill&quot;, secKill); return &quot;detial&quot;; &#125; /** * ajax接口-返回类型 json * 获取秒杀曝露地址 * * @param secKillId */ @RequestMapping(value = &quot;/&#123;secKillId&#125;/exposer&quot;, method = RequestMethod.POST, produces = &#123;&quot;application/json;charset=UTF-8&quot;&#125;//告诉浏览器返回数据类型是json ) @ResponseBody public SecKillResult&lt;Exposer&gt; /*TODO*/ exposer(@PathVariable(&quot;secKillId&quot;) Long secKillId) &#123; SecKillResult&lt;Exposer&gt; result; try &#123; Exposer exposer = secKillService.exportSecKillUrl(secKillId);//返回秒杀地址 result = new SecKillResult&lt;Exposer&gt;(true, exposer); &#125; catch (Exception e) &#123; logger.error(e.getMessage()); result = new SecKillResult&lt;Exposer&gt;(false, e.getMessage()); &#125; return result; &#125;&#125;]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>秒杀</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java高并发秒杀Api-业务分析与DAO层构建3]]></title>
    <url>%2F2018%2F05%2F12%2FJava%E9%AB%98%E5%B9%B6%E5%8F%91%E7%A7%92%E6%9D%80Api-%E4%B8%9A%E5%8A%A1%E5%88%86%E6%9E%90%E4%B8%8EDAO%E5%B1%82%E6%9E%84%E5%BB%BA3%2F</url>
    <content type="text"><![CDATA[章节目录 mybatis与spring整合过程 spring-dao.xml 配置 junit4 单元测试 1.mybatis与spring整合过程1.1 spring-dao.xml 配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!--配置整合mybatis--&gt; &lt;!--1:配置数据库相关参数--&gt; &lt;!-- 1:配置数据库相关参数properties的属性:$&#123;url&#125; --&gt; &lt;context:property-placeholder location=&quot;classpath:jdbc.properties&quot;/&gt; &lt;!--2.数据库连接池配置--&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt; &lt;!-- 配置连接池属性--&gt; &lt;property name=&quot;driverClass&quot; value=&quot;$&#123;driver&#125;&quot; /&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;$&#123;url&#125;&quot; /&gt; &lt;property name=&quot;user&quot; value=&quot;$&#123;username&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;password&#125;&quot; /&gt; &lt;!-- c3p0连接池的私有属性--&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;30&quot; /&gt; &lt;property name=&quot;minPoolSize&quot; value=&quot;10&quot; /&gt; &lt;!-- 关闭连接后不自动commit--&gt; &lt;property name=&quot;autoCommitOnClose&quot; value=&quot;false&quot; /&gt; &lt;!-- 获取连接超时时间 30个连接用完--&gt; &lt;property name=&quot;checkoutTimeout&quot; value=&quot;1000&quot; /&gt; &lt;!-- 当获取连接失败重试次数--&gt; &lt;property name=&quot;acquireRetryAttempts&quot; value=&quot;2&quot; /&gt; &lt;/bean&gt; &lt;!-- 约定大于配置--&gt; &lt;!-- 3:配置SqlSessionFactory对象--&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;!-- 注入数据库连接池--&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;!-- 配置MyBatis全局配置文件：mybatis-config.xml--&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot; /&gt; &lt;!-- 扫描entity包 使用别名--&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;org.seckill.domain&quot; /&gt; &lt;!-- 扫描sql配置文件；mapper需要的xml文件--&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:mapper/*.xml&quot; /&gt; &lt;/bean&gt; &lt;!--配置扫描Dao接口包，动态实现Dao接口 mapper 代理，并注入到Spring容器中 MapperScannerConfigurer--&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;!--注入sqlSessionFactory,懒加载，用到的时候才加载--&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;&gt;&lt;/property&gt; &lt;!--给出扫描DAO接口包--&gt; &lt;property name=&quot;basePackage&quot; value=&quot;org.seckill.dao&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 2.junit 单元测试SecKillDaoTest.java - 测试秒杀1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package org.seckill.dao;import org.junit.Test;import org.junit.runner.RunWith;import org.seckill.domain.SecKill;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import java.util.Date;import java.util.List;/** * 配置spring 与 junit 启动时加载Spring IOC容器 * spring-test,junit整合 * 告诉junit Spring配置文件位置 */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&#123;&quot;classpath:spring/spring-dao.xml&quot;&#125;)public class SecKillDaoTest &#123; //注入Dao类实现 @Autowired private SecKillDao secKillDao; @Test public void queryById() throws Exception &#123; long id = 1000; SecKill secKill = secKillDao.queryById(id); System.out.println(secKill.getName()); System.out.println(secKill); /** * 1000元秒杀iphone x SecKill&#123;seckillId=1000, name=&apos;1000元秒杀iphone x&apos;, stock=100, startTime=Fri May 04 00:00:00 CST 2018, endTime=Sat May 05 00:00:00 CST 2018, createTime=Sat May 05 00:05:03 CST 2018 &#125; */ &#125; /** * @throws Exception */ @Test public void queryAll() throws Exception &#123; // queryAll(offset,limit)-&gt;queryAll(arg0,arg1) List&lt;SecKill&gt; secKillList = secKillDao.queryAll(0, 100); for (SecKill secKill : secKillList) &#123; System.out.println(secKill); &#125; /** * SecKill&#123;seckillId=1000, name=&apos;1000元秒杀iphone x&apos;, stock=100, startTime=Fri May 04 00:00:00 CST 2018, endTime=Sat May 05 00:00:00 CST 2018, createTime=Sat May 05 00:05:03 CST 2018&#125; SecKill&#123;seckillId=1001, name=&apos;500元秒杀ipad x&apos;, stock=200, startTime=Fri May 04 00:00:00 CST 2018, endTime=Sat May 05 00:00:00 CST 2018, createTime=Sat May 05 00:05:03 CST 2018&#125; SecKill&#123;seckillId=1002, name=&apos;300元秒杀小米4&apos;, stock=300, startTime=Fri May 04 00:00:00 CST 2018, endTime=Sat May 05 00:00:00 CST 2018, createTime=Sat May 05 00:05:03 CST 2018&#125; SecKill&#123;seckillId=1003, name=&apos;200元秒杀小米note&apos;, stock=400, startTime=Fri May 04 00:00:00 CST 2018, endTime=Sat May 05 00:00:00 CST 2018, createTime=Sat May 05 00:05:03 CST 2018&#125; */ &#125; @Test public void reduceStock() throws Exception &#123; Date killTime = new Date(); int updateCount = secKillDao.reduceStock(1000L, killTime); System.out.println(updateCount); &#125;&#125; 测试秒杀明细1234567891011121314151617181920212223242526272829303132package org.seckill.dao;import org.junit.Test;import org.junit.runner.RunWith;import org.seckill.domain.SuccessKilled;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&quot;classpath:spring/spring-dao.xml&quot;)public class SuccessKilledDaoTest &#123; @Autowired private SuccessKilledDao successKilledDao; @Test public void insertSuccessKilled() throws Exception &#123; int successCount = successKilledDao.insertSuccessKilled(1001L, &quot;15300815999&quot;); System.out.println(&quot;insertCount=&quot; + successCount); &#125; @Test public void queryByIdWithSecKill() throws Exception &#123; //1个用户只能查询到属于自己的一个秒杀明细 long id = 1001L; String phone = &quot;15300815999&quot;; SuccessKilled successKilled = successKilledDao.queryByIdWithSecKill(id, phone); System.out.println(successKilled); &#125;&#125; 接下来是service 层的构建]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>秒杀</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java高并发秒杀业务Api-Service层构建过程]]></title>
    <url>%2F2018%2F05%2F12%2FJava%E9%AB%98%E5%B9%B6%E5%8F%91%E7%A7%92%E6%9D%80%E4%B8%9A%E5%8A%A1Api-Service%E5%B1%82%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[章节目录 秒杀Service 接口开发工作 秒杀业务逻辑编写 spring-IOC 管理 service 组件 context:component-scan Spring 声明式事务 junit测试 创建基本的代码包层1.创建DTO - 数据传输层对象12网络数据到达Controller 层后会使用框架自带的数据绑定 以及反序列化为dto对象，并作为参数传递至service层进行处理。 2.业务接口实现注意：业务接口的实现需要站在使用者的角度去设计接口 方法定义粒度-非常明确，参数简练，直接，不要一个大map对象去传递，return 还可以抛出异常。 代码如下:业务逻辑接口声明类 SecKillService.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package org.seckill.service;import org.seckill.domain.SecKill;import org.seckill.dto.Exposer;import org.seckill.dto.SecKillExcution;import org.seckill.exception.RepeatKillException;import org.seckill.exception.SecKillCloseException;import org.seckill.exception.SecKillException;import java.util.List;/** * 业务接口的实现需要站在使用者的角度去设计接口 * 三个方面：方法定义粒度、参数、返回类型 dto就可以 */public interface SecKillService &#123; /** * 返回秒杀商品列表 * * @return */ List&lt;SecKill&gt; getSecKillList(); /** * 查询秒杀商品单条记录 * * @param secKillId * @return */ SecKill getSecKillById(long secKillId); /** * 秒杀开启时,输出秒杀接口的地址,否则输出系统时间,和秒杀时间 * * @param secKillId * @return */ Exposer exportSecKillUrl(long secKillId); /** * 执行秒杀操作 * 验证当前的excuteSecKill id 与 传递过来的md5是否相同 * * @param secKillId * @param userPhone * @param md5 */ SecKillExcution excuteSecKill(long secKillId, String userPhone, String md5) throws SecKillException, RepeatKillException, SecKillCloseException;&#125; 业务逻辑接口实现类-SecKillServiceImpl123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120package org.seckill.service.impl;import org.seckill.dao.SecKillDao;import org.seckill.dao.SuccessKilledDao;import org.seckill.domain.SecKill;import org.seckill.domain.SuccessKilled;import org.seckill.dto.Exposer;import org.seckill.dto.SecKillExcution;import org.seckill.enums.SecKillStateEnum;import org.seckill.exception.RepeatKillException;import org.seckill.exception.SecKillCloseException;import org.seckill.exception.SecKillException;import org.seckill.service.SecKillService;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.util.DigestUtils;import java.util.Date;import java.util.List;@Servicepublic class SecKillServiceImpl implements SecKillService &#123; //在业务逻辑层打日志 private Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowire private SecKillDao secKillDao; @Autowire private SuccessKilledDao successKilledDao; //md5加盐，混淆加密 private final String salt = &quot;asdasd8Zy*&amp;ZCY87ywer7t678tzt67wer&quot;; public List&lt;SecKill&gt; getSecKillList() &#123; return secKillDao.queryAll(0, 4); &#125; public SecKill getSecKillById(long secKillId) &#123; return secKillDao.queryById(secKillId); &#125; public Exposer exportSecKillUrl(long secKillId) &#123; SecKill secKill = secKillDao.queryById(secKillId); if (secKill == null) &#123; return new Exposer(false, secKillId);//没有相关产品的秒杀活动 &#125; Date startTime = secKill.getStartTime(); Date endTime = secKill.getEndTime(); Date nowTime = new Date(); if (nowTime.getTime() &lt; startTime.getTime() || nowTime.getTime() &gt; endTime.getTime()) &#123; return new Exposer(false, secKillId, nowTime.getTime(), startTime.getTime(), endTime.getTime());//没有相关产品的秒杀活动 &#125; //转化特定字符串的过程，不可逆 String md5 = null; return new Exposer(secKillId, md5, true); &#125; /** * 生成对应秒杀商品的md5值，做参数校验 * 保证可重用 * * @param secKillId * @return */ private String getMD5(long secKillId) &#123; String base = secKillId + &quot;/&quot; + salt;//用户不知道salt String md5 = DigestUtils.md5DigestAsHex(base.getBytes()); return md5; &#125; /** * 执行秒杀 * * @param secKillId * @param userPhone * @param md5 * @return * @throws SecKillException * @throws RepeatKillException * @throws SecKillCloseException */ public SecKillExcution excuteSecKill(long secKillId, String userPhone, String md5) throws SecKillException, RepeatKillException, SecKillCloseException &#123; try &#123; //1.用户输入的md5值验证 if (md5 == null || !md5.equals(getMD5(secKillId))) &#123; throw new SecKillException(&quot;seckill data rewrite&quot;); &#125; //2.减库存、执行秒杀逻辑+记录购买行为，执行秒杀时间 Date nowTime = new Date(); int updateCount = secKillDao.reduceStock(secKillId, nowTime); if (updateCount &lt;= 0) &#123; //没有更新到记录,秒杀结束 throw new SecKillCloseException(&quot;seckill is closed&quot;); &#125; else &#123; //3.记录购买行为 insertSuccessKilled 可能出现数据库连接超时等问题，所以需要外层try int insertCount = successKilledDao.insertSuccessKilled(secKillId, userPhone); //唯一验证，secKillId + userPhone if (insertCount &lt;= 0) &#123;//数据库联合主键冲突 throw new RepeatKillException(&quot;seckill repeated&quot;); &#125; else &#123;//秒杀成功，返回秒杀成功的实体 SuccessKilled successKilled = successKilledDao.queryByIdWithSecKill(secKillId, userPhone); //不优雅的实现方式，在多处需要用到提示信息时，我们可以采用统一的常量去返回，这样待客户端提示语改变时，我们可以统一进行更改。// return new SecKillExcution(secKillId, 1, &quot;秒杀成功&quot;, successKilled); return new SecKillExcution(secKillId, SecKillStateEnum.SUCCESS, successKilled); &#125; &#125; &#125; catch (SecKillCloseException e1) &#123; throw e1;//还是要回滚 &#125; catch (RepeatKillException e2) &#123; throw e2;//还是要回滚 &#125; catch (Exception e) &#123; logger.error(e.getMessage()); //所有异常最终会转化为 运行时异常，spring 的声明式事务会帮我们做rollback。 throw new SecKillException(&quot;seckill inner error&quot; + e.getMessage()); &#125; &#125;&#125; 数据传输层类- Exposer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293package org.seckill.dto;/** * 暴露秒杀接口 */public class Exposer &#123; private boolean exposed;//秒杀是否开启标志位 private String md5; //加密措施，暴露地址包括一个md5值 private long now; //系统当前时间(毫秒)，方便浏览器计算距离服务器秒杀开启时间 private long secKillId; //秒杀商品的id private long start; private long end; //秒杀正在进行 public Exposer(long secKillId, String md5, boolean exposed) &#123; this.secKillId = secKillId; this.md5 = md5; this.exposed = exposed; &#125; //秒杀结束或还没开启 public Exposer(boolean exposed, long secKillId, long now, long start, long end) &#123; this.exposed = exposed; this.secKillId = secKillId; this.now = now; this.start = start; this.end = end; &#125; //没有相关商品秒杀活动 public Exposer(boolean exposed, long secKillId) &#123; this.exposed = exposed; this.secKillId = secKillId; &#125; public boolean isExposed() &#123; return exposed; &#125; public void setExposed(boolean exposed) &#123; this.exposed = exposed; &#125; public String getMd5() &#123; return md5; &#125; public void setMd5(String md5) &#123; this.md5 = md5; &#125; public long getNow() &#123; return now; &#125; public void setNow(long now) &#123; this.now = now; &#125; public long getStart() &#123; return start; &#125; public void setStart(long start) &#123; this.start = start; &#125; public long getEnd() &#123; return end; &#125; public void setEnd(long end) &#123; this.end = end; &#125; public long getSecKillId() &#123; return secKillId; &#125; public void setSecKillId(long secKillId) &#123; this.secKillId = secKillId; &#125; @Override public String toString() &#123; return &quot;Exposer&#123;&quot; + &quot;exposed=&quot; + exposed + &quot;, md5=&apos;&quot; + md5 + &apos;\&apos;&apos; + &quot;, now=&quot; + now + &quot;, secKillId=&quot; + secKillId + &quot;, start=&quot; + start + &quot;, end=&quot; + end + &apos;&#125;&apos;; &#125;&#125; 数据传输层-SecKillExcution12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package org.seckill.dto;import org.seckill.domain.SuccessKilled;import org.seckill.enums.SecKillStateEnum;/** * 执行秒杀之后的结果 */public class SecKillExcution &#123; private long secKillId; private int state;//状态的标识 private String stateInfo;//状态表示 private SuccessKilled successSecKilled;//秒杀成功对象 //成功 jakson 在转化枚举的时候会出现问题，不支持枚举序列化 public SecKillExcution(long secKillId, SecKillStateEnum secKillStateEnum, SuccessKilled successSecKilled) &#123; this.secKillId = secKillId; this.state = secKillStateEnum.getState(); this.stateInfo = secKillStateEnum.getStateInfo(); this.successSecKilled = successSecKilled; &#125; //失败,使用到枚举 public SecKillExcution(long secKillId, SecKillStateEnum secKillStateEnum) &#123; this.secKillId = secKillId; this.state = secKillStateEnum.getState(); this.stateInfo = secKillStateEnum.getStateInfo(); &#125; public long getSecKillId() &#123; return secKillId; &#125; public void setSecKillId(long secKillId) &#123; this.secKillId = secKillId; &#125; public int getState() &#123; return state; &#125; public void setState(int state) &#123; this.state = state; &#125; public String getStateInfo() &#123; return stateInfo; &#125; public void setStateInfo(String stateInfo) &#123; this.stateInfo = stateInfo; &#125; public SuccessKilled getSuccessSecKilled() &#123; return successSecKilled; &#125; public void setSuccessSecKilled(SuccessKilled successSecKilled) &#123; this.successSecKilled = successSecKilled; &#125; @Override public String toString() &#123; return &quot;SecKillExcution&#123;&quot; + &quot;secKillId=&quot; + secKillId + &quot;, state=&quot; + state + &quot;, stateInfo=&apos;&quot; + stateInfo + &apos;\&apos;&apos; + &quot;, successSecKilled=&quot; + successSecKilled + &apos;&#125;&apos;; &#125;&#125; 业务运行时异常类-SecKillException、RepeatKillException、SecKillCloseException1234567891011121314package org.seckill.exception;/** * 秒杀相关业务异常 */public class SecKillException extends RuntimeException &#123; public SecKillException(String message) &#123; super(message); &#125; public SecKillException(String message, Throwable cause) &#123; super(message, cause); &#125;&#125; 12345678910111213141516package org.seckill.exception;/** * 重复秒杀的异常(运行时异常) * 声明式事务，只接收运行时异常 */public class RepeatKillException extends SecKillException &#123; public RepeatKillException(String message) &#123; super(message); &#125; public RepeatKillException(String message, Throwable cause) &#123; super(message, cause); &#125;&#125; 1234567891011121314package org.seckill.exception;/** * 秒杀关闭异常-友好响应给用户 */public class SecKillCloseException extends SecKillException &#123; public SecKillCloseException(String message) &#123; super(message); &#125; public SecKillCloseException(String message, Throwable cause) &#123; super(message, cause); &#125;&#125; spring-IOC管理 service 组件spring-service.xml 配置1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;!-- 扫描service包下所有使用注解的类型--&gt; &lt;context:component-scan base-package=&quot;org.seckill.service&quot; /&gt; &lt;!-- 配置事务管理器--&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;!-- 注入数据库连接池--&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;/bean&gt; &lt;!-- 配置基于注解的声明式事务 默认使用注解来管理事务行为 --&gt; &lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot; /&gt;&lt;/beans&gt; Spring 声明式事务什么是声明式事务底层原理：采用动态代理的方式为我们的事务核心逻辑添加开启事务、回滚提交事务的控制操作 声明式事务使用方式 推荐使用@Transactional 声明式事务的传播行为定义：即事务方法的嵌套一个业务需要调用多个声明了事务控制的方法，那么最新组合的事务是重新启动一个事务，还是说沿用老的事务呢？1234567891011121314151617默认的事务传播行为:propagation_required浅析如下：ServiceA &#123; void methodA() &#123; ServiceB.methodB(); &#125; &#125; ServiceB &#123; void methodB() &#123; &#125; &#125; 比如说ServiceB.methodB 事务传播行为定义为PROPAGATION_REQUIRED， 那么当ServiceA.methodA 调用 ServiceB.methodB 时，methodA起了新的事务，那么ServiceB.methodB看到自己已经运行在ServiceA.methodA的事务内部，就不再起新的事务。 而假如ServiceA.methodA运行的时候发现自己没有在事务中，他就会为自己分配一个事务。这样，在ServiceA.methodA或者在ServiceB.methodB内的任何地方出现异常，事务都会被回滚。即使ServiceB.methodB的事务已经被提交，但是ServiceA.methodA在接下来fail要回滚，ServiceB.methodB也要回滚 相当于 methodB 通过自己的事务传播行为告诉methodA 自己使用事务的原则，告诉methodA 你要有事务我methodB就用你的，如果methodA没有事务，那你methodA就需要创建一个事务。 什么时候回滚事务当业务方法抛出运行时异常(RuntimeException)的时候spring 事务管理器会进行commit 配置事务管理器123&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/bean&gt; 配置基于注解的声明式事务1&lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;/&gt; 使用注解控制事务方法的优点 开发团队达成一致约定，约定明确标注事务方法的编程风格 保证事务方法的执行时间尽可能的短，不要穿插其他的网络操作，RPC/HTTP请求，如果必须需要的话，那么将这些请求剥离出来，形成一个干净的方法调用。不要混合编写和外部系统进行网络通信的代码。 不是所有的方法都需要事务，select、insert操作，单条语句的insert、update都不需要事务操作、不需要并发控制&amp;多个操作联合形成一个事务时，不需要设置事务，因为mysql有autocommit=1的设置。 上述是性能杀手啊 ，注意再注意。 单元测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package org.seckill.service;import org.junit.Test;import org.junit.runner.RunWith;import org.seckill.domain.SecKill;import org.seckill.dto.Exposer;import org.seckill.dto.SecKillExcution;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import java.util.List;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&#123;&quot;classpath:spring/spring-dao.xml&quot;, &quot;classpath:spring/spring-service.xml&quot;&#125;)public class SecKillServiceTest &#123; private final Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private SecKillService secKillService; @Test public void getSecKillList() throws Exception &#123; List&lt;SecKill&gt; secKillList = secKillService.getSecKillList(); logger.info(&quot;list&#123;&#125;&quot;, secKillList); &#125; @Test public void getSecKillById() throws Exception &#123; long secKillId = 1000L; SecKill secKill = secKillService.getSecKillById(secKillId); logger.info(&quot;seckill&#123;&#125;&quot;, secKill); &#125; @Test public void exportSecKillUrl() throws Exception &#123; long secKillId = 1000L; Exposer exposer = secKillService.exportSecKillUrl(secKillId); logger.info(&quot;exposer&#123;&#125;&quot;, exposer); &#125; @Test public void excuteSecKill() throws Exception &#123; long secKillId = 1000L; String userPhone = &quot;15300815981&quot;; String md5 = &quot;6e3cc65f3b42e656bdbc55a6a381f5d0&quot;; SecKillExcution secKillExcution = secKillService.excuteSecKill(secKillId, userPhone, md5); logger.info(&quot;secKillExcution&#123;&#125;&quot;, secKillExcution); &#125;&#125; intellj idea 下单元测试快捷键：ctrl+shift+t]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>秒杀</tag>
        <tag>MVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java高并发秒杀Api-业务分析与DAO层构建2]]></title>
    <url>%2F2018%2F05%2F12%2FJava%E9%AB%98%E5%B9%B6%E5%8F%91%E7%A7%92%E6%9D%80Api-%E4%B8%9A%E5%8A%A1%E5%88%86%E6%9E%90%E4%B8%8EDAO%E5%B1%82%E6%9E%84%E5%BB%BA2%2F</url>
    <content type="text"><![CDATA[章节目录 DAO 设计编码 数据库设计与编码 DAO层实体和接口编码 基于mybatis实现DAO理论 基于mybatis实现DAO接口-1 mybatis整合Spring DAO层编码解析 Dao 设计编码1.pom.xml 引入项目依赖的包123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.seckill&lt;/groupId&gt; &lt;artifactId&gt;seckill&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;name&gt;seckill Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;!--使用注解方式运行junit--&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--补全项目依赖--&gt; &lt;!--日志--&gt; &lt;!--1.日志 java日志，slf4j,log4j,logback,common-logging--&gt; &lt;!--2. slf4j 是规范、接口 日志实现 log4j,logback,common-logging 使用slf4j+logback --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--实现slf4j接口并实现，直接通过slf4j来进行日志记录--&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--数据库依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.35&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!--数据库连接池--&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--dao层依赖:MyBatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis自身实现的spring依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;!--servlet web相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;taglibs&lt;/groupId&gt; &lt;artifactId&gt;standard&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--end java web 相关依赖--&gt; &lt;!--spring 依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring dao层依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring 声明式事务--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring web 相关依赖 servlet容器加载spring ioc spring aop 启动spring 的工厂--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--junit相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;seckill&lt;/finalName&gt; &lt;/build&gt;&lt;/project&gt; 2.数据库设计与编码数据库脚本如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041--数据库初始化脚本--创建数据库CREATE DATABASE seckill;--使用数据库use seckill;--创建秒杀库存表CREATE TABLE seckill( `seckill_id` bigint not null AUTO_INCREMENT COMMENT &apos;商品库存id&apos;, `name` VARCHAR (120) not null COMMENT &apos;商品名称&apos;, `stock` int not null COMMENT &apos;库存数量&apos;, `start_time` TIMESTAMP NOT NULL COMMENT &apos;秒杀开始时间&apos;, `end_time` TIMESTAMP NOT NULL COMMENT &apos;秒杀结束时间&apos;, `create_time` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;, PRIMARY KEY (seckill_id), key idx_start_time(start_time), key idx_end_time(end_time), key idx_create_time(create_time)) ENGINE=InnoDB AUTO_INCREMENT=1000 DEFAULT CHARSET=utf8 COMMENT=&apos;秒杀库存表&apos;;--初始化数据INSERT INTO seckill(name,stock,start_time,end_time)VALUES (&apos;1000元秒杀iphone x&apos;,&apos;100&apos;,&apos;2018-05-04 00:00:00&apos;,&apos;2018-05-05 00:00:00&apos;), (&apos;500元秒杀ipad x&apos;,&apos;200&apos;,&apos;2018-05-04 00:00:00&apos;,&apos;2018-05-05 00:00:00&apos;), (&apos;300元秒杀小米4&apos;,&apos;300&apos;,&apos;2018-05-04 00:00:00&apos;,&apos;2018-05-05 00:00:00&apos;), (&apos;200元秒杀小米note&apos;,&apos;400&apos;,&apos;2018-05-04 00:00:00&apos;,&apos;2018-05-05 00:00:00&apos;);--秒杀成功明细表CREATE TABLE success_killed( `seckill_id` bigint NOT NULL COMMENT &apos;秒杀商品id&apos;, `user_phone` VARCHAR(11) NOT NULL COMMENT &apos;用户手机号&apos;, `state` tinyint NOT NULL DEFAULT -1 COMMENT &apos;状态标志:-1:无效 0:成功 1:已付款&apos;, `create_time` TIMESTAMP NOT NULL COMMENT &apos;创建时间&apos;, PRIMARY KEY (seckill_id,user_phone),/*联合主键*/ key idx_create_time(create_time)) ENGINE=InnoDB AUTO_INCREMENT=1000 DEFAULT CHARSET=utf8 COMMENT=&apos;秒杀成功明细表&apos;;--连接数据库的控制台mysql -u root -p 3.DAO层实体与接口编码 3.1MyBatis 实现DAO接口的方式 Mapper自动实现DAO接口sql直接编写，注解sql(sql更改，原代码需要重新编译)，xml方式，单独更新sql,源文件不需要重新编译。 API 编程方式自动实现DAO 接口 3.2 基于mybatis实现DAO接口-1 全局mybatis-conf.xml 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;!--配置全局属性--&gt;&lt;configuration&gt; &lt;settings&gt; &lt;!-- changes from the defaults for testing --&gt; &lt;setting name=&quot;cacheEnabled&quot; value=&quot;false&quot; /&gt; &lt;!--使用jdbc 的getGeneratedKeys 获取数据库自增主键值--&gt; &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;true&quot; /&gt; &lt;!--使用列别名 替换列名 默认true 复制到对应的entity属性中 select name as tile from table --&gt; &lt;setting name=&quot;useColumnLable&quot; value=&quot;true&quot;/&gt; &lt;!--开启驼峰命名转化--&gt; &lt;setting name=&quot;mapUnderscoreCameCase&quot; value=&quot;true&quot;/&gt; &lt;!--REUSE 执行器会重用预处理语句--&gt; &lt;setting name=&quot;defaultExecutorType&quot; value=&quot;REUSE&quot; /&gt; &lt;/settings&gt;&lt;/configuration&gt; SecKillDao.xml编写 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;org.seckill.dao.SecKillDao&quot;&gt; &lt;!--目的：为DAO方法提供SQL语句配置 parameter-type不用给 #与$的区别 预编译 1.#&#123;&#125; 解析为一个 JDBC 预编译语句（prepared statement）的参数标记符。 会被解析为 ?占位符 动态SQL-会对SQL进行动态解析，解析为一个BoundSql对象 变量替换 2.$&#123;&#125; 仅仅为一个纯粹的 string 替换，在动态 SQL 解析阶段将会进行变量替换 3.#&#123;&#125;的变量的替换是在 DBMS 中。 4.$&#123;&#125; 在预编译之前已经被变量替换了，这会存在 sql 注入问题 5.表名是不能带&apos;&apos;号的，所以使用$&#123;&#125; 防止出现变量替换后表名带&apos;&apos; --&gt; &lt;update id=&quot;reduceStock&quot;&gt; &lt;!--具体sql--&gt; UPDATE seckill SET stock = stock - 1 WHERE seckill_id = #&#123;secKillId&#125; AND start_time &lt;![CDATA[&lt;=]]&gt; #&#123;killTime&#125; AND end_time &gt;= #&#123;killTime&#125; and stock &gt; 0 &lt;/update&gt; &lt;select id=&quot;queryById&quot; resultType=&quot;SecKill&quot; parameterType=&quot;long&quot;&gt; SELECT seckill_id as seckillId,name,stock,start_time,end_time,create_time from seckill where seckill_id = #&#123;secKillId&#125; &lt;/select&gt; &lt;select id=&quot;queryAll&quot; resultType=&quot;SecKill&quot; parameterType=&quot;int&quot;&gt; SELECT seckill_id as seckillId,name,stock,start_time,end_time,create_time from seckill order by create_time desc limit #&#123;offset&#125;,$&#123;limit&#125; &lt;/select&gt;&lt;/mapper&gt; SuccessKilledDao.xml 编写 123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;org.seckill.dao.SuccessKilledDao&quot;&gt; &lt;insert id=&quot;insertSuccessKilled&quot; &gt; &lt;!--如果出现重复，主键冲突，直接产生一个错误--&gt; INSERT ignore INTO success_killed(seckill_id,user_phone) VALUES (#&#123;secKillId&#125;,#&#123;userPhone&#125;) &lt;/insert&gt; &lt;select id=&quot;queryByIdWithSecKill&quot; resultType=&quot;SuccessKilled&quot; &gt; &lt;!--根据id查询SuccessKilled并携带SecKill实体--&gt; &lt;!--如何告诉mybatis 把结果映射到SuccessKilled的同时映射secKill 属性--&gt; &lt;!--可以自由控制SQL 优化等--&gt; SELECT sk.seckill_id, sk.user_phone, sk.create_time, sk.state, sc.seckill_id as &quot;secKill.seckill_id&quot;, sc.name as &quot;secKill.name&quot;, sc.stock as &quot;secKill.stock&quot;, sc.start_time as &quot;secKill.start_time&quot;, sc.end_time as &quot;sceKill.end_time&quot;, sc.create_time as &quot;secKill.create_time&quot; FROM success_killed sk INNER JOIN seckill sc on sk.seckill_id = sc.seckill_id WHERE sk.seckill_id = #&#123;secKillId&#125; &lt;/select&gt;&lt;/mapper&gt; entity实体层实现-SecKill、SuccessKilled 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package org.seckill.domain;import java.util.Date;/** * 秒杀-库存表 entity */public class SecKill &#123; private long seckillId; //秒杀-商品id private String name; //秒杀-商品名字 private int stock; //秒杀-商品库存 private Date startTime; //秒杀-开始时间 private Date endTime; //秒杀-结束时间 private Date createTime; //秒杀-商品新建时间 public long getSeckillId() &#123; return seckillId; &#125; public void setSeckillId(long seckillId) &#123; this.seckillId = seckillId; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getStock() &#123; return stock; &#125; public void setStock(int stock) &#123; this.stock = stock; &#125; public Date getStartTime() &#123; return startTime; &#125; public void setStartTime(Date startTime) &#123; this.startTime = startTime; &#125; public Date getEndTime() &#123; return endTime; &#125; public void setEndTime(Date endTime) &#123; this.endTime = endTime; &#125; public Date getCreateTime() &#123; return createTime; &#125; public void setCreateTime(Date createTime) &#123; this.createTime = createTime; &#125; @Override public String toString() &#123; return &quot;SecKill&#123;&quot; + &quot;seckillId=&quot; + seckillId + &quot;, name=&apos;&quot; + name + &apos;\&apos;&apos; + &quot;, stock=&quot; + stock + &quot;, startTime=&quot; + startTime + &quot;, endTime=&quot; + endTime + &quot;, createTime=&quot; + createTime + &apos;&#125;&apos;; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package org.seckill.domain;import java.util.Date;/** * 成功秒杀明细表-SuccessKilled */public class SuccessKilled &#123; private long secKillId; //秒杀-成功的商品id private String userPhone; //秒杀-成功的用户手机号 private short state; //秒杀-明细状态 private Date createTime; //秒杀-秒杀成功的时间 //one(被秒杀商品)-to-many(秒杀记录) private SecKill secKill; public long getSecKillId() &#123; return secKillId; &#125; public void setSecKillId(long secKillId) &#123; this.secKillId = secKillId; &#125; public String getUserPhone() &#123; return userPhone; &#125; public void setUserPhone(String userPhone) &#123; this.userPhone = userPhone; &#125; public short getState() &#123; return state; &#125; public void setState(short state) &#123; this.state = state; &#125; public Date getCreateTime() &#123; return createTime; &#125; public void setCreateTime(Date createTime) &#123; this.createTime = createTime; &#125; public SecKill getSecKill() &#123; return secKill; &#125; public void setSecKill(SecKill secKill) &#123; this.secKill = secKill; &#125; @Override public String toString() &#123; return &quot;SuccessKilled&#123;&quot; + &quot;secKillId=&quot; + secKillId + &quot;, userPhone=&apos;&quot; + userPhone + &apos;\&apos;&apos; + &quot;, state=&quot; + state + &quot;, createTime=&quot; + createTime + &apos;&#125;&apos;; &#125;&#125; DAO层接口功能声明-SecKillDao、SuccessKilledDao 123456789101112131415161718192021222324252627282930313233343536package org.seckill.dao;import org.seckill.domain.SecKill;import java.util.Date;import java.util.List;/** * 常用的操作 */public interface SecKillDao &#123; /** * 功能:减库存 * @param secKillId * @param killTime create_time? * @return 如果影响行数&gt;1，表示更新的记录行数 */ int reduceStock(long secKillId,Date killTime); /** * 根据秒杀商品id查询秒杀商品详情 * @param secKillId * @return */ SecKill queryById(long secKillId); /** * 根据偏移量查询秒杀商品列表， * @param offset * @param limit * @return */ List&lt;SecKill&gt; queryAll(int offset,int limit);&#125; 1234567891011121314151617181920package org.seckill.dao;import org.seckill.domain.SuccessKilled;public interface SuccessKilledDao &#123; /** * 功能：新增用户秒杀明细 * @param secKillId * @param userPhone * @return 插入的行数，禁止插入表示插入失败 则返回0 */ int insertSuccessKilled(long secKillId,long userPhone); /** * 功能：根据明细id查询具体的秒杀明细并携带秒杀商品对象 * @param secKillId * @return */ SuccessKilled queryByIdWithSecKill(long secKillId);&#125; MyBatis整合Spring 整合的目标: 更少的编码 更少的配置 足够的灵活性1.mybatis优点1更少的编码、只写接口、不写实现 2.DAO层接口声明能显示说明很多事情 更少的配置-别名 使用spring 提供的package-scan 扫描实体包下的所有实体类。可以简写resultType 更少的配置-配置扫描 单独使用mybatis的场景下，配置文件扫描方式 …. 使用spring 整合 mybatis 自动扫描配置文件，采用通配符的方式。 自动实现DAO接口，DAO接口的实现类是自动注入至Spring 容器 足够的灵活性 DAO层接口设计与SQL编写的反思 DAO - data access object 数据访问层的简称这一层我们主要做的是核心数据操作的接口声明，以及SQL编写，并没有涉及到Service 业务逻辑层代码的编写。这样做的好处是什么呢？主要有以下三点 代码分层，DAO层只关注于核心数据操作的接口声明&amp;SQL编写 代码和SQL的分离，方便代码review 业务逻辑层主要做事务控制、事务中完成DAO层的代码组合与拼接。每一层都可以做单元测试。 接下来详解mybatis 与 spring 整合编码的过程]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>秒杀</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发机制底层实现原理－原子操作的实现原理]]></title>
    <url>%2F2018%2F05%2F12%2FJava%E5%B9%B6%E5%8F%91%E6%9C%BA%E5%88%B6%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%EF%BC%8D%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[章节目录 原子操作含义 相关术语 保证多处理器操作原子性的两种方式 Java语言层面上实现原子操作 原子操作的含义：1原子本意是&quot;不能被进一步分割的最小粒子&quot;，而原子操作意为，不可中断的一个或一系列操作。 相关术语 术语名称 英文 解释 缓存行 Cache line 缓存的最小操作单位 比较并交换 Compare and Swap CAS操作需要输入两个数值，一个旧值(期望操作前的值)和一个新值，在操作期间先比较旧值有没有发生变化，如果没有发生变化，才交换成新值，发生变化，表示有多线程竞争，则不交换 保证多处理器操作原子性的两种方式 通过总线锁保证操作共享变量是原子性的 1234567891011121314151617181920212223242526272829如果多个处理器同事对共享变量进行读改写操作(i++是经典的读改写操作)，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子性的，操作完之后，共享变量的值会和期望的不一致。如：public class IncreaceThread implements Runnable &#123; public int i = 1; public void run() &#123; this.i = ++i; &#125; public int getI()&#123; return this.i; &#125; public static void main(String[] args) &#123; IncreaceThread increaseThread = new IncreaceThread(); Thread thread1 = new Thread(increaseThread); Thread thread2 = new Thread(increaseThread); thread1.start(); thread2.start(); System.out.println(increaseThread.getI()); &#125;&#125;计算出最终i的值有可能是2，而不是3。原因可能是多个处理器同时从各自的缓存中读取变量i，分别进行+1操作，然后分别写入到系统内从中。想要保证改写共享变量的操作是原子的，那就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。处理器使用总线锁来解决这个问题，所谓总线锁，就是处理器提供一个LOCK#信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。 使用缓存锁保证原子性 123第二个机制是通过缓存锁定来保证原子性。同一时刻，我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU 和内存之间的通信锁住，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁的开销比较大。使用缓存锁定开销会变小，缓存锁定，是指内存区域如果被缓存在处理器缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK#信号，而是修改内部的内存地址，并允许它的缓存一致性来保证操作的原子性。 Java语言层面上实现原子操作在Java中通过锁和循环CAS的方式实现原子操作 使用循环CAS实现原子操作JVM中的CAS操作正式利用了处理器提供的cmpxchg指令实现的，自旋基本思路就是循环进行CAS操作知道成功为止，以下代码实现可一个基于CAS线程安全的计数器方法safeCount 和一个非线程安全的计数器count。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.imooc.item;import java.util.ArrayList;import java.util.List;import java.util.concurrent.atomic.AtomicInteger;public class Counter &#123; private AtomicInteger atomicInteger = new AtomicInteger(0); private int i = 0; public void safeCount() &#123; for (; ; ) &#123; int i = atomicInteger.get(); boolean suc = atomicInteger.compareAndSet(i, ++i); if (suc) &#123; break; &#125; &#125; &#125; //线程计数器 public void count() &#123; i++; &#125; public static void main(String[] args) &#123; final Counter cas = new Counter(); List&lt;Thread&gt; ts = new ArrayList&lt;Thread&gt;(600); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 100; i++) &#123; Thread t = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; 10000; i++) &#123; cas.count(); cas.safeCount(); &#125; &#125; &#125;); ts.add(t); &#125; //开始运行线程 for (Thread t : ts) &#123; t.start(); &#125; //等待所有线程执行完毕 for (Thread t : ts) &#123; try &#123; t.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(cas.i); System.out.println(cas.atomicInteger.get()); System.out.println(System.currentTimeMillis() - start); &#125;&#125; 运行结果如下所示：123996309100000061 CAS实现原子操作的三大问题 ABA 问题 12345因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但如果一个值原来是A,变成了B,又变成了A,那么使用CAS进行检查时会发现它的值没有发生变化，但实际上却变了，ABA问题的解决思路就是使用版本号，在变量前面加上版本号，每次变量更新的时候把版本号加1。那么A-&gt;B-&gt;A问题就会变成1A-2B-3A. 循环时间开销大 1自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。常用做法是控制自旋的次数。 只能保证一个共享变量的原子操作 123当对一个共享变量执行操作时，我们可以使用循环CAS的方式保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候可以用锁。 使用锁机制实现原子操作 锁机制保证了只有获得锁的线程才能够 操作锁定的线程共享区域(临界区)，123JVM内部实现了很多的锁机制：偏向锁、轻量级锁和互斥锁。其中，除了偏向锁，JVM实现锁的方式都使用了循环CAS,即当一个线程想进入同步块的时候使用循环CAS的方式获取锁，当它退出同步块的时候使用循环CAS释放锁。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>原子操作的实现原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java高并发秒杀Api-业务分析与DAO层构建1]]></title>
    <url>%2F2018%2F05%2F12%2FJava%E9%AB%98%E5%B9%B6%E5%8F%91%E7%A7%92%E6%9D%80Api-%E4%B8%9A%E5%8A%A1%E5%88%86%E6%9E%90%E4%B8%8EDAO%E5%B1%82%E6%9E%84%E5%BB%BA1%2F</url>
    <content type="text"><![CDATA[章节目录 1.为什么使用Spring+Spring MVC+Mybatis 2.秒杀业务特性 3.秒杀分析过程、优化思路 4.相关技术介绍 5.基于Maven创建项目 6.秒杀业务分析 7.秒杀事务的难点分析 8.实现秒杀的哪些功能 1.为什么使用Spring+Spring MVC+Mybatis 框架易于使用、轻量级 对业务代码侵入性低 成熟的社区与资料 2.秒杀业务特性 秒杀业务场景具有典型的”事务”特性 秒杀、红包类需求越来越常见，对竞争资源的访问 面试常问的问题 3.相关技术介绍 MySQL 表设计 SQL技巧 事务、行级锁 MyBatis DAO层设计与开发 MyBatis 合理使用 MyBatis 与 Spring整合 Spring Spring Ioc 整合Service Spring 声明式事务使用 Spring MVC Restful 接口设计与使用 框架运作流程 Controller 设计技巧 前端 交互设计 BootStrap Jquery 高并发 高并发点和高并发分析 优化思路并实现 4.基于Maven创建项目1.maven命令创建web项目骨架12mvn archetype:generate -DgroupId=org.seckill -DartifactId=seckill -DarchetypeArtifactId=maven-archetype-webapp 5.秒杀业务分析如下图所示：所以秒杀业务的核心是对库存的处理。 用户针对库存处理的业务分析用户的秒杀过程 需要减库存-&gt;记录购买明细-&gt;组成完整事务-&gt;数据持久化如下图所示： 用户购买行为 记录谁购买成功了-&gt;成功的时间及有效期-&gt;付款、发货信息 为什么需要事务 12345678如上图所示1.减了库存，但是没有用户的购买明细，那么就会出现50个商品，但是购买明细小于50个，到时候发货会发现有些许商品滞留在仓库中，此种情况属于少卖的情况。2.记录了明细但是没有减库存，就会发现订单量比商品量要多，出现超卖的情况，还有一种情况也会导致超卖，多个用户并发修改库存，加入库存量为1，这个时候多个用户同时去减库存（经过库存量&gt;0的验证），会导致库存为负数，多个用户抢到同一个商品，这种情况下也会导致超卖发生。 数据落地方案MySQL VS NoSQLNoSQL非关系型数据库在事务的支持上并没有关系型数据库可靠。所以归根结底事务机制依然是目前最可靠的落地方案。 6.秒杀事务难点分析6.1 难点问题-竞争解决方案是采用数据库innodb引擎提供的事务及行级锁。 用户减库存的事务流程： 1234begin;update 库存数量;insert 购买明细；commit; 行级锁如下如所示:情景分析：1234在事务执行过程中，mysql默认的repeateable read 隔离级别会在写操作发生的行上加上行级锁（非记录加锁，而是在对应索引上加锁，上图中的update加锁发生在id上），多个写请求并发更新同一行记录会产生如下问题：因为行级锁在事务结束之后才能释放锁，可能会导致锁等待的发生。数据库吞吐率（事务处理能力）会降低。 7.秒杀的难点是什么？秒杀的难点是如何高效的处理竞争-如何在保证数据一致性的情况下高效的处理竞争 8.实现秒杀的哪些功能 1.秒杀接口暴露 浏览器插件获取秒杀接口，通过脚本去秒杀，保护秒杀接口的一种手段。 2.执行秒杀的操作执行秒杀的业务逻辑 3.秒杀查询，商品详情页查询。 其实市面上最主要的几个秒杀思路是： 1.直接在数据库层面做秒杀 2.缓存中存储库存，用户秒杀请求是将缓存中库存与数据库中库存数据同时进行减库存的过程，保证数据一致性是一个难点。 3.缓存中存储有效的减库存操作，队列减库存的的请求依次顺序执行数据库减库存、生成订单明细事务(操作)，如小米。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>秒杀</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程的挑战]]></title>
    <url>%2F2018%2F05%2F12%2FJava-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B-%E9%94%81%E7%9A%84%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89%2F</url>
    <content type="text"><![CDATA[章节目录 锁的释放-获取建立的 happens-before 关系 锁的释放-获取的内存语义 锁的释放-获取 建立的happens-before 关系 锁是Java并发编程中最重要的同步机制。锁除了让临界区互斥执行之外，还可以让释放锁的线程向获取同一个锁的线程发送消息。 如下所示，下面是锁释放-锁获取的示例代码1234567891011class MonitorExample &#123; int a = 0; public synchronized void writer() &#123; //1 a++; //2 &#125; //3 public synchronized void reader()&#123; //4 int i = a; //5 .... //6 &#125;&#125; 假设线程A执行writer()方法，随后线程执行reader()方法。根据happens-before 规则，这个过程包含happens-before 关系可以分为3类：12341.程序次序规则，1 happens-before 2，2 happens-before 3；4 happens before 5,5 happens-before 62.根据监视器锁规则，3 happens-before 43.根据happens-before 的传递性，2 happens-before 5 如下图所示，为锁的释放与锁的获取的happens-before 关系图 锁的释放-获取的内存语义线程释放锁的内存语义1当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中 线程 获取锁的内存语义12当线程获取锁时，JMM会将该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。 volatile 写-读内存语义 &amp; 锁释放与获取的内存语义1234volatile 写-读内存语义 &amp; 锁释放与获取的内存语义 是相同的1.线程A释放一个锁，即线程A向接下来获取这个锁的某个线程发送（A线程对共享变量做修改的）消息。2.线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量做修改）的消息。3.线程A释放锁，随后线程B获取锁，这个过程实质上是线程A通过主内存向线程B发送消息。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>锁的内存语义</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型-指令重排序-顺序一致性]]></title>
    <url>%2F2018%2F05%2F12%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B-%E6%8C%87%E4%BB%A4%E9%87%8D%E6%8E%92%E5%BA%8F-%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7%2F</url>
    <content type="text"><![CDATA[章节目录 1.重排序定义 2.数据依赖性 3.as-if-serial语义 4.程序顺序规则 5.JMM 参考 顺序一致性内存模型的实践规范 1.重排序定义 重排序是指编译器和处理器为优化程序性能而对指令序列重新排序的一种手段。 2.数据依赖性 如果两个操作访问同一个变量，且两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。 如下表所示，是我们常见的数据依赖性场景： 操作模式 代码示例 说明 store-&gt;load a=1;b=a; 写一个变量后，再读这个位置 store-&gt;store a=1;a=2 写一个变量之后，再写这个变量 load-&gt;store a=b;b=1 读一个变量之后，再写这个变量 注意：上述指令重排序之后，执行结果就会发生变化，所以编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。仅针对于单个处理器中执行的指令序列和单个线程中执行的操作。 3.as-if-serial 语义 对于不存在数据依赖性的操作可以做指令重排序。as-if-serial语义把单线程程序保护了起来。 4.程序顺序规则 如果A happens-before B,注意happens-before定义的不是A，B操作执行的顺序是A先B后，，而是A操作的结果对B操作的结果可见，且A操作的结果按顺序排在B操作结果之前，所以进行指令重排序必须保证的前提是不改变程序执行结果。 5.JMM 参考 顺序一致性内存模型的实践规范 1.JMM采用共享内存模型通过通过控制共享内存与每个线程本地内存之间的交互，来提供内存可见性保证。 2.JMM通过指令重排序来优化程序执行性能，但不正确的重排序会破坏多线程程序的语义，程序运行结果出现非预想的情况。 3.JMM参考顺序一致性内存模型，（但不能完全实现，比如在非同步多线程程序下），来对正确同步的多线程程序做了如下保证－程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同，但正确同步的多线程程序在执行过程中可以对临界区内不存在数据依赖的指令行进行重排序，以在保证执行结果正确的情况下通过指令重排序对程序运行性能做提升。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>重排序、顺序一致性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型-Java内存模型的基础1]]></title>
    <url>%2F2018%2F05%2F12%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B-Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9F%BA%E7%A1%801%2F</url>
    <content type="text"><![CDATA[章节目录 1.并发编程需要解决的问题-线程间通信&amp;线程间同步 2.Java内存模型的抽象结构 3.从源代码到指令序列的重排序 4.happens-before 简介 1.并发编程需要解决的问题-线程间通信&amp;线程间同步 并发编程中需要处理两个关键问题：线程间通信、 线程间同步 线程之间通信机制分为两种：共享内存、消息传递共享内存通信与同步 操作类型 实现方式 通信 线程之间共享程序的公共状态，通过写－读内存中的变量的公共状态进行隐式通信 同步 显式进行同步，必须显式制定某个方法或某段代码需要在线程之间互斥执行 消息传递通信与同步 操作类型 实现方式 通信 线程之间没有公共状态，线程之间通过发送消息显式进行通信 同步 隐式进行同步，消息发送必须在消息发送之前 注意：java并发采用的是共享内存模型，java线程之间的通信总是隐式进行的。 2.Java内存模型的抽象结构 在Java中所有的实例对象、静态数据域、和数组元素都存储在堆内存当中，堆内存在线程之间是共享的。 -堆中数据域是线程共享的 局部变量、方法定义参数、和异常处理器参数不会在线程之间共享、他们不会有内存可见性问题，也不受内存模型的影响。-线程独享的 JMM简介JMM决定一个线程对共享变量的写入何时对另一个线程可见。(可见性保证)如下图所示: 图示解释121.线程之间共享的变量存储在主内存中，每个线程都有一个本地内存，本地内存中存储了用共享内存中共享数据的副本。 线程A与线程B之间进行通信121.线程A把本地内存A中更新过的共享变量刷新到主存中去2.线程B到主存中去读取线程A之前已更新过的新的共享变量 JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。 3.从源代码到指令序列的重排序 重排序的作用1在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。 重排序类型 含义 编译器优化的重排序 编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序 指令级并行的重排序 不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序 内存系统的重排序 处理器采用缓存和读/写缓冲区，这使得加载和存储操作看起来是在乱序执行 123对于处理器重排序，JMM处理器重排序规则要求java编译器在生成指令序列时，插入特定类型的内存屏障指令，通过内存屏障指令禁止特定类型的处理器重排序。 4.happens-before 简介 Java内存模型，使用happens-before的概念来阐述操作之间的内存可见性、在JMM中，如果一个操作执行的结果需要对另一个操作可见、那么两个操作之间必须要存在happens-before（前一个操作的结果对后一个操作可见）关系。 与程序员密切相关的happens-before规则如下：12341.程序顺序规则：一个线程中的每个操作，happens-before于线程中的任意后续操作。2.监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。3.volatile规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。4.传递性：如果A操作happens-beforeB，且B happens-before C,那么A happens-before C。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>Java内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发机制底层实现原理-volatile]]></title>
    <url>%2F2018%2F05%2F12%2FJava%E5%B9%B6%E5%8F%91%E6%9C%BA%E5%88%B6%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86-volatile%2F</url>
    <content type="text"><![CDATA[章节目录 volatile的实现原理与应用 1.volatile的实现原理与应用 Java source code-&gt;Java class-&gt;JVM-&gt;汇编指令-&gt;cpu执行java中使用的并发机制依赖于JVM实现和cpu指令。 1.1 volatile应用 volatile-保证可见性123volatile 是轻量级 synchronized，在多处理器并发中保证了共享变量的&quot;可见性&quot;。可见性含义：当一个线程修改共享变量-时，另一个线程能立即读到这个修改的值。 volatile-执行成本低12volatile不会引起线程上下文的切换和调度。使用合适，volatile的使用代价会比synchronized小。 volatile 如何保证可见性123456class A&#123; private volatile Singleton instance ; public A()&#123; instance = new Singleton(); &#125;&#125; 转成汇编代码，如下：movb, lock add1上述对volatile共享变量instance进行写操作的时候会多出第二行汇编代码，Lock前缀的指令在多核处理器下会引发两件事情。 将当前处理器缓存行的数据写回到系统内存（工作内存写入到主内存） 这个写回操作，会使在其他cpu里缓存了该内存地址的数据无效。 注意:在多处理器下，为了保证各个处理器缓存是一致的，就会实现缓存一致性协议缓存一致性协议1234每个处理器通过嗅探在总线上传播的数据来对比检查自己缓存的值是否过期了，当处理器发现自己缓存行对应的内存地址中的值被修改，就会将当前处理器的缓存行设置为无效状态，当其他处理器对这个共享变量进行修改操作时，会重新从系统内存中把数据都到处理器缓存行当中。 volatile两条实现原则 Lock前缀指令会引起处理器缓存回写到内存 121.锁总线+独占任何共享内存2.缓存锁定+缓存一致性协议 一个处理器的缓存回写到主内存会导致其他缓存此主内存共享变量的处理器缓存无效 1234每个处理器通过嗅探在总线上传播的数据来对比检查自己缓存的值是否过期了，当处理器发现自己缓存行对应的内存地址中的值被修改，就会将当前处理器的缓存行设置为无效状态，当其他处理器对这个共享变量进行修改操作时，会重新从系统内存中把数据都到处理器缓存行当中。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>volatile 底层实现原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发机制底层实现原理-synchronized]]></title>
    <url>%2F2018%2F05%2F12%2FJava%E5%B9%B6%E5%8F%91%E6%9C%BA%E5%88%B6%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86-synchronized%2F</url>
    <content type="text"><![CDATA[章节目录 synchronized的实现原理与应用 synchronized 重量级锁1231.6版本之前 synchronized 被称之为 重量级锁1.6版本对 synchronized 进行了优化，主要优化的点在于 减少 获得锁和释放锁带来的性能消耗，为实现这个目的引入了偏向锁、与轻量级锁。 synchronized 实现同步的基础1234Java中每一个对象都可以作为锁。普通同步方法，锁是当前实例对象。静态同步方法块，锁是当前类的Class对象。对于同步方法块，锁是synchronized括号里配置的对象。 synchronized 同步锁的获取 底层原理如下图所示：synchronized锁的存储位置1234567synchronized 用的锁是存在java对象头里的。对象头中的Mark-word 默认存储对象的hashcode、分代年龄、和锁标志位。Mark-word 中存储的数据会随着锁标志位的变化而变化轻量级锁-00重量级锁-10GC标记-11偏向锁-01 锁的升级与对比Java SE 1.6 当中锁一共有4种状态，级别从低到高一次为:无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态。锁可以升级但不能降级，这种锁升级但不能降级的策略，目的是为了提高获得锁与释放锁的效率。 1.偏向锁原理 偏向锁的优点及初始化过程： 加锁解锁不需要额外的资源消耗，只需要对比当前线程id在对象头中是否存储指向当前线程的偏向锁。如果存在，表示当前线程已经获得锁。如果测试失败，则查询当前mark word中的偏向锁标志是否设置成为1，如果没有设置，则使用CAS竞争锁(非偏向锁状态)，如果设置了偏向锁标志，则尝试使用CAS将对象头的偏向锁指向当前线程。 偏向锁的撤销： 偏向锁使用了一种等到竞争出现才释放锁的机制，当其他线程尝试竞争偏向锁的时候，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点，这个时间点上没有正在执行的字节码。它首先会暂停拥有偏向锁的线程，然后检查持有偏向锁的线程活着，如果线程不处于活动状态，则将对象头设置为无锁状态。如果线程仍活着，拥有偏向锁的栈会被执行完。 2.轻量级锁原理 轻量级锁加锁： 线程在执行同步块之前，JVM会先在当前线程的栈桢中创建存储锁记录的空间，并将对象头中的mark word 复制到锁记录当中，然后线程尝试使用CAS将对象头中的 mark word 替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋锁来获取锁。 轻量级锁解锁 轻量级解锁时，会使用原子的CAS将锁记录(Displaced Mark Word)替换回到对象头，如果成功，则表示没有发生竞争。如果失败，表示当前锁存在竞争，锁就会膨胀为重量级锁。 ##总结不同锁的优缺点| 锁 | 优点 | 缺点 | 适用场景| | —– | —– | —- |—-| | 偏向锁 | 加锁和解锁都不需要额外的消耗，和执行非同步的方法相比只存在纳秒级差距 | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 |适用于只有一个线程访问同步块的场景| | 轻量级锁 | 竞争的线程不会阻塞，提高了应用的相应速率 | 如果始终得不到竞争的线程，适用自旋会消耗cpu，造成cpu空转 |追求响应时间，同步块执行速度非常快| | 重量级锁 | 线程竞争不使用自旋，不会消耗cpu | 线程阻塞，响应时间缓慢 |追求吞吐量，同步块执行速度较长|]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
        <tag>synchronized 底层实现原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx特性-常用操作命令]]></title>
    <url>%2F2018%2F05%2F12%2Fnginx-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[nginx-常用操作命令查看nginx 相关目录1rpm ql nginx 查看当前nginx占用端口1netstat -tlnp | grep nginx 查看当前nginx启动状态1ps aux | grep nginx 启停nginx123nginx -s reloadnginx -s start nginx -s stop 查看请求过程1curl -v http://www.baidu.com 检查配置是否正确1nginx -t -c /etc/nginx/nginx.conf 查看当前linux版本1cat /etc/issue]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>服务器中间件</tag>
        <tag>常用操作命令 实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx特性-负载均衡调度策略]]></title>
    <url>%2F2018%2F05%2F12%2Fnginx-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1-%E8%BD%AE%E8%AE%AD%E7%AD%96%E7%95%A5%E4%B8%8E%E5%8A%A0%E6%9D%83%E8%BD%AE%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[章节目录 Nginx 负载均衡调度策略 加权轮询演示 ip_hash url_hash Nginx 负载均衡调度策略 调度策略 含义 轮询 按照时间顺序，逐一分配到不同的后端服务器 加权轮询 weight值越大，分配到的访问几率越高 ip_hash 每个请求按访问IP的hash结果分配，这样来自同一个IP的请求固定访问一个后端服务器，可以解决分布式session问题，但不是最优的解决办法，另一个即集中式session存储校验，将session放到redis集群当中。 url_hash 按照访问的URL的hash结果来分配请求，使一个URL始终定向到同一个后端服务器 less_conn 最少连接数，哪个机器连接数少，就分发 hash关键数值 hash自定义的key 加权轮询演示1.修改 upstream_test.conf 中upstream server配置12345upstream testUpstream &#123; server eshop-cache04:8081 weight=5; //权重设置为5 ，如果7个请求过来，理论上有5个会落到8081对应的后端服务器上。 server eshop-cache04:8082; server eshop-cache04:8083;&#125; 多次刷新浏览器会发现浏览器显示 it is page1 ip_hash 基于用户ip计算ip值，ip hash 之后便会显示使的特定ip的请求一直被特定后端服务器处理。 配置upstream_test.conf 12345671.修改采用ip_hash 方式来进行请求负载upstream testUpstream &#123; ip_hash; server eshop-cache04:8081; server eshop-cache04:8082; server eshop-cache04:8083;&#125; 2.重载配置1nginx -s reload 结果 url_hash 将用户请求的资源定位至某一台后端服务器去处理。1.配置upstream_test.conf 1234567upstream testUpstream &#123; #ip_hash; hash $request_uri;//非域名后面的资源部分。 server eshop-cache04:8081; server eshop-cache04:8082; server eshop-cache04:8083;&#125; 2.重载配置1nginx -s reload 结果]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>服务器中间件</tag>
        <tag>负载均衡调度策略 实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx特性-负载均衡-Server参数]]></title>
    <url>%2F2018%2F05%2F12%2Fnginx-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1-server%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[章节目录 后端服务器在负载均衡调度中的状态 backup 状态演示 后端服务器在负载均衡调度中的状态 参数 含义 down 当前的server暂时不参与负载均衡 backup 预留的备份服务器 max_fails 允许请求失败的次数 fail_timeout 经过max_fails服务暂停的时间默认10留给运维人员解决后端服务器问题的时间 max_conns 限制最大的接收的连接数 backup 状态演示设置 nginx upstream server 状态：12345upstream testUpstream &#123; server eshop-cache04:8081 down;//不启用 server eshop-cache04:8082 backup;//所有应用服务器失效状态下启用 server eshop-cache04:8083 max_fails=1 fail_timeout=10s;//允许失败次数1次，失败1次后，暂停时间10s&#125; 重新加载配置文件1nginx -s reload 浏览器请求，观察响应结果如上图所示，多次请求 http://eshop-cache04/ 只显示可用后端服务器节点 eshop-cache04:8083。 iptables drop 8083 端口，不对外提供服务1iptables -I INPUT -p tcp --dport 8083 -j DROP 重新访问浏览器最终响应结果为： 清除iptables 规则1iptables -F]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>服务器中间件</tag>
        <tag>负载均衡 实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx特性-负载均衡]]></title>
    <url>%2F2018%2F05%2F12%2Fnginx-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[章节目录 什么是负载均衡 使用负载均衡要解决的问题 基于LVS的中间件架构 GSLB SLB 四层负载均衡和七层负载均衡 Nginx 负载均衡 配置语法 负载均衡配置实战 什么是负载均衡1234当用户请求量增加至单台服务器不能及时处理的时候即（单台服务器可接受能够建立连接的并发请求超过上限时），那么就需要横向扩容应用服务器来多当前场景下的高并发请求做处理，负载均衡正是将高并发请求分流至水平节点上不同应用服务器的一种技术。 负载均衡要解决的问题1提升服务的高可用性，容灾，提升应用服务器对并发请求的处理能力。 基于LVS的中间件架构GSLB-全局负载均衡如下图所示：12345适用场景：跨国机房应用服务部署如北京张三访问应用服务器，则请求先到达本地的调度节点，调度节点返回应用服务器某服务的调用地址，客户端再去请求对应的应用服务器。指路 SLB如下图所示：123调度节点转发客户请求至真正的应用服务器，应用服务器再将响应数据返回至调度节点，调度节点再将数据返回给客户端。从图中可以看出调度节点与服务节点在统一区域内，这样可以应对高并发请求的场景。 四层负载均衡和七层负载均衡四层负载均衡1传输层负载均衡，TCP/IP层负载均衡，进行数据包转发，性能更高 七层负载均衡1应用层负载均衡 http nginx采用的就是七层负载均衡 Nginx 负载均衡如下图所示：1Nginx 负载均衡采用了proxy_pass 方式将请求代理至一组虚拟的服务池，upstream server ，用户请求过来时，通过一定的负载策略，将请求分发至服务池中的某一个应用服务器中。 配置语法1234语法：upstream name &#123;&#125;默认：－可配置上下文：http注意配置到 server 层以外，且必须配置在http中 配置实战1.新建文件夹 分别存储不同应用服务上的同名静态文件1234567891011121.cd /opt/app/ 2.mkdir code1 code2 code33.cd code1 4.touch index.html5.vi index.html&lt;html&gt; &lt;title&gt;page1&lt;/title&gt; &lt;body&gt; it is page1 &lt;/body&gt;&lt;/html&gt;同上在code2 code3 中同样建立index.html 并且index.html中的内容 page1 更改为page2、page3 。 2.新建应用服务器配置文件12345678910111213141516171819202122232425262728291.cd /etc/nginx/conf.d2.touch server1.conf server2.conf server3.conf3.vi server1.conf server &#123; listen 8081; server_name eshop-cache04; location / &#123; root /opt/app/code1; index index.html index.htm; &#125;&#125;4.vi server2.confserver &#123; listen 8082; server_name eshop-cache04; location / &#123; root /opt/app/code2; index index.html index.htm; &#125;&#125;5.vi server3.confserver &#123; listen 8083; server_name eshop-cache04; location / &#123; root /opt/app/code3; index index.html index.htm; &#125;&#125; 3.配置upstream&amp;代理请求至虚拟服务池upstream 中12345678910111213141516171.touch upstream_test.conf2.vi upstream_test.confupstream testUpstream &#123; server eshop-cache04:8081; server eshop-cache04:8082; server eshop-cache04:8083;&#125;server &#123; listen 80; server_name eshop-cache04; location / &#123; proxy_pass http://testUpstream;//虚拟服务池名字 # include proxy_params; &#125;&#125; 4.检查配置文件正确性，重新加载配置文件121.nginx -t -c /etc/nginx/conf.d2.nginx -s reload 6.浏览器请求，验证结果 可以观察到，同样的请求显示的页面内容是不一致的，所以负载均衡配置成功。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>服务器中间件</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx特性-代理服务]]></title>
    <url>%2F2018%2F05%2F12%2Fnginx-%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[目录章节 代理示意图 Nginx代理服务 配置语法及反向代理场景 代理示意图12客户端发送请求至代理服务，代理服务请求真正的服务器，服务器返回结果给代理服务器，代理服务器将请求结果转发给客户端。 Nginx代理服务如图所示12nginx代理服务可以实现HTTP、ICMP、POP、IMAP、HTTPS、RTMP 代理服务即普通http服务代理、邮件服务代理、https服务代理、media服务代理 翻墙-正向代理12翻墙使用的是正向代理，客户端知道请求结果是通过代理服务器获取到的。代理的对象是客户端，即正向代理是客户端的代理 反向代理1代理的对象是服务器，即反向代理是服务器的代理。并不关心访问的服务器是具体的哪一台。 配置语法及反向代理场景配置语法123语法：proxy_pass URL;默认：——可配置项：location、if in location、limit_except 配置实战1234567891011121314151617181920212223242526272829301.cd /etc/nginx/conf.d2.touch fx_proxy.conf3.touch realserver.conf4.vi fx_proxy.conf //代理服务器配置server &#123; listen 80; server_name eshop-cache04; location ~ /test_proxy.html$ &#123; proxy_pass http://eshop-cache04:8080; &#125;&#125;5.vi realserver.conf //被代理服务器，真实服务器server &#123; listen 8080; server_name eshop-cache04; location / &#123; root /opt/app/code2; index index.html index.htm; &#125;&#125;6.cd /opt/app/code2 7.touch test_proxy.html8.vi test_proxy.html&lt;html&gt; &lt;body&gt; test fx_proxy &lt;/body&gt;&lt;/html&gt;9.nginx -t 10.nginx -s reload //重新加载配置文件 最终结果如下所示：]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>服务器中间件</tag>
        <tag>正向代理、反向代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx特性-I/O多路服用]]></title>
    <url>%2F2018%2F05%2F12%2Fnginx-feature-I-O%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%2F</url>
    <content type="text"><![CDATA[章节目录 I/O复用 IO多路复用 多路复用-select、epoll select epoll 优缺点总结 linux 更改文件描述符大小的命令 - 面试会问 I/O复用什么是I/O复用1234I/O复用 解决的是并发性请求的问题。处理多个并发请求，要产生多个I/O流来进行系统内核数据的读取。常用的两种处理方式是串行，前一个阻塞，后面无法继续进行处理、并行处理请求－实现最大并发和吞吐。I/O复用定义为：一个socket作为复用来完成整个I/O流的请求链接建立，处理请求则采用多线程。 IO多路复用普通版：12老师给一个班学生出题，并且老师不停挨个询问学生有没有做完试题，如果有学生做完试题，则解答，这种方式采用的是串行的处理方式。 强化版：1老师分身，创建多个线程老师，分别处理每个学生做完的试题，这种方式采用的是多线程的处理方式。但是资源分配上、上下文切换会出现额外资源消耗。 究极版：12真正的I/O多路复用学生（网络请求-请求数据分组到达，）主动上报自己做题的情况，复用的是老师处理学生做题情况的线程 什么是I/O多路复用12多个描述符的I/O操作都能在一个线程内并发交替地顺序完成，这就叫I/O多路复用，这里的“复用”指的是复用同一个线程 多路复用-select、epollselect123I/O多路复用采用的是select 模型，即系统发出select系统调用，等待内核主动将可用的文件描述符信息发送给应用一端，fd未准备好，应用会block住socket请求，当fd就许后，select 会遍历维护的文件描述符发现可用的文件描述符。 epoll1每当fd就绪，系统采用回调函数将fd放入就绪列表，效率非常高。 123举例：告诉服务员，用餐结束，服务员告知老板，说有几桌要结账，老板需要询问告诉服务员，用餐结束，服务员告知老板，说哪号桌要结账，老板不需要询问。 select epoll 优缺点总结 模型 优点 缺点 select 1.采用线性遍历的方式获取可用的fd文件描述符2.可维护文件描述符大小有限制为1024 epoll 1.每当fd就绪，系统采用回调函数将fd放入就绪列表，效率非常高。2.最大连接数没有限制 linux 更改文件描述符大小的命令 - 面试会问当前登陆态修改方式1ulimit -n ［fd数量］ 永久生效、开机启动方式1231.vi /etc/security/limits.conf 2.- nofile 40963.重启操作系统]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>服务器中间件</tag>
        <tag>I/O多路复用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-轻量级+CPU亲和+超强的静态文件处理能力]]></title>
    <url>%2F2018%2F05%2F12%2Fnginx-%E8%BD%BB%E9%87%8F%E7%BA%A7-CPU%E4%BA%B2%E5%92%8C-%E8%B6%85%E5%BC%BA%E7%9A%84%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%E8%83%BD%E5%8A%9B%2F</url>
    <content type="text"><![CDATA[章节目录 轻量级 CPU亲和 超强的静态文件处理能力 轻量级功能模块少1源代码只保留与http 及核心功能代码，出于性能考虑，不像httpd 有那么丰富的插件。 代码模块化1易读，可进行二次改进。 CPU亲和8核心 16核心，多核密集计算、多线程，接入层中间件双cpu、每个cpu有四个核心不同worker进程 绑定不同核心 均匀分配，多个核心自动切换的模式，会带来核心切换资源消耗。什么是CPU亲和？12把CPU核心和NGINX 工作进程绑定的方式，把每个worker进程固定在一个cpu上执行，减少切换cpu的cache miss，获得更好的性能。 超强的静态文件处理能力-sendfile内核空间-用户空间数据拷贝模式 可以看到上图为nginx应用程序进程配合内核空间返回给用户请求静态文件的response过程这种响应模式，需要进行 内核空间 与 应用进程 空间之间数据的拷贝，比较消耗性能。 内核空间零拷贝模式 直接通过内核空间进行数据的拷贝，sendfile利用带了linux在2.2 零拷贝传递模式nginx对静态文件的处理能力超强的原因就是因为sendfile使用了内核空间零拷贝数据传递模式。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>服务器中间件</tag>
        <tag>轻量级、CPU亲和、超强的静态文件处理能力</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-静态资源处理]]></title>
    <url>%2F2018%2F05%2F12%2Fnginx-%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%2F</url>
    <content type="text"><![CDATA[章节目录 静态资源分类 CDN场景 nginx作为静态资资源web服务_配置语法 浏览器缓存 服务器端设置浏览器缓存过期实践 跨站访问 静态资源分类静态资源：非服务器动态运行生成的文件 类型 种类 浏览器端渲染 html、js、css 图片 jpeg、gif、png 视频 flv、mpeg 文件 txt、excel CDN场景 如上图所示，用户请求通过DNS解析技术，将用户请求定位到分发层 代理服务器nginx上。 nginx作为静态资资源web服务_配置语法配置语法-tcp_nopush12345要求实时性不高的场景下使用，不着急返回给客户端语法：tcp_nopush on | off;默认配置：tcp_nopush off;可配置模块：http、server、locationnopush：整体处理，资源准备好之后一起发送给用户 作用：在sendfile开启状态下，提高网络包的传输效率 配置语法-tcp_nodelay1234要求实时性比较高的场景下使用语法：tcp_nodelay on | off;默认配置：tcp_nodelay on;可配置模块：http、server、location 作用：keepalive连接下，提高网络包的传输实时性 配置语法-压缩1234567解压(浏览器端)----------------&gt;压缩(nginx静态资源服务端)语法： gzip_comp_level level;默认配置：gzip_comp_level 1;可配置模块：http、server、location压缩模块扩展http_gzip_static_module－支持预读gzip功能 作用：较少网络资源的消耗，提高静态资源快速响应的能力,提高服务端的处理效率 浏览器缓存http协议定义的缓存机制1如:Expires；cache-control等 校验过期机制 校验是否过期 Expires-1.0、Cache-Control(max-age)-1.1版本 协议中Etag头信息校验 Etag Last-Modified头信息校验 Last-Modified 详细解释：12345671.cache-control-(本地缓存是否失效验证阶段):客户端缓存的文件先会检查原先请求头中的cache-control是否已经超过可缓存 期限，超过则过期2.Last-Modified 1s精度跟了时间，客户端请求过程中请求头中携带Last-Modified 如果跟服务器端文件的last-Modified相同则返回304，如果不相同则服务端重新返回给客户端。3.Etag 是对服务器文件的一段编码，服务器文件变化后Etag会发生变化，如果客户端传递过来的Etag与服务器端不一致，则响应最新的文件并在响应之前进行缓存协商，返回对应的缓存控制信息给浏览器。 浏览器缓存原理示意图 服务器端设置浏览器缓存过期实践Response添加Cache-Control、Expries头123语法：expries time;默认：expries off;//默认是关闭的可配置项：http、server、location、if in location 配置实践1234567891011121. touch /etc/nginx/conf.d/static_server.conf2. vi /etc/nginx/conf.d/static_server.conf3. 配置如下：server &#123; listen 80; server_name eshop-cache03; location ~ .*\.(html|htm)$ &#123; expires 24h;//添加时间 root /opt/app/code; &#125;&#125; 浏览器强制设置请求头Cache-Control 保证随时跟服务器交互 ####跨站访问什么是跨站访问1即浏览器访问统一个页面www.a.com，利用ajax请求www.b.com 为什么浏览器禁止跨域访问不安全，容易出现csrf攻击！如下图所示：跨站访问详解12345678910举例说明：假如一家银行用以执行转账操作的URL地址如下： [http://www.examplebank.com/withdraw?account=AccoutName&amp;amount=1000&amp;for=PayeeName](http://www.examplebank.com/withdraw?account=AccoutName&amp;amount=1000&amp;for=PayeeName)那么，一个恶意攻击者可以在另一个网站上放置如下代码： &lt;img src=&quot;[http://www.examplebank.com/withdraw?account=Alice&amp;amount=1000&amp;for=Badman](http://www.examplebank.com/withdraw?account=Alice&amp;amount=1000&amp;for=Badman)&quot;&gt;如果有账户名为Alice的用户访问了恶意站点，而她之前刚访问过银行不久，登录信息尚未过期，那么她就会损失1000资金。这种恶意的网址可以有很多种形式，藏身于网页中的许多地方。此外，攻击者也不需要控制放置恶意网址的网站。例如他可以将这种地址藏在论坛，博客等任何[用户生成内容](https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E7%94%9F%E6%88%90%E5%86%85%E5%AE%B9 &quot;用户生成内容&quot;)的网站中。这意味着**如果服务器端没有合适的防御措施的话，用户即使访问熟悉的可信网站也有受攻击的危险**。透过例子能够看出，攻击者并不能通过CSRF攻击来直接获取用户的账户控制权，也不能直接窃取用户的任何信息。他们能做到的，是**欺骗用户浏览器，让其以用户的名义执行操作**。 nginx设置允许跨站访问假如我们使用nginx做了动静分离，动态数据都需要通过ajax请求数据接口来获取，那么浏览器默认的同源策略会组织我们去成功请求数据接口。比如我们网站A网页域名前缀是www.abc.com、数据接口网站前缀是 api.abc.com .那么这个就属于跨站访问了。如何通过nginx服务器设置，使得api.abc.com 允许跨站访问呢？1234配置如下：语法：add_header name value [always];默认：---可配置上下文：http、server、location 浏览器端是否允许跨站访问是需要验证response 中的Access-Control-Allow-Origin跨站访问实战*12345678910配置如下：server &#123; listen 80; server_name api.abc.com; location ~ .*\.(html|htm)$ &#123; add_header Access-Control-Allow-Origin http://www.abc.com; add_header Access-Control-Allow-Methods GET,POST,DELET,PUT,OPTIONS; root /opt/app/code; &#125;&#125; 浏览器判断服务器返回头中返回的Access-Control-Allow-Origin 字段是否包含www.abc.com ，如若包含，正确返回相关响应数据。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>服务器中间件</tag>
        <tag>nginx-静态资源处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis－伪分布式集群]]></title>
    <url>%2F2018%2F05%2F12%2FRedis%E4%B8%93%E9%A2%98-%E4%BC%AA%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[教程大纲1234在虚拟机中安装CentOS在每个CentOS中都安装Java和Perl在4个虚拟机中安装CentOS集群配置4台CentOS为ssh免密码互相通信 注意事项123456789101112131415161718192021222324从零开始，纯手工，一步一步搭建出一个4个节点的CentOS集群。为我们后面的课程做准备，后面会讲解大型的分布式的redis集群架构，一步一步纯手工搭建redis集群，集群部署，主从架构，分布式集群架构。后面的课程，会讲解一些实时计算技术的应用，包括storm，讲解一下storm的基础知识，对于java工程师来说，会用就可以了，用一些storm最基本的分布式实时计算的feature就ok了，搭建一个storm的集群。部署我们整套的系统，nginx，tomcat+java web应用，mysql。尽量以真实的网络拓扑的环境，去给大家演示一下整套系统的部署，不要所有东西，redis集群+storm集群+nginx+tomcat+mysql，全部放在一个节点上玩儿，也可以去试一试，但是作为课程来说，效果不是太理想。redis集群，独立的一套机器storm集群，独立的一套机器nginx，独立部署tomcat + java web应用，独立部署mysql，独立部署十几个机器，去部署整套系统，我在自己的笔记本电脑上来讲课的，这么玩儿撑不住的。i5，8G+Mac OS 凶他4台虚拟机，每台虚拟机是1G的内存，电脑基本还能撑住电脑本身就6个G内存的话，学习这种大型的系统架构的课程，是有点吃力，给大家建议，几个G的内存条，也就几百块钱，给自己最好加个内存条，至少到8G以上16G凑合，玩的很嗨。纯手工，从零开始。很多视频课程，里面讲师都是现成的虚拟机，自己都装好了，包括各种必要的软件讲课的时候直接基于自己的虚拟机就开始讲解了很多同学就会发现，想要做到跟讲师一样的环境都很难，自己可能照着样子装了个环境，但是发现，各种问题，各种报错，环境起不来。学习课程的过程很艰难学视频课程，肯定是要跟着视频的所有的东西自己去做一做，练一练，结果你却因为环境问题，做不了，连不了，那就太惨了从centos的镜像文件，到所有的需要使用的软件，全都给你，在自己电脑上，下载一个虚拟机管理软件，virtual box，就可以跟着玩儿了如果你一步一步跟着视频做，搭建起整个环境，应该问题不大环境问题，给大家弄成傻瓜式的。 1、在虚拟机中安装CentOS动一个virtual box虚拟机管理软件（vmware，我早些年，发现不太稳定，主要是当时搭建一个hadoop大数据的集群，发现每次休眠以后再重启，集群就挂掉了）virtual box，发现很稳定，集群从来不会随便乱挂，所以就一直用virtual box了. 1.使用课程提供的CentOS 6.5镜像即可，CentOS-6.5-i386-minimal.iso。2.创建虚拟机：1234567打开Virtual Box点击“新建”按钮点击“下一步”输入虚拟机名称为eshop-cache01选择操作系统为Linux，选择版本为Red Hat，分配1024MB内存，后面的选项全部用默认。在Virtual Disk File location and size中，一定要自己选择一个目录来存放虚拟机文件，最后点击“create”按钮，开始创建虚拟机。 3.设置虚拟机网卡：1选择创建好的虚拟机，点击“设置”按钮，在网络一栏中，连接方式中，选择“Bridged Adapter”。 4.安装虚拟机中的CentOS16.5操作系统：选择创建好的虚拟机，点击“开始”按钮，选择安装介质（即本地的CentOS 6.5镜像文件），选择第一项开始安装-Skip-欢迎界面Next-选择默认语言-Baisc Storage Devices-Yes, discard any data-主机名:spark2upgrade01-选择时区-设置初始密码为hadoop-Replace Existing Linux System-Write changes to disk-CentOS 6.5自己开始安装。 5.Reboot1安装完以后，CentOS会提醒你要重启一下，就是reboot，你就reboot就可以了。 6.配置网络1vi /etc/sysconfig/network-scripts/ifcfg-eth0 配置内容如下所示：123456789101112DEVICE=eth0TYPE=EthernetONBOOT=yesBOOTPROTO=dhcpservice network restartifconfigBOOTPROTO=staticIPADDR=192.168.0.XNETMASK=255.255.255.0GATEWAY=192.168.0.1service network restart 7.配置hosts12vi /etc/hosts配置本机的hostname到ip地址的映射 8.关闭防火墙12345678910service iptables stopservice ip6tables stopchkconfig iptables offchkconfig ip6tables offvi /etc/selinux/configSELINUX=disabled注意：一定要关闭本地宿主机上的防火墙。后面要搭建集群，有的大数据技术的集群之间需要通信，在本地你设置了防火墙的话，可能会导致集群之前没办法互相连接，相互通讯，会导致搭建失败。 9.配置yum123yum clean allyum makecacheyum install wget 2、在每个CentOS中都安装Java和Perl1.安装JDK123456781、将jdk-7u60-linux-i586.rpm通过WinSCP上传到虚拟机中2、安装JDK：rpm -ivh jdk-7u65-linux-i586.rpm3、配置jdk相关的环境变量vi .bashrcexport JAVA_HOME=/usr/java/latestexport PATH=$PATH:$JAVA_HOME/binsource .bashrc4、测试jdk安装是否成功：java -version 2.安装Perl123456789yum install -y gccwget http://www.cpan.org/src/5.0/perl-5.16.1.tar.gztar -xzf perl-5.16.1.tar.gzcd perl-5.16.1./Configure -des -Dprefix=/usr/local/perlmake &amp;&amp; make test &amp;&amp; make installperl -v为什么要装perl？我们整个大型电商网站的详情页系统，复杂。java+nginx+lua，需要perl。perl，是一个基础的编程语言的安装，tomcat，跑java web应用 3.在4个虚拟机中安装CentOS集群12345678910（1）按照上述步骤，再安装三台一模一样环境的linux机器（2）另外三台机器的hostname分别设置为eshop-cache02，eshop-cache03，eshop-cache04（3）安装好之后，在每台机器的hosts文件里面，配置好所有的机器的ip地址到hostname的映射关系比如说，在eshop-cache01的hosts里面192.168.31.187 eshop-cache01192.168.31.xxx eshop-cache02192.168.31.xxx eshop-cache03192.168.31.xxx eshop-cache04 4、配置4台CentOS为ssh免密码互相通信123456789101112131415164.1 首先在三台机器上配置对本机的ssh免密码登录ssh-keygen -t rsa生成本机的公钥，过程中不断敲回车即可，ssh-keygen命令默认会将公钥放在/root/.ssh目录下cd /root/.sshcp id_rsa.pub authorized_keys将公钥复制为authorized_keys文件，此时使用ssh连接本机就不需要输入密码了4.2接着配置三台机器互相之间的ssh免密码登录使用ssh-copy-id -i hostname命令将本机的公钥拷贝到指定机器的authorized_keys文件中java，在公司里做项目，有几个人是自己去维护linux集群的啊？？？？？几乎没有，很少很少，类似这一讲要做的事情，其实都是SRE，运维的同学，去做的但是对于课程来说，我们只能自己一步一步做，才有环境去学习啊！！！基于虚拟机的linux集群环境，都准备好了，手上有4台机器，后面玩儿各种redis、kafka、storm、tomcat、nginx，都有机器了. 利其事，必先利其器！下节继续！]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>缓存中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx－性能测试]]></title>
    <url>%2F2018%2F05%2F12%2Fnginx-ab-test%2F</url>
    <content type="text"><![CDATA[章节目录 nginx 性能优化的点 当前系统性能的评估 ab 压力测试工具使用 1.nginx 性能优化的点当前系统结构瓶颈12可用方案：观察指标-top、压力测试-substatus、线上系统可以支撑的并发。清除当前架构、当前业务，每个服务可以支撑多少并发,多少QPS。 了解业务模式1接口业务类型、系统层次化结构 是代理、动静分离、业务服务器？ 性能与安全 2.当前系统性能的评估系统监测、日志分析 ab接口压力测试 业务量还没有大幅度增长之前，就需要对接口的响应能力做一个压测，防止业务量增加的时候出现问题。 ab接口压力测试工具在评估好当前业务的系统压力需求情况下面，工具检测当前的系统负载能力是否能满足对应的压力测试需求。 3.ab 接口压力测试工具使用安装1yum install httpd-tools 使用1234ab -n 1000 -c 100 http://www.baidu.com/-n 总的请求数-c 并发数-k 是否开启长连接 实战演示1.请求静态页面 http://eshop-cache04:82/test_proxy.html1ab -n 1000 -c 100 http://eshop-cache04:82/test_proxy.html -n 1000 总请求数1000-c 100 单个时刻并发数100资源： http://eshop-cache04:82/test_proxy.html测验结果]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>服务器中间件</tag>
        <tag>性能压测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程的挑战]]></title>
    <url>%2F2017%2F11%2F17%2Fjava_%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%9A%84%E8%89%BA%E6%9C%AF_%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0_chapter1%2F</url>
    <content type="text"><![CDATA[并发编程带来的问题121.上下文切换问题2.死锁问题 上下文切换多线程不一定快11.线程有创建和上下文切换的开销 如何减少上下文切换减少上下文切换的方法有无锁编程、CAS算法、使用最小线程、使用协程12341.无锁并发编程，多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照hash算法取模分段，不同的线程处理不同段的数据2.CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁，其实也加了锁，只不过加锁于cpu上，系统开销可忽略不计3.使用最小线程。避免创建不需要的线程，比如任务很少，但是创建很多线程来处理，这样会造成大量线程处于等待状态4.协程，在单线程里实现多任务调度，并在单线程里维持多个任务间的切换 死锁有如下代码：123456789101112131415161718192021222324252627282930313233343536373839404142package com.fx.pattern.cor.handler;public class DeadLockDemo &#123; private static String A = "A"; private static String B = "B"; public static void main(String[] args) &#123; new DeadLockDemo().deadLock(); &#125; private void deadLock() &#123; Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (A) &#123; try &#123; Thread.currentThread().sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (B) &#123; System.out.println('1'); &#125; &#125; &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (B) &#123; synchronized (A) &#123; System.out.println('2'); &#125; &#125; &#125; &#125;); t1.start(); t2.start(); &#125; 这段代码运行之后会引起死锁，t1线程与t2线程互相等待对方释放锁。待程序运行之后，我们采用如下方式来查看jvm对程序的跟踪栈信息：获取当前程序进程id11.ps aux | grep DeadLockDemo 进程id如下图所示： 获取当前程序产生的堆栈信息12.sudo -u root jstack -F 32125 &gt; /Users/mark/Desktop/JAVA/dump 获取到的堆栈信息如下图所示： idea中堆栈信息更加明确程序出现死锁的代码行数： 避免死锁的方法12341.避免一个线程同时获取多个锁2.避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源3.尝试使用定时锁，使用lock.tryLock(timeout)来代替使用内部锁机制。4.对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。 资源限制的挑战什么是资源限制1资源限制是指在并发编程时，程序的执行速度受限于计算机硬件资源或软件资源 资源限制引发的问题1并发编程，将代码执行速度加快的原则是将代码中串行执行的部分变成并发执行，但将串行执行的代码演变成并发执行，需要考虑到资源限制，资源受限的情况下，串行到并发的演变反而会使程序执行变得更慢，因为增加了上下文切换和资源调度的时间。 如何解决资源限制问题12硬件资源限制，考虑使用集群并行执行程序，既然单机资源有限，那就让程序在多机上运行。软件资源限制，考虑使用资源池将资源复用，比如使用连接池将数据库和Socket连接复用，或者在调用对方webService接口获取数据时，只建立一个连接。 在资源限制情况下进行并发编程11.根据不同的资源限制调整程序的并发度。涉及数据库连接数的sql操作，如果sql语句执行非常快，但是线程数量比数据库连接大很多，则某些线程会被阻塞，等待数据库连接。 博客搬家：大坤的个人博客欢迎评论哦~]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java并发编程的艺术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优雅使用Mac]]></title>
    <url>%2F2017%2F11%2F16%2F%E4%BC%98%E9%9B%85%E4%BD%BF%E7%94%A8Mac%2F</url>
    <content type="text"><![CDATA[【教程大纲】如下所示： 【操作手势设置】使用Mac后，可以不再使用鼠标，依靠不同手势动作即可方便操作电脑。 1.点击系统偏好设置 2.点击触控板设置像我一样设置就好了。 3.设置光标与点按像我一样设置就好了。 4.设置滚动缩放像我一样设置就好了。 5.更多手势像我一样设置就好了。 手势设置完后，可以先自己尝试10分钟左右，熟悉之后，俺们进行下一步。 【操作系统简介】MacOS内核为unix,是区别于windows的一种操作系统内核。 【软件安装】输入法安装123451.打开链接：pinyin.sougou.com/mac/2.点击立即下载，下载完后是dmg文件3.双击dmg文件，安装。4.进入Application 点击搜狗拼音即打开程序。5.按压command+大空格键进行输入法的切换。 搜狗拼音安装状态如下所示: 浏览器安装123451.四指在触摸板上向下聚拢，打开应用程序聚集页面。2.在搜索中输入Safari,点按Safari,打开应用程序。3.在搜索框中输入Chrome4.点击下载chrome5.如上图安装搜狗拼音所示，安装并打开chrome 翻墙软件安装1231.在Safari 中输入 shadowsocks。2.下载安装。3.配置翻墙，此处配置非常简单，扫描我分享给你的二维码即可。 印象笔记安装1231.点击链接Safari2.输入Evernote，点击下载并安装。3.command+n 新建一篇笔记，编写笔记很方便，可以尝试一下。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>软件使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k码特权中关于 Redis与MySQL DB 乐观锁应用]]></title>
    <url>%2F2017%2F11%2F14%2Fkcode%2F</url>
    <content type="text"><![CDATA[1.【背景】 斐讯路由App 需要新增k码特权模块。 2.【需求】 1.已通过k码激活状态验证的用户可免费领取k码特权商品2.每个用户每天只能领取一张k码特权奖品 3.【应用场景及难点分析】 1.接口数据安全性要求：121.1 当某k码特权商品数据量为1，且高并发情况下，1.2 如何防止超卖(即多个用户都抢到了剩余的一个商品) 2.接口性能要求：123456斐讯路由App 现用户量为300w+，日活4w＋，2/8原则分析(**指80%的业务量在20%的时间里完成**)。经验可知用户使用斐讯路由App 的持续时间为12小时，所以2/8分析后，80%的日活在20%的时间内完成。即32000人免费领取k码特权商品要在2.4小时内完成，换算成每秒 完成请求数即 QPS = 3.7/s 。即每个接口响应请求时间至少要在 270ms 以内。才算是高性能。 4.问题分析： 1.读多写少1每个用户每日只能领取一个k码特权商品。即1个用户加入请求免费领取k码特权接口多次，在k码商品库存量充足的情况下，只能领取到1个商品，其余请求都应该返回“对不起，您今日已领取k码特权商品”。从这个方面来定义，其属于读多写少的问题。 2.并发量低123以斐讯路由现在日活情况为4w＋的数据量来估算、接口并发能力 QPS = 3.7/s ，属于低并发，但在k码特权模块优化程度达到一定量时，并发量是否会上升有待考察。但总体来说属于并发量不高的场景。 也就是说k码特权问题经过模型抽象，已经变成了读多写少、并发量不大，但要保证性能，和数据安全性一致性的问题。 对于这类问题，乐观锁思想可以作为解决这类问题的指导思想。 5.乐观锁思想 网上文章对乐观锁理解的误区: 1.乐观锁是一种思想，并不是一种具体的技术实现。2.乐观锁类似于CAS无锁编程技术(其实也加锁，只不过在cpu层面)1234567即当多个线程同时并发更新统一个变量，采用先select再update的方式，select出当前变量a的副本值b，然后用新值c去更新，更新时需要拿select 出来的变量值a的副本值b与当前非副本变量a的值做对比，若暂存副本值b与当前变量a非副本值相同，则正常更新，如果不同，则认为在当前线程更新之前已经有一个值将a变量更新，则更新失败，在并发情况不大的情况下，采用循环的方式去更新，总能更新成功，且循环更新次数不会太多。因此CAS也叫自旋锁。 6.k码特权-免费领取解决方案 1.用户每日成功领取k码特权商品次数的限制 采用redis 数据结构 String，记录用户每日免费领取成功次数。并且可以轻松使用redis 缓存的过期 (expire) 机制做每日领次数的控制），用户每日成功领取k码特权的次数次日凌晨清空。为什么不使用数据库来进行用户成功领取k码特权商品次数的控制。当然建立好索引此问题也可以完美解决。使用redis进行用户成功领取k码特权商品次数的控制原因有两个：121.因为redis 纯粹的查询快，减轻数据库压力！不用每次都通过数据库二次索引，从磁盘找到目标记录并读入到内存。**2.线上配置的redis使用量10%都不到，为了更好的利用硬件资源。** 2.用户每日成功领取k码特权次数的并发更改 从接口安全性考虑，若有用户恶意领取、那么有可能产生一个用户在一天之内领取了多个k码特权奖品，这个是业务需求所不允许的。这里我们使用到了redis 提供的 事务(multi)与watch(乐观锁实现) 机制来控制 用户每日成功领取k码特权次数的并发更改。12watch机制：对键值进行监控，当被其他客户端改变时，当前的客户端的所有操作将会失败，抛出错误信息。 3.用户并发更新同一k码特权商品库存、同一商品的具体某个item 上述问题，属于对竟态资源的并发修改，在接口请求并发量不大、且读多写少的情况下，采用数据库乐观锁来解决问题。1234567891011121314151617181920212223数据库乐观锁实现方式：在竞态资源(商品)记录上添加一列，update_version，表示更新次数。数据库乐观锁实现方式伪代码：for(;;)&#123; //获取某k码商品库存，更新版本号 sql $getRewardStcokSql = &apos;select reward_stock,reward_update_version from fx_platform_reward_amount where reward_type_id = &#123;$reward_type_id&#125;&apos;; $getReardStockResult = $model-&gt;query($getRewardStcokSql); if(!$getReardStockResult )&#123; die; &#125; $reward_stock = getReardStockResult[&apos;reward_stock&apos;]; $reward_update_version = getReardStockResult[&apos;reward_update_version&apos;]; //如果库存量&gt;0 if($reward_stock&gt;0)&#123; //更新k码商品库存，版本号需要进行对比，其实本质上是不再使用数据库提供的排它锁，而将排他控制的职责交给选择某条需要更新记录的过滤条件。 $updateRewardStockSql = &apos;update fx_platform_reward_amount set reward_stock = reward_stock-1 and reward_update_version = reward_update_version + 1 where reward_type_id = &#123;$reward_type_id&#125; reward_update_version = &#123;$reward_update_version&#125; &apos;; $updateRewardStockResult = $model-&gt;excute($updateRewardStockSql); &#125; //并发更新失败，表示在此用户更新商品库存之前已经有用户更新成功，需要重新尝试更新。 if(!$updateRewardStockResult)&#123; continue; &#125;&#125; 7.测试结果 1237.1 并发测试，数据能保持一致性7.2 用户免费领取k码特权商品响应时间均值为 110ms 左右， 用户当日已领取过k码特权奖品的接口响应时间40-55ms左右。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>项目实操</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UML关系图]]></title>
    <url>%2F2017%2F11%2F14%2FUML-%E7%BB%9F%E4%B8%80%E5%BB%BA%E6%A8%A1%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[继承 指的是一个类（称为子类、子接口）继承另外的一个类（称为父类、父接口）的功能，并可以增加它自己的新功能的能力，继承是类与类或者接口与接口之间最常见的关系；在Java中此类关系通过关键字extends明确标识，在设计时一般没有争议性；注意：实心线条，实心三角箭头 实现 指的是一个class类实现interface接口（可以是多个）的功能；实现是类与接口之间最常见的关系；在Java中此类关系通过关键字implements明确标识，在设计时一般没有争议性； 注意：虚线线条，实心三角箭头 依赖 可以简单的理解，就是一个类A使用到了另一个类B，而这种使用关系是具有偶然性的、、临时性的、非常弱的，但是B类的变化会影响到A；比如某人要过河，需要借用一条船，此时人与船之间的关系就是依赖；表现在代码层面，为类B作为参数被类A在某个method方法中使用； 注意：虚心线条，实心普通箭头 关联 他体现的是两个类、或者类与接口之间语义级别的一种强依赖关系，比如我和我的朋友；这种关系比依赖更强、不存在依赖关系的偶然性、关系也不是临时性的，一般是长期性的，而且双方的关系一般是平等的、关联可以是单向、双向的；表现在代码层面，为被关联类B以类属性的形式出现在关联类A中，也可能是关联类A引用了一个类型为被关联类B的全局变量； 注意：实心线条，实心普通箭头 聚合 聚合是关联关系的一种特例，他体现的是整体与部分、拥有的关系，即has-a的关系，此时整体与部分之间是可分离的，他们可以具有各自的生命周期，部分可以属于多个整体对象，也可以为多个整体对象共享；比如计算机与CPU、公司与员工的关系等；表现在代码层面，和关联关系是一致的，只能从语义级别来区分； 组合 组合也是关联关系的一种特例，他体现的是一种contains-a的关系，这种关系比聚合更强，也称为强聚合；他同样体现整体与部分间的关系，但此时整体与部分是不可分的，整体的生命周期结束也就意味着部分的生命周期结束；比如你和你的大脑；表现在代码层面，和关联关系是一致的，只能从语义级别来区分 总结 完。]]></content>
      <categories>
        <category>UML</category>
      </categories>
      <tags>
        <tag>UML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThinkPHP 静态资源，公共模板引用方法]]></title>
    <url>%2F2017%2F11%2F14%2FThinkPHP%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E7%BB%84%E7%BB%87%2F</url>
    <content type="text"><![CDATA[ThinkPHP 静态资源引入 ThinkPHP 项目中静态资源一般放置在项目root目录下的Public文件夹下： 在 template文件夹中放置的是一些静态资源，包含js,css，fronts,img.一般情况下比如说网站首页，网站后台，都是采用引入公共模板的方式，传统的方式是采用frame，现在基本上是将Index页面进行拆分，确定不变的部分并拆分成为独立的公共模板，比如header,slider,footer等。 1 引入公共模板在ThinkPHP项目当中，我们采用标签将公共模板引入进去。file 属性的内容可以是：’模板表达式/相对路径/绝对路径’’ 三种。]]></content>
      <categories>
        <category>ThinkPHP</category>
      </categories>
      <tags>
        <tag>项目实操</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThinkPHP 接入 SeasLog 日志组件]]></title>
    <url>%2F2017%2F11%2F14%2Fthinkphp-SeasLog%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[##【背景】 为实现开发前期联调bug 定位、线上bug快速定位、快速响应，遂暂为斐讯路由后台 Api 模块添加日志记录支持。 ##【SeasLog 简介】 1. 国产log组件 2. 简洁配置 3.应用简单、性能强劲 4.分模块、分级别记录日志。 分模块：如斐讯路由后台分为 Api 模块、后台Admin模块。 分级别：支持8种日志记录级别，对斐讯路由后台来说日志记录级别定义为—debug、info、emergency 即可。 5.日志记录策略：日志-&gt;内存-&gt;文件 更详细介绍，github主页：https://github.com/Neeke/SeasLog ##【SeasLog安装流程】 1.打开网址 http://pecl.php.net/ 2.选择seaslog 并点击获取箭头 3.点击seaslog 4.下载最新版本SeasLog 5.安装php seaslog 扩展5.1解压压缩包 5.2使用phpize 编译安装seaslog 外挂模块 什么是phpize？链接如下：http://blog.csdn.net/czhphp/article/details/68067324 由上至下之行前两个命令，执行完phpize 命令之后，会看到文件夹下多出了 configure 文件夹 5.3执行如下命令 ./configure — with-php-config=(服务器上php安装路径)/usr/local/php/bin/php-config“＝” 后面的路径为本地php-config 目录 5.4执行如下命令 make &amp;&amp; make install 编译 SeasLog 模块 5.5 安装成功，安装成功之后，扩展模块所在文件路径如下图所示/usr/local/Cellar/php55/5.5.38_11/lib/php/extensions/no-debug-non-zts-20121212/ 本机 5.6在php.ini 中配置 seaslog.so 扩展，应该是在etc文件夹下 5.7 重启php应用服务器 5.8 验证 seaslog有没有安装成功，访问phpInfo.php 文件 SeasLog 为国产日志软件，支持！gitHub 地址:https://github.com/Neeke/SeasLog作者自述：https://github.com/Neeke/SeasLog/blob/master/README.md 5.9 在 php.ini 中配置 seaslog 基础配置 关于 SeasLog 的配置跟统一开发环境一致。 5.10 重新访问php info 看是否配置成功 ##【现阶段SeasLog实践情况】 已在统一开发环境实现斐讯路由App 5.0.0 新增接口的日志记录。 若测试环境配置通过，可立即接入。 ##【SeasLog 对 接口响应性能的影响】 理论上SeasLog 对接口响应时间肯定会有延迟影响。 但因SeasLog 对应用系统产生的日志是先写入存储到内存，当内存中写入的日志达到阀值(内存中日志达到1000行刷新一次，一次访问结束刷新一次),便刷新日志内容到文件当中。（缓冲区） 性能测试： 虽有理论支持， 建议仍需要做性能测试。 ##【SeasLog 与 Kibana 结合】 SeasLog 负责生产日志。 Kibana负责消费、分析日志。 烦请运维同事先在测试环境配置、多谢！]]></content>
      <categories>
        <category>ThinkPHP</category>
      </categories>
      <tags>
        <tag>项目实操</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Controller层设置AOP]]></title>
    <url>%2F2017%2F11%2F14%2FSpring-Controller%E5%B1%82%E8%AE%BE%E7%BD%AEAop%2F</url>
    <content type="text"><![CDATA[近期公司需要做一个web项目，项目中有需求是需要记录特定管理员的操作。操作属性包括：操作时间、操作人、触发数据量等。自然而然的就想到了面向切面编程(AOP)。项目初步的技术选型是：Intellij idea+gradle+spring+spring security+hibernate+spring aop+jsp完成项目需求。 项目结构图如下所示：项目创建初期没有web.xml设置如下：file-&gt;project structs-&gt;facets-&gt;web-&gt;Deployment Descriptors-&gt;➕注意创建的web.xml存在位置与上图中的项目结构图是对应的。 1.各配置文件： 1.1 build.gradle 脚本文件12345678910111213141516171819202122232425262728293031323334353637group &apos;com.fxmms&apos;version &apos;1.0-SNAPSHOT&apos;apply plugin: &apos;java&apos;apply plugin: &apos;idea&apos;apply plugin: &apos;war&apos;sourceCompatibility = 1.8repositories &#123; mavenLocal() maven &#123; url &quot;http://maven.aliyun.com/nexus/content/groups/public/&quot; &#125; maven &#123; url &quot;http://repo.maven.apache.org/maven2/&quot;&#125; mavenCentral()&#125;dependencies &#123; testCompile group: &apos;junit&apos;, name: &apos;junit&apos;, version: &apos;4.12&apos; // servlet-api compile group: &apos;javax.servlet&apos;, name: &apos;servlet-api&apos;, version: &apos;2.5&apos; //spring相关 compile group: &apos;org.springframework&apos;, name: &apos;spring-webmvc&apos;, version: &apos;4.3.3.RELEASE&apos; compile group: &apos;org.springframework&apos;, name: &apos;spring-orm&apos;, version: &apos;4.3.3.RELEASE&apos; compile group: &apos;org.springframework&apos;, name: &apos;spring-aspects&apos;, version: &apos;4.3.3.RELEASE&apos; //hibernate jpa相关 compile group: &apos;org.jboss.spec.javax.transaction&apos;, name: &apos;jboss-transaction-api_1.2_spec&apos;, version: &apos;1.0.1.Final&apos; compile group: &apos;org.hibernate&apos;, name: &apos;hibernate-entitymanager&apos;, version: &apos;5.2.2.Final&apos; //c3p0连接池 compile group: &apos;org.hibernate&apos;, name: &apos;hibernate-c3p0&apos;, version: &apos;5.2.2.Final&apos; //ehcahe二级缓存 compile group: &apos;org.hibernate&apos;, name: &apos;hibernate-ehcache&apos;, version: &apos;5.2.2.Final&apos; //mysql compile group: &apos;mysql&apos;, name: &apos;mysql-connector-java&apos;, version: &apos;5.1.39&apos; //springData compile group: &apos;org.springframework.data&apos;, name: &apos;spring-data-jpa&apos;, version: &apos;1.10.3.RELEASE&apos;&#125; 1.2 web.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1"&gt; &lt;!--配置启动IOC容器的Listener--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 配置字符编码过滤器 必须配置在所有过滤器的最前面 --&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 配置看可以把POST请求转为PUT，DELETE请求的Filter --&gt; &lt;filter&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 配置 OpenEntityManagerInViewFilter. 可以解决懒加载异常的问题 --&gt; &lt;filter&gt; &lt;filter-name&gt;OpenEntityManagerInViewFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.orm.jpa.support.OpenEntityManagerInViewFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;OpenEntityManagerInViewFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--配置SpringMVC的DispatcherServlet--&gt; &lt;servlet&gt; &lt;servlet-name&gt;springDispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;&lt;!--这里&lt;span style="font-family: Arial, Helvetica, sans-serif;"&gt;param-name&lt;/span&gt;名称必须为&lt;span style="font-family: Arial, Helvetica, sans-serif;"&gt;contextConfigLocation&lt;/span&gt;--&gt; &lt;param-value&gt;classpath:dispatcher-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springDispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 1.3 Spring 配置文件－applicationContext.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:jpa=&quot;http://www.springframework.org/schema/data/jpa&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa.xsd &quot;&gt; &lt;!-- 配置自动扫描的包 --&gt; &lt;context:component-scan base-package=&quot;com.fxmms&quot;&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot; /&gt; &lt;!--&lt;context:exclude-filter type=&quot;annotation&quot;--&gt; &lt;!--expression=&quot;org.springframework.web.bind.annotation.ControllerAdvice&quot; /&gt;--&gt; &lt;/context:component-scan&gt; &lt;!-- 配置数据源 --&gt; &lt;context:property-placeholder location=&quot;classpath:db.properties&quot; /&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt; &lt;property name=&quot;user&quot; value=&quot;$&#123;jdbc.user&#125;&quot;&gt;&lt;/property&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot;&gt;&lt;/property&gt; &lt;property name=&quot;driverClass&quot; value=&quot;$&#123;jdbc.driverClass&#125;&quot;&gt;&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;$&#123;jdbc.jdbcUrl&#125;&quot;&gt;&lt;/property&gt; &lt;!-- 配置其他属性 --&gt; &lt;property name=&quot;initialPoolSize&quot; value=&quot;$&#123;jdbc.initPoolSize&#125;&quot;&gt;&lt;/property&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;$&#123;jdbc.maxPoolSize&#125;&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置JPA部分 --&gt; &lt;!-- 配置JPA的EntityManagerFactory --&gt; &lt;bean id=&quot;entityManagerFactory&quot; class=&quot;org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt; &lt;property name=&quot;jpaVendorAdapter&quot;&gt; &lt;bean class=&quot;org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter&quot;&gt;&lt;/bean&gt; &lt;/property&gt; &lt;property name=&quot;packagesToScan&quot; value=&quot;com.fxmms&quot;&gt;&lt;/property&gt; &lt;property name=&quot;jpaProperties&quot;&gt; &lt;props&gt; &lt;prop key=&quot;hibernate.ejb.naming_strategy&quot;&gt;org.hibernate.cfg.ImprovedNamingStrategy&lt;/prop&gt; &lt;prop key=&quot;hibernate.hbm2ddl.auto&quot;&gt;update&lt;/prop&gt; &lt;prop key=&quot;hibernate.show_sql&quot;&gt;true&lt;/prop&gt; &lt;prop key=&quot;hibernate.format_sql&quot;&gt;true&lt;/prop&gt; &lt;prop key=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.MySQL5InnoDBDialect&lt;/prop&gt; &lt;prop key=&quot;hibernate.cache.use_second_level_cache&quot;&gt;true&lt;/prop&gt; &lt;prop key=&quot;hibernate.cache.region.factory_class&quot;&gt;org.hibernate.cache.ehcache.EhCacheRegionFactory &lt;/prop&gt; &lt;prop key=&quot;hibernate.cache.use_query_cache&quot;&gt;true&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;!--使用二級緩存--&gt; &lt;property name=&quot;sharedCacheMode&quot; value=&quot;ENABLE_SELECTIVE&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置事务 --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.orm.jpa.JpaTransactionManager&quot;&gt; &lt;property name=&quot;entityManagerFactory&quot; ref=&quot;entityManagerFactory&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置支持基于注解的事务 --&gt; &lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot; /&gt; &lt;!-- 配置SpringData部分 --&gt; &lt;jpa:repositories base-package=&quot;com.fxmms&quot; entity-manager-factory-ref=&quot;entityManagerFactory&quot;&gt; &lt;/jpa:repositories&gt;&lt;/beans&gt; 1.4 Spring mvc配置文件－dispatcher-servlet.xml123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.3.xsd"&gt; &lt;!-- 配置自动扫描的包 --&gt; &lt;context:component-scan base-package="com.fxmms" use-default-filters="true"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;!--&lt;context:include-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice"/&gt;--&gt; &lt;/context:component-scan&gt; &lt;!-- 配置视图解析器 --&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/views/"&gt;&lt;/property&gt; &lt;property name="suffix" value=".jsp"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;mvc:default-servlet-handler/&gt; &lt;mvc:annotation-driven&gt;&lt;/mvc:annotation-driven&gt; &lt;!-- &lt;!– 配置 MultipartResolver 文件上传–&gt; &lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;property name="defaultEncoding" value="UTF-8"&gt;&lt;/property&gt; &lt;property name="maxUploadSize" value="1024000000"&gt;&lt;/property&gt; &lt;/bean&gt;--&gt; &lt;!-- 把切面类交由Spring容器来管理 --&gt; &lt;bean id="logAspectBean" class="com.fxmms.aspect.LogAnnotationAspect"/&gt; &lt;!-- 启用spring对AspectJ注解的支持 --&gt; &lt;aop:aspectj-autoproxy proxy-target-class="true"/&gt;&lt;/beans&gt; 1.5 数据库连接文件jdbc－db.properties 1234567jdbc.user=rootjdbc.password=jdbc.driverClass=com.mysql.jdbc.Driverjdbc.jdbcUrl=jdbc:mysql://localhost/fxmms?useUnicode=true&amp;characterEncoding=UTF-8jdbc.initPoolSize=5jdbc.maxPoolSize=20 1.6 aspect包中切面（封装横切关注点）文件－ LogAnnotationAspect.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.fxmms.aspect;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.*;/** * Created by mark on 16/10/31. * 日志切面类 */@Aspectpublic class LogAnnotationAspect &#123; @SuppressWarnings("unused") //定义切入点 @Pointcut("execution(* com.fxmms.controller.*.*(..))") private void allMethod() &#123; &#125; //针对指定的切入点表达式选择的切入点应用前置通知 @Before("execution(* com.fxmms.controller.*.*(..))") public void before(JoinPoint call) &#123; String className = call.getTarget().getClass().getName(); String methodName = call.getSignature().getName(); System.out.println("【注解-前置通知】:" + className + "类的" + methodName + "方法开始了"); &#125; //访问命名切入点来应用后置通知 @AfterReturning("allMethod()") public void afterReturn() &#123; System.out.println("【注解-后置通知】:方法正常结束了"); &#125; //应用最终通知 @After("allMethod()") public void after() &#123; System.out.println("【注解-最终通知】:不管方法有没有正常执行完成," + "一定会返回的"); &#125; //应用异常抛出后通知 @AfterThrowing("allMethod()") public void afterThrowing() &#123; System.out.println("【注解-异常抛出后通知】:方法执行时出异常了"); &#125; //应用周围通知 //@Around("allMethod()") public Object doAround(ProceedingJoinPoint call) throws Throwable &#123; Object result = null; this.before(call);//相当于前置通知 try &#123; result = call.proceed(); this.afterReturn(); //相当于后置通知 &#125; catch (Throwable e) &#123; this.afterThrowing(); //相当于异常抛出后通知 throw e; &#125; finally &#123; this.after(); //相当于最终通知 &#125; return result; &#125;&#125; 1.7 dao包中数据库访问文件－AccountDao.java12345678910111213package com.fxmms.dao;import org.springframework.stereotype.Component;/** * Created by mark on 16/10/31. */@Componentpublic class AccountDao &#123; public void save(String loginname, String password) &#123; //Do data access System.out.println(&quot;进行数据操作&quot;); &#125;&#125; 1.8 业务逻辑层(service)-AccountService.java 其中注入AccountDao.java123456789101112131415161718package com.fxmms.service;import com.fxmms.dao.AccountDao;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;/** * Created by mark on 16/10/31. */@Componentpublic class AccountService &#123; @Autowired private AccountDao accountDao; public void save(String loginname, String password) &#123; accountDao.save(loginname, password); /*throw new RuntimeException(&quot;故意抛出一个异常。。。。&quot;);*/ &#125;&#125; 1.9 Controller层 IndexController.java 其中注入AccountService.java 123456789101112131415161718192021package com.fxmms.controller;import com.fxmms.service.AccountService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;/** * Created by mark on 16/10/31. */@Controllerpublic class IndexController &#123; @Autowired(required = true) AccountService accountService; @RequestMapping(&quot;/index&quot;) public String index() &#123; accountService.save(&quot;张晓&quot;,&quot;asdasdas&quot;); return &quot;index&quot;; &#125;&#125; 2.测试用例 采用junit进行单元测试代码如下：123456789101112131415import com.fxmms.controller.IndexController;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * Created by mark on 16/10/31. */public class SpringAopTest &#123; @Test public void inteceptorTest() &#123; ApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;dispatcher-servlet.xml&quot;); IndexController bean = (IndexController) ctx.getBean(&quot;indexController&quot;); bean.index(); &#125;&#125; 运行结果：1234【注解-前置通知】:com.fxmms.controller.IndexController类的index方法开始了进行数据操作【注解-最终通知】:不管方法有没有正常执行完成,一定会返回的【注解-后置通知】:方法正常结束了 总结： 当需要在Controller层设置AOP时，那么需要将 配置到dispatcher-servlet.xml(MVC文件当中)当中并且设置包扫描规则为“use-default-filters=”true”。将横切关注点封装为切面，切面中方法的注入是根据切点表达式来决定的。]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>项目实操</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自定义注解与Spring AOP实现日志组件(可重用)]]></title>
    <url>%2F2017%2F11%2F14%2FSpring-Aop%E6%B7%BB%E5%8A%A0%E9%A1%B9%E7%9B%AE%E6%97%A5%E5%BF%97%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[项目需求 需求1: web项目一般而言都需要日志记录，比较常用的是实用log4j来记录项目的异常日志，将日志单独存储于文件当中，这样有利于我们快速进行bug 排解。需求2: 异常的记录一般就是将异常的堆栈保存在文件中，这样文件大小会急剧上升，有效异常信息也不能被立即定位，有没有一种方式可以可以让我们重写异常记录，并保存在异常日志文件当中呢。需求3: 在异常日志之上，我们一般还需要对系统中各角色的各个重要操作进行一些日志记录，以方便我们找到操作人，以及责任人。 针对1中的需求，我们大家熟悉的是实用log4j进行日志记录。配置简单，实现快速。针对2，3中的需求我们一般采用的是基于拦截器实现（Aop思想的一种实现方式）在方法操作之前进行一定的处理，获取操作人、操作方法名、操作参数，异常捕获与记录，这样实现也是完全可以的。今天记录的是基于自定义注解和面向切面(AOP)进行统一操作日志以及异常日志记录的实现。 项目代码 项目中代码如下所示：1.首先定义两个注解：分别为SystemControllerLog(用于拦截Controller层操作注解，起切点表达式作用，明确切面应该从哪里注入),SystemServiceLog(用于拦截Service层操作注解，起切点表达式作用，明确切面应该从哪里注入)这两个注解在切面中定义切点表达式的时候会用到。SystemControllerLog.java12345678910111213package com.fxmms.common.log.logannotation;import java.lang.annotation.*;/** * Created by mark on 16/11/25. * @usage 自定义注解，拦截Controller */@Target(&#123;ElementType.PARAMETER, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface SystemControllerLog &#123; String description() default "";&#125; SystemServiceLog12345678910111213package com.fxmms.common.log.logannotation;import java.lang.annotation.*;/** * Created by mark on 16/11/25. * @usage 自定义注解 拦截service */@Target(&#123;ElementType.PARAMETER, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface SystemServiceLog &#123; String description() default "";&#125; 2.接下来定义切面类，这里面主要定义了几个通知，在调用被代理对象目标方法前后，或目标方法抛出异常之后使用。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175package com.fxmms.common.log.logaspect;import com.fxmms.common.log.logannotation.SystemControllerLog;import com.fxmms.common.log.logannotation.SystemServiceLog;import com.fxmms.common.security.ScottSecurityUtil;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.AfterThrowing;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import org.springframework.web.context.request.RequestContextHolder;import org.springframework.web.context.request.ServletRequestAttributes;import javax.servlet.http.HttpServletRequest;import java.lang.reflect.Method;/** * 切点类 * @author tiangai * @since 2014-08-05 Pm 20:35 * @version 1.0 */@Aspect@Componentpublic class SystemLogAspect &#123; //注入Service用于把日志保存数据库 nodo service 层实现 //本地异常日志记录对象 private static final Logger logger = LoggerFactory.getLogger(SystemLogAspect.class); /** * Service层切点 使用到了我们定义的 SystemServiceLog 作为切点表达式。 * 而且我们可以看出此表达式基于 annotation。 * */ @Pointcut("@annotation(com.fxmms.common.log.logannotation.SystemServiceLog)") public void serviceAspect() &#123; &#125; /** * Controller层切点 使用到了我们定义的 SystemControllerLog 作为切点表达式。 * 而且我们可以看出此表达式是基于 annotation 的。 */ @Pointcut("@annotation(com.fxmms.common.log.logannotation.SystemControllerLog)") public void controllerAspect() &#123; &#125; /** * 前置通知 用于拦截Controller层记录用户的操作 * * @param joinPoint 连接点 */ @Before("controllerAspect()") public void doBefore(JoinPoint joinPoint) &#123; HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); //请求的IP String ip = request.getRemoteAddr(); System.out.println(ip+"sdsdsdsdsd"); try &#123; //控制台输出 System.out.println("=====前置通知开始====="); Object object = joinPoint.getTarget(); System.out.println("请求方法:" + (joinPoint.getTarget().getClass().getName() + "." + joinPoint.getSignature().getName() + "()")); System.out.println("方法描述:" + getControllerMethodDescription(joinPoint)); System.out.println("请求人:" + ScottSecurityUtil.getLoginName()); System.out.println("请求IP:" + ip); //构造数据库日志对象 //保存数据库 System.out.println("=====前置通知结束====="); &#125; catch (Exception e) &#123; //记录本地异常日志 logger.error("==前置通知异常=="); logger.error("异常信息:&#123;&#125;", e.getMessage()); &#125; &#125; /** * 异常通知 用于拦截service层记录异常日志 * * @param joinPoint * @param e */ @AfterThrowing(pointcut = "serviceAspect()", throwing = "e") public void doAfterThrowing(JoinPoint joinPoint, Throwable e) &#123; HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); //获取请求ip String ip = request.getRemoteAddr(); //获取用户请求方法的参数并组织成字符串 String params = ""; if (joinPoint.getArgs() != null &amp;&amp; joinPoint.getArgs().length &gt; 0) &#123; for (int i = 0; i &lt; joinPoint.getArgs().length; i++) &#123; params += joinPoint.getArgs()[i]+ ","; &#125; &#125; try &#123; //控制台输出 System.out.println("=====异常通知开始====="); System.out.println("异常代码:" + e.getClass().getName()); System.out.println("异常信息:" + e.getMessage()); System.out.println("异常方法:" + (joinPoint.getTarget().getClass().getName() + "." + joinPoint.getSignature().getName() + "()")); System.out.println("方法描述:" + getServiceMthodDescription(joinPoint)); System.out.println("请求人:" + ScottSecurityUtil.getLoginName()); System.out.println("请求IP:" + ip); System.out.println("请求参数:" + params); //构造数据库日志对象 //保存数据库 System.out.println("=====异常通知结束====="); &#125; catch (Exception ex) &#123; //记录本地异常日志 logger.error("==异常通知异常=="); logger.error("异常信息:&#123;&#125;", ex); &#125; //录本地异常日志 logger.error("异常方法:&#123;&#125;异常代码:&#123;&#125;异常信息:&#123;&#125;参数:&#123;&#125;", joinPoint.getTarget().getClass().getName() + joinPoint.getSignature().getName(), e.getClass().getName(), e.getMessage(), params); &#125; /** * 获取注解中对方法的描述信息 用于service层注解 * * @param joinPoint 切点 * @return 方法描述 * @throws Exception */ public static String getServiceMthodDescription(JoinPoint joinPoint) throws Exception &#123; String targetName = joinPoint.getTarget().getClass().getName(); String methodName = joinPoint.getSignature().getName(); Object[] arguments = joinPoint.getArgs(); Class targetClass = Class.forName(targetName); Method[] methods = targetClass.getMethods(); String description = ""; for (Method method : methods) &#123; if (method.getName().equals(methodName)) &#123; Class[] clazzs = method.getParameterTypes(); if (clazzs.length == arguments.length) &#123; description = method.getAnnotation(SystemServiceLog.class).description(); break; &#125; &#125; &#125; return description; &#125; /** * 获取注解中对方法的描述信息 用于Controller层注解 * * @param joinPoint 切点 * @return 方法描述 * @throws Exception */ public static String getControllerMethodDescription(JoinPoint joinPoint) throws Exception &#123; String targetName = joinPoint.getTarget().getClass().getName(); String methodName = joinPoint.getSignature().getName(); Object[] arguments = joinPoint.getArgs(); Class targetClass = Class.forName(targetName); Method[] methods = targetClass.getMethods(); String description = ""; for (Method method : methods) &#123; if (method.getName().equals(methodName)) &#123; Class[] clazzs = method.getParameterTypes(); if (clazzs.length == arguments.length) &#123; description = method.getAnnotation(SystemControllerLog.class).description(); break; &#125; &#125; &#125; return description; &#125;&#125; 上面的切面类中定义了公共切点 serviceAspect、serviceAspect，并实现了Controller层的前置通知，Service业务逻辑层的异常通知。其中预留了保存日志到数据库的代码段，我们可以根据业务自行进行填充。3.创建好切点、切面类之后，如何让他起作用呢，我们需要在配置文件中进行配置了。我将web项目中关于不同层的配置文件进行的切割，数据访问层配置文件是data-access.xml、业务逻辑层是service-application.xml、控制层是defalut-servlet.xml首先看defalut-servlet.xml中的配置文件：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt; &lt;!--开启aop--&gt; &lt;aop:aspectj-autoproxy proxy-target-class="true"/&gt; &lt;mvc:annotation-driven&gt; &lt;!--json解析--&gt; &lt;mvc:message-converters&gt; &lt;bean class="org.springframework.http.converter.StringHttpMessageConverter"/&gt; &lt;bean class="org.springframework.http.converter.json.MappingJackson2HttpMessageConverter"/&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; &lt;context:component-scan base-package="com.fxmms.www.controller"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;/context:component-scan&gt; &lt;!--扫描日志记录切面--&gt; &lt;context:component-scan base-package="com.fxmms.common.log" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Component"/&gt; &lt;/context:component-scan&gt; &lt;!--配置异常处理器--&gt; &lt;context:component-scan base-package="com.fxmms.common.exception_handler" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Component"/&gt; &lt;/context:component-scan&gt; &lt;!--因为web.xml中defaultDispatcherServlet对所有请求进行了拦截，所以对一些.css .jpg .html .jsp也进行了拦截，所以此配置项 保证对对静态资源不拦截--&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!--视图解析器--&gt; &lt;bean id="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/views/"/&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt; &lt;!--配置文件上上传--&gt; &lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;property name="defaultEncoding" value="utf-8"/&gt; &lt;property name="maxUploadSize" value="10485760000"/&gt; &lt;property name="maxInMemorySize" value="40960"/&gt; &lt;/bean&gt;&lt;/beans&gt; 注意:以上配置有两个重要的点： 1.项，2. proxy-target-class=”true”默认是false,更改为true时使用的是cglib动态代理。这样只能实现对Controller层的日志记录。 service-application.xml配置AOP，实现对Service层的日志记录. 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:task="http://www.springframework.org/schema/task" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd"&gt; &lt;!--开启AOP--&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;!--设置定时任务--&gt; &lt;task:annotation-driven/&gt; &lt;context:component-scan base-package="com.fxmms.www" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Service"/&gt; &lt;/context:component-scan&gt; &lt;!--ioc管理切面--&gt; &lt;context:component-scan base-package="com.fxmms.common.log" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Component"/&gt; &lt;/context:component-scan&gt; &lt;!-- enable the configuration of transactional behavior based on annotations --&gt; &lt;tx:annotation-driven transaction-manager="txManager"/&gt; &lt;bean id="txManager" class="org.springframework.orm.hibernate4.HibernateTransactionManager"&gt; &lt;property name="sessionFactory" ref="sessionFactory"/&gt; &lt;/bean&gt;&lt;/beans&gt; 这样Service也是可以实现操作、异常日志记录了。4.在代码中使用自定义注解，相当于在目标方法上设置了一个切点，通过切点注入切面。Controller层上运用SystemControllerLog注解:TestNullPointExceptionController.java(验证Controller层中异常，Controller中调用Service层代码)12345678910111213141516171819202122232425262728package com.fxmms.www.controller.admin;import com.fxmms.common.log.logannotation.SystemControllerLog;import com.fxmms.www.service.TestExceptionLog;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;/** * Created by mark on 16/11/25. */@Controllerpublic class TestNullPointExceptionController &#123; private static Log logger = LogFactory.getLog(TestNullPointExceptionController.class); //自动注入一个Service层类对象 @Autowired TestExceptionLog testExceptionLog; @ResponseBody @RequestMapping("/admin/testexcption") @SystemControllerLog(description = "testException")//使用 SystemControllerLog注解，此为切点 public String testException(String str)&#123; return testExceptionLog.equalStr(str); &#125;&#125; TestExceptionLog.java123456789101112131415161718192021222324package com.fxmms.www.service;import com.fxmms.common.log.logannotation.SystemServiceLog;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.springframework.stereotype.Service;/** * Created by mark on 16/11/25. */@Servicepublic class TestExceptionLog &#123; private static Log logger = LogFactory.getLog(TestExceptionLog.class); @SystemServiceLog(description = "equalstr") public String equalStr(String str) &#123; str = null; if (str.equals("sd")) &#123; return "sd"; &#125;else &#123; return "sd"; &#125; &#125;&#125; 我在其中手动设置str = null，用于模拟前台输入。程序在运行时会报运行时异常。最终启动项目项目console日志输出如下图所示： 这样就完成了自定义注解&amp;Aop&amp;自定义异常&amp;操作日志的记录，而且自定义的注解与切面可以进行重用，操作日志与异常日志可以进行数据库记录，后期甚至可以做一个关于异常分析的系统，我们可以直接从日志后台系统中查看异常出现的频率，以及定位异常的发声位置，明确操作人等。完。]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>项目实操</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自定义注解与Spring AOP实现为原程序加入Redis缓存支持(可重用)]]></title>
    <url>%2F2017%2F11%2F14%2FSpring-Aop%2F</url>
    <content type="text"><![CDATA[应用场景 数据访问采用ORM方式（Hibernate） 直接访问数据库，在访问量小、并发性小、数据量小时，可正常访问，反之则服务响应能力低。 目标&amp;要解决的问题 自定义注解&amp;Spring AOP为项目加入Redis缓存依赖提高应用程序的响应能力(可重用) 项目扩充承接于http://www.jianshu.com/p/25039d901ac2 难点 设置缓存的失效策略，缓存数据的Struct选取，切面(Aspect)的编写 方法&amp;扩充步骤1.扩充build.gradle 脚本文件1234567//https://mvnrepository.com/artifact/org.springframework.data/spring-data-redis 项目添加redis支持 compile group: &apos;org.springframework.data&apos;, name: &apos;spring-data-redis&apos;, version: &apos;1.4.1.RELEASE&apos; // https://mvnrepository.com/artifact/redis.clients/jedis redis 基于java的Redis客户端调用实现 compile group: &apos;redis.clients&apos;, name: &apos;jedis&apos;, version: &apos;2.6.1&apos; // https://mvnrepository.com/artifact/com.alibaba/fastjson // 采用阿里巴巴fastjson 进行对象&amp;json字符串的序列化与反序列化 compile group: &apos;com.alibaba&apos;, name: &apos;fastjson&apos;, version: &apos;1.2.21&apos; 2.扩充Spring 配置文件，添加Redis相关Java Bean 到Ioc容器中为了符合开闭原则，重新创建Spring 配置文件 spring-redis.xml1234567891011121314151617181920212223&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxIdle" value="100" /&gt; &lt;!-- &lt;property name="max" value="$&#123;redis.maxActive&#125;" /&gt; &lt;property name="maxWait" value="$&#123;redis.maxWait&#125;" /&gt;--&gt; &lt;property name="testOnBorrow" value="true" /&gt; &lt;/bean&gt; &lt;bean id="connectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory" p:host-name="127.0.0.1" p:port="6379" p:password="ls" p:pool-config-ref="jedisPoolConfig"/&gt; &lt;bean id="redisTemplateForString" class="org.springframework.data.redis.core.StringRedisTemplate"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;/bean&gt;&lt;/beans&gt; 3.自定义两个注解 RedisCahe: 标识缓存 注解 RedisEvit: 标识缓存清除 注解 代码如下：RedisCahe.java1234567891011121314package com.fxmms.common.rediscache.redisannotation;import java.lang.annotation.*;/** * Created by mark on 16/11/29. * @usage 缓存注解类 */@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)@Documentedpublic @interface RedisCache &#123; Class type();//被代理类的全类名，在之后会做为redis hash 的key&#125; RedisEvit.java12345678910111213141516package com.fxmms.common.rediscache.redisannotation;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * Created by mark on 16/11/29. * @usage 清除过期缓存注解，放置于update delete insert 类型逻辑之上 */@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface RedisEvict &#123; Class type();&#125; 4.RedisCacheAspect.java 切面程序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189package com.fxmms.common.rediscache.redisaspect;import com.fxmms.common.rediscache.redisannotation.RedisCache;import com.fxmms.common.rediscache.redisannotation.RedisEvict;import com.fxmms.common.util.FastJsonUtil;import com.fxmms.common.util.JsonUtil;import org.apache.log4j.Logger;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Pointcut;import org.aspectj.lang.reflect.MethodSignature;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Component;import java.lang.reflect.Method;import java.util.List;/** * Created by mark on 16/11/29. */@Aspect@Component@SuppressWarnings(value = &#123;"rawtypes", "unchecked"&#125;)public class RedisCacheAspect &#123; private static final Logger logger = Logger.getLogger(RedisCacheAspect.class); /** * 分隔符 生成key 格式为 类全类名|方法名|参数所属类全类名 **/ private static final String DELIMITER = "|"; /** * spring-redis.xml配置连接池、连接工厂、Redis模板 **/ @Autowired @Qualifier("redisTemplateForString") StringRedisTemplate srt; /** * Service层切点 使用到了我们定义的 RedisCache 作为切点表达式。 * 而且我们可以看出此表达式基于 annotation。 * 并且用于内建属性为查询的方法之上 */ @Pointcut("@annotation(com.fxmms.common.rediscache.redisannotation.RedisCache)") public void redisCacheAspect() &#123; &#125; /** * Service层切点 使用到了我们定义的 RedisEvict 作为切点表达式。 * 而且我们可以看出此表达式是基于 annotation 的。 * 并且用于内建属性为非查询的方法之上，用于更新表 */ @Pointcut("@annotation(com.fxmms.common.rediscache.redisannotation.RedisEvict)") public void redisCacheEvict() &#123; &#125; @Around("redisCacheAspect()") public Object cache(ProceedingJoinPoint joinPoint) &#123; // 得到类名、方法名和参数 String clazzName = joinPoint.getTarget().getClass().getName(); String methodName = joinPoint.getSignature().getName(); Object[] args = joinPoint.getArgs(); // 根据类名、方法名和参数生成Key logger.info("key参数: " + clazzName + "." + methodName); //System.out.println("key参数: " + clazzName + "." + methodName); String key = getKey(clazzName, methodName, args); if (logger.isInfoEnabled()) &#123; logger.info("生成key: " + key); &#125; // 得到被代理的方法 Method method = ((MethodSignature) joinPoint.getSignature()).getMethod(); // 得到被代理的方法上的注解 Class modelType = method.getAnnotation(RedisCache.class).type(); // 检查Redis中是否有缓存 String value = (String) srt.opsForHash().get(modelType.getName(), key); // 得到被代理方法的返回值类型 Class returnType = ((MethodSignature) joinPoint.getSignature()).getReturnType(); // result是方法的最终返回结果 Object result = null; try &#123; if (null == value) &#123; if (logger.isInfoEnabled()) &#123; logger.info("缓存未命中"); &#125; // 调用数据库查询方法 result = joinPoint.proceed(args); // 序列化查询结果 String json = FastJsonUtil.toJsonString(result); //String json = GsonUtil.toJson(result); System.out.println("打印："+json); // 序列化结果放入缓存 srt.opsForHash().put(modelType.getName(), key, json); &#125; else &#123; // 缓存命中 if (logger.isInfoEnabled()) &#123; logger.info("缓存命中, value = " + value); &#125; result = value; // 反序列化 从缓存中拿到的json字符串 result = FastJsonUtil.toObject(value, returnType); //result = GsonUtil.fromJson(value,returnType); System.out.println(result.toString()); if (logger.isInfoEnabled()) &#123; logger.info("gson反序列化结果 = " + result); &#125; &#125; &#125; catch (Throwable e) &#123; logger.error("解析异常",e); &#125; return result; &#125; /** * * 在方法调用前清除缓存，然后调用业务方法 * * @param joinPoint * * @return * * @throws Throwable * */ @Around("redisCacheEvict()") public Object evictCache(ProceedingJoinPoint joinPoint) throws Throwable &#123; // 得到被代理的方法 Method method = ((MethodSignature) joinPoint.getSignature()).getMethod(); // 得到被代理的方法上的注解 Class modelType = method.getAnnotation(RedisEvict.class).type(); if (logger.isInfoEnabled()) &#123; logger.info("清空缓存 = " + modelType.getName()); &#125; // 清除对应缓存 srt.delete(modelType.getName()); return joinPoint.proceed(joinPoint.getArgs()); &#125; /** * @param json * @param clazz * @param modelType * @return 反序列化json字符串 * Question 遇到问题，如何将复杂json字符串解析为复杂java object */ private Object deserialize(String json, Class clazz, Class modelType) &#123; // 序列化结果是List对象 if (clazz.isAssignableFrom(List.class)) &#123; return JsonUtil.jsonToList(json, modelType); &#125; // 序列化结果是普通对象 return JsonUtil.jsonToPojo(json, clazz); &#125; private String serialize(Object result, Class clazz) &#123; return JsonUtil.objectToJson(result); &#125; /** * * 根据类名、方法名和参数生成Key * * @param clazzName * * @param methodName * * @param args * * @return key格式：全类名|方法名｜参数类型 * */ private String getKey(String clazzName, String methodName, Object[] args) &#123; StringBuilder key = new StringBuilder(clazzName); key.append(DELIMITER); key.append(methodName); key.append(DELIMITER); for (Object obj : args) &#123; key.append(obj.getClass().getSimpleName()); key.append(DELIMITER); &#125; return key.toString(); &#125;&#125; 5.FastJsonUtil.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 package com.fxmms.common.util;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.serializer.SerializerFeature;import com.alibaba.fastjson.serializer.ValueFilter;import java.util.List;/** * Created by mark on 16/11/30. * 采用阿里巴巴fastjson 进行对象&amp;json字符串的序列化与反序列化 */public class FastJsonUtil &#123; /** * @param object * @return 将java对象转化为json字符串 */ public static String toJsonString(Object object) &#123; return JSON.toJSONString(object,filter,SerializerFeature.DisableCircularReferenceDetect); &#125; /** * 添加过滤器使数据库中字段为NULL的字段为"" */ private static ValueFilter filter = new ValueFilter() &#123; @Override public Object process(Object obj, String s, Object v) &#123; if (v == null) return ""; return v; &#125; &#125;; /** * @param json * @param cla * @param &lt;T&gt; * @return 将json字符串转化为java对象 */ public static &lt;T&gt; T toObject(String json, Class&lt;T&gt; cla) &#123; return JSON.parseObject(json, cla); &#125; public static &lt;T&gt; List&lt;T&gt; toList(String json, Class&lt;T&gt; t) &#123; return JSON.parseArray(json, t); &#125;&#125; 6.业务逻辑层设置缓存即扩充service-applicationContext.xml加入切面支持12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:task="http://www.springframework.org/schema/task" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd"&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;!--设置定时任务--&gt; &lt;task:annotation-driven/&gt; &lt;context:component-scan base-package="com.fxmms.www" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Service"/&gt; &lt;/context:component-scan&gt; &lt;!--扫描日志切面--&gt; &lt;context:component-scan base-package="com.fxmms.common.log" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Component"/&gt; &lt;/context:component-scan&gt; &lt;!--扫描redis切面--&gt; &lt;context:component-scan base-package="com.fxmms.common.rediscache.redisaspect" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Component"&gt;&lt;/context:include-filter&gt; &lt;/context:component-scan&gt; &lt;!-- enable the configuration of transactional behavior based on annotations --&gt; &lt;tx:annotation-driven transaction-manager="txManager"/&gt; &lt;bean id="txManager" class="org.springframework.orm.hibernate4.HibernateTransactionManager"&gt; &lt;property name="sessionFactory" ref="sessionFactory"/&gt; &lt;/bean&gt;&lt;/beans&gt; 7.业务逻辑层应用缓存123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262package com.fxmms.www.service;import com.fxmms.common.jniutil.GetDownloadIDUtil;import com.fxmms.common.macutil.CountBetweenMacByMacStr;import com.fxmms.common.poiutil.ReadExcelUtil;import com.fxmms.common.rediscache.redisannotation.RedisCache;import com.fxmms.common.rediscache.redisannotation.RedisEvict;import com.fxmms.common.ro.ControllerResult;import com.fxmms.common.ro.DtoResultWithPageInfo;import com.fxmms.www.dao.AdminDao;import com.fxmms.www.dao.MacDao;import com.fxmms.www.dao.TaskDao;import com.fxmms.www.domain.Admin;import com.fxmms.www.domain.Mac;import com.fxmms.www.domain.Task;import com.fxmms.www.dto.MacDto;import com.fxmms.www.qo.MacQo;import com.fxmms.www.thunderinterfaceutil.VisitThunderInterface;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;import java.io.File;import java.util.ArrayList;import java.util.Date;import java.util.List;/** * Created by mark on 16/11/7. * * @usage Mac地址操作业务逻辑层 */@Servicepublic class MacService &#123; @Autowired MacDao macDao; @Autowired AdminDao adminDao; @Autowired TaskDao taskDao; /** * @param macStr * @param username * @return mac * @usage 判断数据库中是否已经存储过对应的mac * 防止数据库中存储多个同样的mac地址 */ @Transactional @RedisEvict(type=Mac.class) public Mac doJudgementBySingleMacStr(String macStr, String username) &#123; Mac mac = macDao.getByUniqueKey("macAddr", macStr); if (mac == null) &#123; //1.单个mac地址转化为downloadId String downLoadId = GetDownloadIDUtil.getDownLoadId(macStr); Task task = new Task();//单个mac所属task's id task.setDate(new Date()); task.setFlag(0);//录入未成功 taskDao.save(task); Admin admin = adminDao.getByUniqueKey("userName", username); mac = new Mac(); mac.setDownLoadId(downLoadId); mac.setAdmin(admin); mac.setMacAddr(macStr); mac.setDate(new Date()); //设置mac状态为init状态 mac.setStatus(0); mac.setTask(task); macDao.save(mac); &#125; return mac; &#125; /** * @param macStrList * @param username * @usage 判断数据库中是否已经存储过对应的mac * 防止数据库中存储多个同样的mac地址 */ @Transactional @RedisEvict(type=Mac.class) public void doJudgementBySeriseMacStr(List&lt;String&gt; macStrList, String username) &#123; Task task = new Task();//单个mac所属task's id task.setDate(new Date()); task.setFlag(0);//初始化task 状态为录入未成功 for (String macStr : macStrList) &#123; Mac mac = macDao.getByUniqueKey("macAddr", macStr); if (mac == null) &#123; //1.单个mac地址转化为downloadId String downLoadId = GetDownloadIDUtil.getDownLoadId(macStr); taskDao.save(task); Admin admin = adminDao.getByUniqueKey("userName", username); mac = new Mac(); mac.setDownLoadId(downLoadId); mac.setAdmin(admin); mac.setMacAddr(macStr); mac.setDate(new Date()); //设置mac状态为init状态 mac.setStatus(0); mac.setTask(task); macDao.save(mac); &#125; &#125; &#125; /** * @param macStr * @param username * @return 1.单个mac地址转化为downloadId, 并调用迅雷方接口 * 2.调用接口之前先将地址存储为数据库中一条记录，状态置为0-初始化状态 * 3.调用完接口根据返回状态，将返回状态为success的数据置为1-正在录入 */ @Transactional @RedisEvict(type=Mac.class) public ControllerResult addSingleMac(String macStr, String username) &#123; if (macStr == null || ("".equals(macStr))) &#123; return ControllerResult.valueOf(ControllerResult.ERROR, "对不起，MAC地址不能为空"); &#125; if (!CountBetweenMacByMacStr.matchMacAddrByregex(macStr)) &#123; return ControllerResult.valueOf(ControllerResult.ERROR, "对不起，MAC地址格式不正确"); &#125; List&lt;String&gt; macStrList = new ArrayList&lt;&gt;(); macStrList.add(macStr); Mac mac = doJudgementBySingleMacStr(macStr, username); //调用迅雷录入接口。 if (VisitThunderInterface.addDownLoadId(macStrList)) &#123; Admin admin = adminDao.getByUniqueKey("userName", username); if (mac.getStatus() != 2) &#123; mac.setStatus(1); mac.setDate(new Date()); mac.setAdmin(admin); macDao.update(mac); &#125; return ControllerResult.valueOf(ControllerResult.SUCCESS, "迅雷录入接口请求成功", mac); &#125; else &#123; Admin admin = adminDao.getByUniqueKey("userName", username); if (mac.getStatus() != 2) &#123; mac.setStatus(3); mac.setDate(new Date()); mac.setAdmin(admin); macDao.update(mac); return ControllerResult.valueOf(ControllerResult.ERROR, "对不起,请求迅雷录入接口失败!&lt;a href='admin/addsinglemac'&gt;重新录入&lt;/a&gt;"); &#125; return ControllerResult.valueOf(ControllerResult.ERROR, "此条mac地址已经录入成功"); &#125; &#125; /** * @param startMacStr * @param endMacStr * @param username * @return * @usage 批量区间录入业务逻辑方法 */ @Transactional @RedisEvict(type=Mac.class) public ControllerResult addSeriseMac(String startMacStr, String endMacStr, String username) &#123; if (startMacStr == null || ("".equals(startMacStr)) || endMacStr == null || ("".equals(endMacStr))) &#123; return ControllerResult.valueOf(ControllerResult.ERROR, "对不起，MAC地址不能为空"); &#125; if (!CountBetweenMacByMacStr.matchMacAddrByregex(startMacStr) || !CountBetweenMacByMacStr.matchMacAddrByregex(endMacStr)) &#123; return ControllerResult.valueOf(ControllerResult.ERROR, "对不起，MAC地址格式不正确"); &#125; List&lt;String&gt; macStrList = CountBetweenMacByMacStr.countBetweenMacByMacStr(startMacStr, endMacStr); if (macStrList.size() &gt; 1000) &#123; return ControllerResult.valueOf(ControllerResult.ERROR, "对不起，MAC区间太长，请拆分后录入。&lt;a href='admin/addserisemacs'&gt;重新录入&lt;/a&gt;"); &#125; doJudgementBySeriseMacStr(macStrList, username); if (VisitThunderInterface.addDownLoadId(macStrList)) &#123; for (String macStr : macStrList) &#123; Mac mac = macDao.getByUniqueKey("macAddr", macStr); Admin admin = adminDao.getByUniqueKey("userName", username); if (mac.getStatus() != 2) &#123; mac.setStatus(1); mac.setDate(new Date()); mac.setAdmin(admin); macDao.update(mac); &#125; &#125; return ControllerResult.valueOf(ControllerResult.SUCCESS, "录入成功"); &#125; else &#123; for (String macStr : macStrList) &#123; Mac mac = macDao.getByUniqueKey("macAddr", macStr); Admin admin = adminDao.getByUniqueKey("userName", username); if (mac.getStatus() != 2) &#123; mac.setStatus(3); mac.setDate(new Date()); mac.setAdmin(admin); macDao.update(mac); &#125; &#125; return ControllerResult.valueOf(ControllerResult.ERROR, "对不起,请求迅雷录入接口失败!&lt;a href='admin/addserisemacs'&gt;重新录入&lt;/a&gt;"); &#125; &#125; /** * @param macQo * @return * @usage 获取所有的mac录入状态数据业务逻辑方法 */ @RedisCache(type=Mac.class) @Transactional public ControllerResult getAllMacStatus(MacQo macQo) &#123; DtoResultWithPageInfo&lt;MacDto&gt; info = macDao.queryPageListByCriteriaWithQo(macQo, MacDto.class); return ControllerResult.valueOf(ControllerResult.SUCCESS, "获取mac录入状态成功", info); &#125; /** * @param serverFile * @param username * @return * @usage 非连续mac地址录入逻辑方法 */ @Transactional @RedisEvict(type=Mac.class) public ControllerResult addNoOrderMac(File serverFile, String username) &#123; ReadExcelUtil readExcelUtil = new ReadExcelUtil(); try &#123; List&lt;String&gt; macStrList = readExcelUtil.readUploadMacFile(serverFile); if (macStrList.size() == 0 || macStrList == null) &#123; return ControllerResult.valueOf(ControllerResult.ERROR, "对不起，文件中MAC数据不能为空"); &#125; if (macStrList.size() &gt; 1000) &#123; return ControllerResult.valueOf(ControllerResult.ERROR, "对不起，文件中数据超过1000条，请进行拆分后上传！"); &#125; for (String inFilemacStr : macStrList) &#123; if (!CountBetweenMacByMacStr.matchMacAddrByregex(inFilemacStr)) &#123; return ControllerResult.valueOf(ControllerResult.ERROR, "对不起，文件中有不合法的MAC地址"); &#125; &#125; doJudgementBySeriseMacStr(macStrList, username); if (VisitThunderInterface.addDownLoadId(macStrList)) &#123; for (String macStr : macStrList) &#123; Mac mac = macDao.getByUniqueKey("macAddr", macStr); Admin admin = adminDao.getByUniqueKey("userName", username); if (mac.getStatus() != 2) &#123; mac.setStatus(1); mac.setDate(new Date()); mac.setAdmin(admin); macDao.update(mac); &#125; &#125; return ControllerResult.valueOf(ControllerResult.SUCCESS, "请求迅雷录入接口成功"); &#125; else &#123; for (String macStr : macStrList) &#123; Mac mac = macDao.getByUniqueKey("macAddr", macStr); Admin admin = adminDao.getByUniqueKey("userName", username); if (mac.getStatus() != 2) &#123; mac.setStatus(3); mac.setAdmin(admin); mac.setDate(new Date()); macDao.update(mac); &#125; &#125; return ControllerResult.valueOf(ControllerResult.ERROR, "对不起,请求迅雷录入接口失败!&lt;a href='admin/loadnoordermacs'&gt;重新录入&lt;/a&gt;"); &#125; &#125; catch (Exception e) &#123; return ControllerResult.valueOf(ControllerResult.ERROR, "文件上传失败"); &#125; &#125;&#125; 注意： 上述程序中为非查询方法上加上了 @RedisEvict注解，表示删除旧的缓存。 上述程序中为查询方法上加上了 @RedisCache注解，表示为查询业务逻辑应用缓存，应用逻辑为：项目中缓存数据的Struct为Hash，每张表对应的实体类使用一个名为Key的Hash结构来存储数据，当访问的key 存在时，直接从缓存中取出数据，不存在时第一步先从数据库中查询数据，再生成key，并生成对应的filed与value。 程序运行结果：12342016-12-03 20:16:05,212 [INFO]-[com.fxmms.common.rediscache.redisaspect.RedisCacheAspect.cache(RedisCacheAspect.java:67)] key参数: com.fxmms.www.service.MacService.getAllMacStatus2016-12-03 20:16:05,219 [INFO]-[com.fxmms.common.rediscache.redisaspect.RedisCacheAspect.cache(RedisCacheAspect.java:71)] 生成key: com.fxmms.www.service.MacService|getAllMacStatus|MacQo|2016-12-03 20:16:05,357 [INFO]-[com.fxmms.common.rediscache.redisaspect.RedisCacheAspect.cache(RedisCacheAspect.java:108)] 缓存命中, value = &#123;&quot;msg&quot;:&quot;获取mac录入状态成功&quot;,&quot;result&quot;:&quot;success&quot;,&quot;rows&quot;:&#123;&quot;emptyResult&quot;:false,&quot;pageInfo&quot;:&#123;&quot;firstPage&quot;:true,&quot;firstResultNum&quot;:0,&quot;lastPage&quot;:false,&quot;lastResultNum&quot;:10,&quot;pageNo&quot;:1,&quot;pageSize&quot;:10,&quot;totalPage&quot;:49,&quot;totalQuantity&quot;:488&#125;,&quot;results&quot;:[&#123;&quot;admin&quot;:&#123;&quot;enable&quot;:1,&quot;id&quot;:1,&quot;isDelete&quot;:0,&quot;password&quot;:&quot;11&quot;,&quot;role&quot;:&quot;admin&quot;,&quot;userName&quot;:&quot;ls&quot;&#125;,&quot;date&quot;:1479913221000,&quot;dateStr&quot;:&quot;2016-11-23 23:00:21&quot;,&quot;deviceId&quot;:&quot;730CBAEA-6954-000A-2D77-BAF544E6F192&quot;,&quot;downLoadId&quot;:&quot;11123E566745FB30FE5C9AC094A1BAA0&quot;,&quot;id&quot;:488,&quot;macAddr&quot;:&quot;11:12:3e:56:67:45&quot;,&quot;status&quot;:2,&quot;statusStr&quot;:&quot;&lt;span class=\&quot;label label-success\&quot;&gt;录入成功&lt;/span&gt;&quot;,&quot;task&quot;:&#123;&quot;date&quot;:1479913220000,&quot;flag&quot;:1,&quot;id&quot;:29&#125;&#125;,&#123;&quot;admin&quot;:&#123;&quot;enable&quot;:1,&quot;id&quot;:1,&quot;isDelete&quot;:0,&quot;password&quot;:&quot;11&quot;,&quot;role&quot;:&quot;admin&quot;,&quot;userName&quot;:&quot;ls&quot;&#125;,&quot;date&quot;:1479448899000,&quot;dateStr&quot;:&quot;2016-11-18 14:01:39&quot;,&quot;deviceId&quot;:&quot;&quot;,&quot;downLoadId&quot;:&quot;34BDF9C0B2C1EC6B5CA3B81DCB05241D&quot;,&quot;id&quot;:487,&quot;macAddr&quot;:&quot;34:BD:F9:C0:B2:c1&quot;,&quot;status&quot;:3,&quot;statusStr&quot;:&quot;&lt;span class=\&quot;label label-danger\&quot;&gt;录入失败&lt;/span&gt;&quot;,&quot;task&quot;:&#123;&quot;date&quot;:1479448898000,&quot;flag&quot;:0,&quot;id&quot;:28&#125;&#125;,&#123;&quot;admin&quot;:&#123;&quot;enable&quot;:1,&quot;id&quot;:1,&quot;isDelete&quot;:0,&quot;password&quot;:&quot;11&quot;,&quot;role&quot;:&quot;admin&quot;,&quot;userName&quot;:&quot;ls&quot;&#125;,&quot;date&quot;:1479448476000,&quot;dateStr&quot;:&quot;2016-11-18 13:54:36&quot;,&quot;deviceId&quot;:&quot;&quot;,&quot;downLoadId&quot;:&quot;11123E586745088C6CAF8E6C2EBDB7A5&quot;,&quot;id&quot;:486,&quot;macAddr&quot;:&quot;11:12:3e:58:67:45&quot;,&quot;status&quot;:3,&quot;statusStr&quot;:&quot;&lt;span class=\&quot;label label-danger\&quot;&gt;录入失败&lt;/span&gt;&quot;,&quot;task&quot;:&#123;&quot;date&quot;:1479448476000,&quot;flag&quot;:0,&quot;id&quot;:27&#125;&#125;,&#123;&quot;admin&quot;:&#123;&quot;enable&quot;:1,&quot;id&quot;:1,&quot;isDelete&quot;:0,&quot;password&quot;:&quot;11&quot;,&quot;role&quot;:&quot;admin&quot;,&quot;userName&quot;:&quot;ls&quot;&#125;,&quot;date&quot;:1479447598000,&quot;dateStr&quot;:&quot;2016-11-18 13:39:58&quot;,&quot;deviceId&quot;:&quot;&quot;,&quot;downLoadId&quot;:&quot;34BDFAC0B2F01A731572C0BCEC4D26F0&quot;,&quot;id&quot;:485,&quot;macAddr&quot;:&quot;34:BD:FA:C0:B2:F0&quot;,&quot;status&quot;:3,&quot;statusStr&quot;:&quot;&lt;span class=\&quot;label label-danger\&quot;&gt;录入失败&lt;/span&gt;&quot;,&quot;task&quot;:&#123;&quot;date&quot;:1479447598000,&quot;flag&quot;:0,&quot;id&quot;:26&#125;&#125;,&#123;&quot;admin&quot;:&#123;&quot;enable&quot;:1,&quot;id&quot;:1,&quot;isDelete&quot;:0,&quot;password&quot;:&quot;11&quot;,&quot;role&quot;:&quot;admin&quot;,&quot;userName&quot;:&quot;ls&quot;&#125;,&quot;date&quot;:1479447575000,&quot;dateStr&quot;:&quot;2016-11-18 13:39:35&quot;,&quot;deviceId&quot;:&quot;&quot;,&quot;downLoadId&quot;:&quot;3EBDF9C0B2F02D7F2A6CAC4F2B5121E8&quot;,&quot;id&quot;:484,&quot;macAddr&quot;:&quot;3e:BD:F9:C0:B2:F0&quot;,&quot;status&quot;:3,&quot;statusStr&quot;:&quot;&lt;span class=\&quot;label label-danger\&quot;&gt;录入失败&lt;/span&gt;&quot;,&quot;task&quot;:&#123;&quot;date&quot;:1479447575000,&quot;flag&quot;:0,&quot;id&quot;:25&#125;&#125;,&#123;&quot;admin&quot;:&#123;&quot;enable&quot;:1,&quot;id&quot;:1,&quot;isDelete&quot;:0,&quot;password&quot;:&quot;11&quot;,&quot;role&quot;:&quot;admin&quot;,&quot;userName&quot;:&quot;ls&quot;&#125;,&quot;date&quot;:1479446783000,&quot;dateStr&quot;:&quot;2016-11-18 13:26:23&quot;,&quot;deviceId&quot;:&quot;&quot;,&quot;downLoadId&quot;:&quot;11128E566749F8776504253D15D8B001&quot;,&quot;id&quot;:483,&quot;macAddr&quot;:&quot;11:12:8e:56:67:49&quot;,&quot;status&quot;:3,&quot;statusStr&quot;:&quot;&lt;span class=\&quot;label label-danger\&quot;&gt;录入失败&lt;/span&gt;&quot;,&quot;task&quot;:&#123;&quot;date&quot;:1479446783000,&quot;flag&quot;:0,&quot;id&quot;:24&#125;&#125;,&#123;&quot;admin&quot;:&#123;&quot;enable&quot;:1,&quot;id&quot;:1,&quot;isDelete&quot;:0,&quot;password&quot;:&quot;11&quot;,&quot;role&quot;:&quot;admin&quot;,&quot;userName&quot;:&quot;ls&quot;&#125;,&quot;date&quot;:1479446754000,&quot;dateStr&quot;:&quot;2016-11-18 13:25:54&quot;,&quot;deviceId&quot;:&quot;&quot;,&quot;downLoadId&quot;:&quot;11128E566745B130B2E6C6AA8E52EB4A&quot;,&quot;id&quot;:482,&quot;macAddr&quot;:&quot;11:12:8e:56:67:45&quot;,&quot;status&quot;:3,&quot;statusStr&quot;:&quot;&lt;span class=\&quot;label label-danger\&quot;&gt;录入失败&lt;/span&gt;&quot;,&quot;task&quot;:&#123;&quot;date&quot;:1479446753000,&quot;flag&quot;:0,&quot;id&quot;:23&#125;&#125;,&#123;&quot;admin&quot;:&#123;&quot;enable&quot;:1,&quot;id&quot;:1,&quot;isDelete&quot;:0,&quot;password&quot;:&quot;11&quot;,&quot;role&quot;:&quot;admin&quot;,&quot;userName&quot;:&quot;ls&quot;&#125;,&quot;date&quot;:1479446736000,&quot;dateStr&quot;:&quot;2016-11-18 13:25:36&quot;,&quot;deviceId&quot;:&quot;&quot;,&quot;downLoadId&quot;:&quot;341DF9C0B2F11E391DDA8EDAB78B4162&quot;,&quot;id&quot;:481,&quot;macAddr&quot;:&quot;34:1D:F9:C0:B2:F1&quot;,&quot;status&quot;:3,&quot;statusStr&quot;:&quot;&lt;span class=\&quot;label label-danger\&quot;&gt;录入失败&lt;/span&gt;&quot;,&quot;task&quot;:&#123;&quot;date&quot;:1479446736000,&quot;flag&quot;:0,&quot;id&quot;:22&#125;&#125;,&#123;&quot;admin&quot;:&#123;&quot;enable&quot;:1,&quot;id&quot;:1,&quot;isDelete&quot;:0,&quot;password&quot;:&quot;11&quot;,&quot;role&quot;:&quot;admin&quot;,&quot;userName&quot;:&quot;ls&quot;&#125;,&quot;date&quot;:1479437904000,&quot;dateStr&quot;:&quot;2016-11-18 10:58:24&quot;,&quot;deviceId&quot;:&quot;&quot;,&quot;downLoadId&quot;:&quot;11446633889613659EE26ABE4FBE28CD&quot;,&quot;id&quot;:480,&quot;macAddr&quot;:&quot;11:44:66:33:88:96&quot;,&quot;status&quot;:3,&quot;statusStr&quot;:&quot;&lt;span class=\&quot;label label-danger\&quot;&gt;录入失败&lt;/span&gt;&quot;,&quot;task&quot;:&#123;&quot;date&quot;:1479437904000,&quot;flag&quot;:0,&quot;id&quot;:21&#125;&#125;,&#123;&quot;admin&quot;:&#123;&quot;enable&quot;:1,&quot;id&quot;:1,&quot;isDelete&quot;:0,&quot;password&quot;:&quot;11&quot;,&quot;role&quot;:&quot;admin&quot;,&quot;userName&quot;:&quot;ls&quot;&#125;,&quot;date&quot;:1479437899000,&quot;dateStr&quot;:&quot;2016-11-18 10:58:19&quot;,&quot;deviceId&quot;:&quot;&quot;,&quot;downLoadId&quot;:&quot;1144663388947CCC987231F802C72F83&quot;,&quot;id&quot;:479,&quot;macAddr&quot;:&quot;11:44:66:33:88:94&quot;,&quot;status&quot;:3,&quot;statusStr&quot;:&quot;&lt;span class=\&quot;label label-danger\&quot;&gt;录入失败&lt;/span&gt;&quot;,&quot;task&quot;:&#123;&quot;date&quot;:1479437899000,&quot;flag&quot;:0,&quot;id&quot;:20&#125;&#125;]&#125;,&quot;total&quot;:0&#125;` 完。]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>项目实操</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单工厂模式]]></title>
    <url>%2F2017%2F11%2F14%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%2F</url>
    <content type="text"><![CDATA[创建型设计模式： 简单工厂模式、工厂方法模式、抽象工厂模式、单例模式、原型模式和建造者模式。 统共六种。 本此分享三种工厂模式中的简单工厂模式。 记录结构： –1.实际问题引入（需求） –2.传统解决办法 –3.传统解决办法带来的问题 –4.使用xx模式解决问题 –4.1xx模式简述 –4.2xx模式类图表示 –4.3xx模式完整解决方案 –5.方案改进 –6.模式总结1.简单工厂模式： 1.1实际问题引入 YY软件公司欲基于 Java 语言开发一套图表库,该图表库可以为应用系统提供各种不同外观的图表,例如柱 状图、饼状图、折线图等。Sunny 软件公司图表库设计人员希望为应用系统开发人员提供一套灵活易用的图表 库,而且可以较为方便地对图表库进行扩展,以便能够在将来增加一些新类型的图表。 2.2传统解决办法： Sunny 软件公司图表库设计人员提出了一个初始设计方案,将所有图表的实现代码封装在一个 Chart 类中,其框 架代码如下所示: /** Created by tao.liu on 16/10/18. */ class Chart { private String type; //图表类型 public Chart(Object[][] data, String type) { this.type = type; if (type.equalsIgnoreCase(“histogram”)) { //初始化柱状图 } else if (type.equalsIgnoreCase(“pie”)) { //初始化饼状图 } else if (type.equalsIgnoreCase(“line”)) { //初始化折线图 } } public void display() { if (this.type.equalsIgnoreCase(“histogram”)) { //显示柱状图 } else if (this.type.equalsIgnoreCase(“pie”)) { //显示饼状图 } else if (this.type.equalsIgnoreCase(“line”)) { //显示折线图 } } } 客户端代码通过调用 Chart 类的构造函数来创建图表对象,根据参数 type 的不同可以得到不同类型的图表,然 后再调用 display() 方法来显示相应的图表。 3.传统解决办法带来的问题 不难看出,Chart 类是一个“巨大的”类,在该类的设计中存在如下几个问题: (1) 在 Chart 类中包含很多if…else…代码块,整个类的代码相当冗长,代码越长,阅读难度、维护难度和测试 难度也越大;而且大量条件语句的存在还将影响系统的性能,程序在执行过程中需要做大量的条件判断。 (2) Chart 类的职责过重,它负责初始化和显示所有的图表对象,将各种图表对象的初始化代码和显示代码集中在 一个类中实现,违反了“单一职责原则”,不利于类的重用和维护;而且将大量的对象初始化代码都写在构造函 数中将导致构造函数非常庞大,对象在创建时需要进行条件判断,降低了对象创建的效率。 (3) 当需要增加新类型的图表时,必须修改 Chart 类的源代码,违反了“开闭原则”。 (4) 客户端只能通过 new 关键字来直接创建 Chart 对象,Chart 类与客户端类耦合度较高,对象的创建和使用无 法分离。 (5) 客户端在创建 Chart 对象之前可能还需要进行大量初始化设置,例如设置柱状图的颜色、高度等,如果在 Chart 类的构造函数中没有提供一个默认设置,那就只能由客户端来完成初始设置,这些代码在每次创建 Chart 对 象时都会出现,导致代码的重复。 面对一个如此巨大、职责如此重,且与客户端代码耦合度非常高的类,我们应该怎么办?本章将要介绍的简单工厂模式将在一定程度上解决上述问题。 4.使用简单工厂模式解决问题 4.1简单工厂模式简述： 简单工厂模式并不属于 GoF 23 个经典设计模式,但通常将它作为学习其他工厂模式的基础,它的设计思想很简单,其基本流程如下: 首先将需要创建的各种不同对象(例如各种不同的 Chart 对象)的相关代码封装到不同的类中,这些类称为具体 产品类,而将它们公共的代码进行抽象和提取后封装在一个抽象产品类中,每一个具体产品类都是抽象产品类的子类;然后提供一个工厂类用于创建各种产品,在工厂类中提供一个创建产品的工厂方法,该方法可以根据所传入的参数不同创建不同的具体产品对象;客户端只需调用工厂类的工厂方法并传入相应的参数即可得到一个产品对象。 4.2简单工厂模式类图表示 简单工厂模式类图在简单工厂模式结构图中包含如下几个角色: Factory(工厂角色):工厂角色即工厂类,它是简单工厂模式的核心,负责实现创建所有产品实例的内部逻 辑;工厂类可以被外界直接调用,创建所需的产品对象;在工厂类中提供了静态的工厂方法 factoryMethod(),它的返回类型为抽象产品类型 Product。 Product(抽象产品角色):它是工厂类所创建的所有对象的父类,封装了各种产品对象的公有方法,它的 引入将提高系统的灵活性,使得在工厂类中只需定义一个通用的工厂方法,因为所有创建的具体产品对象都 是其子类对象。 ConcreteProduct(具体产品角色):它是简单工厂模式的创建目标,所有被创建的对象都充当这个角色的 某个具体类的实例。每一个具体产品角色都继承了抽象产品角色,需要实现在抽象产品中声明的抽象方法。 在简单工厂模式中,客户端通过工厂类来创建一个产品类的实例,而无须直接使用 new 关键字来创建对象,它是工厂模式家族中最简单的一员。 分部代码展示： 1.在使用简单工厂模式时,首先需要对产品类进行重构,不能设计一个包罗万象的产品类,而需根据实际情况设计 一个产品层次结构,将所有产品类公共的代码移至抽象产品类,并在抽象产品类中声明一些抽象方法,以供不同 的具体产品类来实现,典型的抽象产品类代码如下所示: /** Created by tao.liu on 16/10/18. */ abstract class Product { //所有产品类的公共业务方法 public void methodSame() { //公共方法的实现 } //声明抽象业务方法 public abstract void methodDiff(); } 2.在具体产品类中实现了抽象产品类中声明的抽象业务方法,不同的具体产品类可以提供不同的实现,典型的具体 产品类代码如下所示: /** Created by tao.liu on 16/10/18. */ class ConcreteProduct extends Product { //实现业务方法 public void methodDiff() { //业务方法的实现 } ｝ 3.简单工厂模式的核心是工厂类,在没有工厂类之前,客户端一般会使用 new 关键字来直接创建产品对象,而在引 入工厂类之后,客户端可以通过工厂类来创建产品,在简单工厂模式中,工厂类提供了一个静态工厂方法供客户 端使用,根据所传入的参数不同可以创建不同的产品对象,典型的工厂类代码如下所示: /** Created by tao.liu on 16/10/18. */ class Factory { //静态工厂方法 public static Product getProduct(String arg) { Product product = null; if (arg.equalsIgnoreCase(“A”)) { //初始化设置productA product = new ConcreteProductA(); } else if (arg.equalsIgnoreCase(“B”)) { //初始化设置productB product = new ConcreteProductB(); } return product; } } 4.在客户端代码中,我们通过调用工厂类的工厂方法即可得到产品对象,典型代码如下所示: /** Created by tao.liu on 16/10/18. */ class Client { public static void main(String args[]) { Product product; //通过工厂类创建产品对象，没有通过new关键字 product = Factory.getProduct(“A”); product.methodSame(); product.methodDiff(); } } 4.3简单工厂模式完整解决方案 完整解决方案： 为了将 Chart 类的职责分离,同时将 Chart 对象的创建和使用分离,Sunny 软件公司开发人员决定使用简单工 厂模式对图表库进行重构,重构后的结构如图所示: 图片 1.2 图表库结构图 在图中,Chart 接口充当抽象产品类,其子类HistogramChart、PieChart 和 LineChart 充当具体产品类,Ch artFactory 充当工厂类。完整代码如下所示: /** Created by tao.liu on 16/10/18. */ //抽象图表接口：抽象产品类 interface Chart { public void display(); } //柱状图类：具体产品类 class HistogramChart implements Chart { public HistogramChart() { System.out.println(“创建柱状图！”); } public void display() { System.out.println(“显示柱状图！”); } } //饼状图类：具体产品类 class PieChart implements Chart { public PieChart() { System.out.println(“创建饼状图！”); } public void display() { System.out.println(“显示饼状图！”); } } //折线图类：具体产品类 class LineChart implements Chart { public LineChart() { System.out.println(“创建折线图！”); } public void display() { System.out.println(“显示折线图！”); } } //图表工厂类：工厂类 class ChartFactory { //静态工厂方法 public static Chart getChart(String type) { Chart chart = null; if (type.equalsIgnoreCase(“histogram”)) { chart = new HistogramChart(); System.out.println(“初始化设置柱状图！”); } else if (type.equalsIgnoreCase(“pie”)) { chart = new PieChart(); System.out.println(“初始化设置饼状图！”); } else if (type.equalsIgnoreCase(“line”)) { chart = new LineChart(); System.out.println(“初始化设置折线图！”); } return chart; } } 编写如下客户端测试代码: /** Created by tao.liu on 16/10/18. */ class Client { public static void main(String args[]) { Chart chart; chart = ChartFactory.getChart(“histogram”); //通过静态工厂方法创建产品 chart.display(); } } 编译并运行程序,输出结果如下： 创建柱状图！ 初始化设置柱状图！ 显示柱状图！ 在客户端测试类中,我们使用工厂类的静态工厂方法创建产品对象,如果需要更换产品,只需修改静态工厂方法 中的参数即可,例如将柱状图改为饼状图,只需将代码: chart = ChartFactory.getChart(“histogram”); //改为 chart = ChartFactory.getChart(“pie”); 编译程序，运行结果是： 创建饼状图！ 初始化设置饼状图！ 显示饼状图！ 5.方案改进 YY软件公司开发人员发现在创建具体 Chart 对象时,每更换一个 Chart 对象都需要修改客户端代码中静态 工厂方法的参数,客户端代码将要重新编译,这对于客户端而言,违反了“开闭原则”,有没有一种方法能够在 不修改客户端代码的前提下更换具体产品对象呢?答案是肯定的,下面将介绍一种常用的实现方式。 我们可以将静态工厂方法的参数存储在 XML 或 properties 格式的配置文件中,如下 config.xml 所示: histogram 再通过一个工具类 XMLUtil 来读取配置文件中的字符串参数,XMLUtil 类的代码如下所示: /** Created by tao.liu on 16/10/18. */ import javax.xml.parsers.*; import org.w3c.dom.*; import org.xml.sax.SAXException; import java.io.*; public class XMLUtil { //该方法用于从XML配置文件中提取图表类型，并返回类型名 public static String getChartType() { try { //创建文档对象 DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = dFactory.newDocumentBuilder(); Document doc; doc = builder.parse(new File(“config.xml”)); //获取包含图表类型的文本节点 NodeList nl = doc.getElementsByTagName(“chartType”); Node classNode = nl.item(0).getFirstChild(); String chartType = classNode.getNodeValue().trim(); return chartType; } catch(Exception e) { e.printStackTrace(); return null; } } } 修改之后客户端调用代码如下所示： class Client { public static void main(String args[]) { Chart chart; String type = XMLUtil.getChartType(); //读取配置文件中的参数 chart = ChartFactory.getChart(type); //创建产品对象 chart.display(); } } 不难发现，在上述客户端代码中不包含任何与具体图表对象相关的信息，如果需要更换具体图表对象，只需修改配置文件 config.xml，无须修改任何源代码，符合“开闭原则”。 6.模式总结： 简单工厂模式提供了专门的工厂类用于创建对象，将对象的创建和对象的使用分离开，它作为一种最简单的工厂模式在软件开发中得到了较为广泛的应用。 简单工厂模式的主要优点如下： (1) 工厂类包含必要的判断逻辑，可以决定在什么时候创建哪一个产品类的实例，客户端可以免除直接创建产品对象的职责，而仅仅“消费”产品，简单工厂模式实现了对象创建和使用的分离。 (2) 客户端无须知道所创建的具体产品类的类名，只需要知道具体产品类所对应的参数即可，对于一些复杂的类名，通过简单工厂模式可以在一定程度减少使用者的记忆量。 (3) 通过引入配置文件，可以在不修改任何客户端代码的情况下更换和增加新的具体产品类，在一定程度上提高了系统的灵活性。 简单工厂模式的主要缺点如下： (1) 由于工厂类集中了所有产品的创建逻辑，职责过重，一旦不能正常工作，整个系统都要受到影响。 (2) 使用简单工厂模式势必会增加系统中类的个数（引入了新的工厂类），增加了系统的复杂度和理解难度。 (3) 系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展和维护。 (4) 简单工厂模式由于使用了静态工厂方法，造成工厂角色无法形成基于继承的等级结构。 适用场景 在以下情况下可以考虑使用简单工厂模式： (1) 工厂类负责创建的对象比较少，由于创建的对象较少，不会造成工厂方法中的业务逻辑太过复杂。 (2) 客户端只知道传入工厂类的参数，对于如何创建对象并不关心。]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Ioc 源码分析(二)--refresh()]]></title>
    <url>%2F2017%2F11%2F14%2Foriginal_code_Spring_anylize_springIoc_load%2F</url>
    <content type="text"><![CDATA[1.目标：这篇记录debug 追溯源码的过程，大概分三个篇幅，这是第一篇，现整体了解一下运行流程，定位资源加载，资源解析，bean 注册发生的位置。 2.记录结构： 1.调试栈截图 2.整体流程 3.bean.xml的处理每段代码下面有相应的讲解 1.调试栈截图 每个栈帧中方法的行号都有标明，按照行号追溯源码，然后配合教程能够快速学习。 2.整体流程 ioc容器实例化代码 1ApplicationContext applicationContext = new ClassPathXmlApplicationContext("bean.xml"); 进入代码中一步步追溯，发现重要方法：refresh();如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); //beanFactory实例化方法 单步调试入口 // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &apos;active&apos; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; &#125; &#125; 首先这个方法是同步的，以避免重复刷新。然后刷新的每个步骤，都放在单独的方法里，比较清晰，可以按顺序一个个看 首先是prepareRefresh()方法123456789101112131415161718protected void prepareRefresh() &#123; this.startupDate = System.currentTimeMillis(); synchronized (this.activeMonitor) &#123; this.active = true; &#125; if (logger.isInfoEnabled()) &#123; logger.info(&quot;Refreshing &quot; + this); &#125; // Initialize any placeholder property sources in the context environment initPropertySources(); // Validate that all properties marked as required are resolvable // see ConfigurablePropertyResolver#setRequiredProperties this.environment.validateRequiredProperties(); &#125; 这个方法里做的事情不多，记录了开始时间，输出日志，另外initPropertySources()方法和validateRequiredProperties()方法一般都没有做什么事。 然后是核心的obtainFreshBeanFactory()方法，这个方法是初始化BeanFactory，是整个refresh()方法的核心，其中完成了配置文件的加载、解析、注册，后面会专门详细说 。 这里要说明一下，ApplicationContext实现了BeanFactory接口，并实现了ResourceLoader、MessageSource等接口，可以认为是增强的BeanFactory。但是ApplicationContext并不自己重复实现BeanFactory定义的方法，而是委托给DefaultListableBeanFactory来实现。这种设计思路也是值得学习的。后面的 prepareBeanFactory()、postProcessBeanFactory()、invokeBeanFactoryPostProcessors()、registerBeanPostProcessors()、initMessageSource()、initApplicationEventMulticaster()、onRefresh()、registerListeners()、finishBeanFactoryInitialization()、finishRefresh()等方法，是添加一些后处理器、广播、拦截器等，就不一个个细说了 其中的关键方法是finishBeanFactoryInitialization()，在这个方法中，会对刚才注册的Bean（不延迟加载的），进行实例化，所以也是一个核心方法。 3.bean.xml的处理 从整体上介绍完了流程，接下来就重点看obtainFreshBeanFactory()方法，上文说到，在这个方法里，完成了配置文件的加载、解析、注册12345678protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; refreshBeanFactory(); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory); &#125; return beanFactory; &#125; 这个方法做了2件事，首先通过refreshBeanFactory()方法，创建了DefaultListableBeanFactory的实例，并进行初始化。123456789101112131415161718protected final void refreshBeanFactory() throws BeansException &#123; if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex); &#125; &#125; 首先如果已经有BeanFactory实例，就先清空。然后通过createBeanFactory()方法，创建一个DefaultListableBeanFactory的实例123protected DefaultListableBeanFactory createBeanFactory() &#123; return new DefaultListableBeanFactory(getInternalParentBeanFactory()); &#125; 接下来设置ID唯一标识1beanFactory.setSerializationId(getId()); 然后允许用户进行一些自定义的配置123456789protected void customizeBeanFactory(DefaultListableBeanFactory beanFactory) &#123; if (this.allowBeanDefinitionOverriding != null) &#123; beanFactory.setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; if (this.allowCircularReferences != null) &#123; beanFactory.setAllowCircularReferences(this.allowCircularReferences); &#125; beanFactory.setAutowireCandidateResolver(new QualifierAnnotationAutowireCandidateResolver()); &#125; 最后，就是核心的loadBeanDefinitions()方法123456789101112131415protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // Create a new XmlBeanDefinitionReader for the given BeanFactory. XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // Configure the bean definition reader with this context&apos;s // resource loading environment. beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // Allow a subclass to provide custom initialization of the reader, // then proceed with actually loading the bean definitions. initBeanDefinitionReader(beanDefinitionReader); loadBeanDefinitions(beanDefinitionReader); &#125; 这里首先会创建一个XmlBeanDefinitionReader的实例，然后进行初始化。这个XmlBeanDefinitionReader中其实传递的BeanDefinitionRegistry类型的实例，为什么可以传递一个beanFactory呢，因为DefaultListableBeanFactory实现了BeanDefinitionRegistry接口，这里是多态的使用。1234567891011121314protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // Create a new XmlBeanDefinitionReader for the given BeanFactory. XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // Configure the bean definition reader with this context's // resource loading environment. beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // Allow a subclass to provide custom initialization of the reader, // then proceed with actually loading the bean definitions. initBeanDefinitionReader(beanDefinitionReader);&#125; 这里要说明一下，ApplicationContext并不自己负责配置文件的加载、解析、注册，而是将这些工作委托给XmlBeanDefinitionReader来做。1loadBeanDefinitions(beanDefinitionReader); 这行代码，就是Bean定义读取实际发生的地方。这里的工作，主要是XmlBeanDefinitionReader来完成的，下一篇博客会详细介绍这个过程。]]></content>
      <categories>
        <category>源码分析</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Ioc 源码分析(三)--loadBeanDefinitions]]></title>
    <url>%2F2017%2F11%2F14%2Foriginal_code_Spring_anyliz_loadBeanDefinitions%2F</url>
    <content type="text"><![CDATA[上一篇博客说到，ApplicationContext将解析BeanDefinition的工作委托给BeanDefinitionReader组件，这篇就接着分析一下BeanDefinition的解析过程。 loadBeanDefinitions: 源码阅读 入口是loadBeanDefinitions方法123456789protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws IOException &#123; String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; for (String configLocation : configLocations) &#123; reader.loadBeanDefinitions(configLocation); &#125; &#125;&#125; 这是解析过程最外围的代码，首先要获取到配置文件的路径，这在之前已经完成了。然后将每个配置文件的路径，作为参数传给BeanDefinitionReader的loadBeanDefinitions方法里123public int loadBeanDefinitions(String location) throws BeanDefinitionStoreException &#123; return loadBeanDefinitions(location, null);&#125; 这个方法又调用了重载方法1234567891011121314151617181920212223242526272829303132333435363738394041public int loadBeanDefinitions(String location, Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException &#123; ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader == null) &#123; throw new BeanDefinitionStoreException( "Cannot import bean definitions from location [" + location + "]: no ResourceLoader available"); &#125; if (resourceLoader instanceof ResourcePatternResolver) &#123; // Resource pattern matching available. try &#123; Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); int loadCount = loadBeanDefinitions(resources); if (actualResources != null) &#123; for (Resource resource : resources) &#123; actualResources.add(resource); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Loaded " + loadCount + " bean definitions from location pattern [" + location + "]"); &#125; return loadCount; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( "Could not resolve bean definition resource pattern [" + location + "]", ex); &#125; &#125; else &#123; // Can only load single resources by absolute URL. Resource resource = resourceLoader.getResource(location); int loadCount = loadBeanDefinitions(resource); if (actualResources != null) &#123; actualResources.add(resource); &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Loaded " + loadCount + " bean definitions from location [" + location + "]"); &#125; return loadCount; &#125; &#125; 首先getResourceLoader()的实现的前提条件是因为XmlBeanDefinitionReader在实例化的时候已经确定了创建了实例ResourceLoader实例, 代码位于 AbstractBeanDefinitionReader12345678910111213141516protected AbstractBeanDefinitionReader(BeanDefinitionRegistry registry) &#123; Assert.notNull(registry, "BeanDefinitionRegistry must not be null"); this.registry = registry; // Determine ResourceLoader to use. if (this.registry instanceof ResourceLoader) &#123; this.resourceLoader = (ResourceLoader) this.registry; &#125; else &#123; this.resourceLoader = new PathMatchingResourcePatternResolver(); &#125; // Inherit Environment if possible if (this.registry instanceof EnvironmentCapable) &#123; this.environment = ((EnvironmentCapable)this.registry).getEnvironment(); &#125; else &#123; this.environment = new StandardEnvironment(); &#125;&#125; 这个方法比较长，BeanDefinitionReader不能直接加载配置文件，需要把配置文件封装成Resource，然后才能调用重载方法loadBeanDefinitions()。所以这个方法其实就是2段，第一部分是委托ResourceLoader将配置文件封装成Resource，第二部分是调用loadBeanDefinitions()，对Resource进行解析 而这里的ResourceLoader，就是前面的XmlWebApplicationContext，因为ApplicationContext接口，是继承自ResourceLoader接口的 Resource也是一个接口体系，在web环境下，这里就是ServletContextResource 接下来进入重载方法loadBeanDefinitions()12345678public int loadBeanDefinitions(Resource... resources) throws BeanDefinitionStoreException &#123; Assert.notNull(resources, "Resource array must not be null"); int counter = 0; for (Resource resource : resources) &#123; counter += loadBeanDefinitions(resource); &#125; return counter; &#125; 这里就不用说了，就是把每一个Resource作为参数，继续调用重载方法。读spring源码，会发现重载方法特别多。1234public int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException &#123; return loadBeanDefinitions(new EncodedResource(resource));&#125; 还是重载方法，不过这里对传进来的Resource又进行了一次封装，变成了编码后的Resource。12345678910111213141516171819202122232425262728293031323334353637383940public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Assert.notNull(encodedResource, &quot;EncodedResource must not be null&quot;); if (logger.isInfoEnabled()) &#123; logger.info(&quot;Loading XML bean definitions from &quot; + encodedResource.getResource()); &#125; Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;EncodedResource&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; if (!currentResources.add(encodedResource)) &#123; throw new BeanDefinitionStoreException( &quot;Detected cyclic loading of &quot; + encodedResource + &quot; - check your import definitions!&quot;); &#125; try &#123; InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; inputStream.close(); &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( &quot;IOException parsing XML document from &quot; + encodedResource.getResource(), ex); &#125; finally &#123; currentResources.remove(encodedResource); if (currentResources.isEmpty()) &#123; this.resourcesCurrentlyBeingLoaded.remove(); &#125; &#125; &#125; 这个就是loadBeanDefinitions()的最后一个重载方法，比较长，可以拆看来看。1234567891011121314Assert.notNull(encodedResource, &quot;EncodedResource must not be null&quot;); if (logger.isInfoEnabled()) &#123; logger.info(&quot;Loading XML bean definitions from &quot; + encodedResource.getResource()); &#125; Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;EncodedResource&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; if (!currentResources.add(encodedResource)) &#123; throw new BeanDefinitionStoreException( &quot;Detected cyclic loading of &quot; + encodedResource + &quot; - check your import definitions!&quot;); &#125; 这第一部分，是处理线程相关的工作，把当前正在解析的Resource，设置为当前Resource。12345678910111213try &#123; InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; inputStream.close(); &#125; &#125; 这里是第二部分，是核心，首先把Resource还原为InputStream，然后调用实际解析的方法doLoadBeanDefinitions()。可以看到，这种命名方式是很值得学习的，一种业务方法，比如parse()，可能需要做一些外围的工作，然后实际解析的方法，可以命名为doParse()。这种doXXX()的命名方法，在很多开源框架中都有应用，比如logback等。接下来就看一下这个doLoadBeanDefinitions()方法123456789101112131415161718192021222324252627282930protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; Document doc = doLoadDocument(inputSource, resource);return registerBeanDefinitions(doc, resource); return registerBeanDefinitions(doc, resource); &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (SAXParseException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), &quot;Line &quot; + ex.getLineNumber() + &quot; in XML document from &quot; + resource + &quot; is invalid&quot;, ex); &#125; catch (SAXException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), &quot;XML document from &quot; + resource + &quot; is invalid&quot;, ex); &#125; catch (ParserConfigurationException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), &quot;Parser configuration exception parsing XML from &quot; + resource, ex); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), &quot;IOException parsing XML document from &quot; + resource, ex); &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), &quot;Unexpected exception parsing XML document from &quot; + resource, ex); &#125; &#125; 抛开异常处理：核心代码如下：1234567891011 Document doc = doLoadDocument(inputSource, resource); return registerBeanDefinitions(doc, resource);``` doLoadDocument方法将InputStream读取成标准的Document对象，然后调用registerBeanDefinitions()，进行解析工作。```javaprotected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception &#123; return this.documentLoader.loadDocument(inputSource, getEntityResolver(), this.errorHandler, getValidationModeForResource(resource), isNamespaceAware());&#125; 接下来就看一下这个核心方法registerBeanDefinitions12345678public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; //创建的其实是DefaultBeanDefinitionDocumentReader 的实例，利用反射创建的。 BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); documentReader.setEnvironment(this.getEnvironment()); int countBefore = getRegistry().getBeanDefinitionCount(); documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore;&#125; 这里注意两点 : 1.Document对象首先这个Document对象，是W3C定义的标准XML对象，跟spring无关。其次这个registerBeanDefinitions方法，我觉得命名有点误导性。因为这个时候实际上解析还没有开始，怎么直接就注册了呢。比较好的命名，我觉得可以是parseAndRegisterBeanDefinitions()。2.documentReader的创建时使用反射创建的，代码如下12345protected BeanDefinitionDocumentReader createBeanDefinitionDocumentReader() &#123; return BeanDefinitionDocumentReader.class.cast(BeanUtils. instantiateClass(this.documentReaderClass));&#125; instantiateClass方法中传入了一个Class类型的参数。追溯发现下述代码：12private Class&lt;?&gt; documentReaderClass = DefaultBeanDefinitionDocumentReader.class; 所以创建的documentReaderClass是DefaultBeanDefinitionDocumentReader类的实例。接下来就进入BeanDefinitionDocumentReader 中定义的registerBeanDefinitions()方法看看123456public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; this.readerContext = readerContext; logger.debug("Loading bean definitions"); Element root = doc.getDocumentElement(); doRegisterBeanDefinitions(root); &#125; 处理完外围事务之后，进入doRegisterBeanDefinitions()方法，这种命名规范，上文已经介绍过了12345678910111213141516171819202122protected void doRegisterBeanDefinitions(Element root) &#123; String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; Assert.state(this.environment != null, &quot;environment property must not be null&quot;); String[] specifiedProfiles = StringUtils.tokenizeToStringArray(profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!this.environment.acceptsProfiles(specifiedProfiles)) &#123; return; &#125; &#125; // any nested &lt;beans&gt; elements will cause recursion in this method. In // order to propagate and preserve &lt;beans&gt; default-* attributes correctly, // keep track of the current (parent) delegate, which may be null. Create // the new (child) delegate with a reference to the parent for fallback purposes, // then ultimately reset this.delegate back to its original (parent) reference. // this behavior emulates a stack of delegates without actually necessitating one. BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createHelper(readerContext, root, parent); preProcessXml(root); parseBeanDefinitions(root, this.delegate); postProcessXml(root); this.delegate = parent;&#125; 这个方法也比较长，拆开来看12345678String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; Assert.state(this.environment != null, "environment property must not be null"); String[] specifiedProfiles = StringUtils.tokenizeToStringArray(profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!this.environment.acceptsProfiles(specifiedProfiles)) &#123; return; &#125;&#125; 如果配置文件中元素，配有profile属性，就会进入这一段，不过一般都是不会的123456BeanDefinitionParserDelegate parent = this.delegate;this.delegate = createHelper(readerContext, root, parent);preProcessXml(root);parseBeanDefinitions(root, this.delegate);postProcessXml(root);this.delegate = parent; 然后这里创建了BeanDefinitionParserDelegate对象，preProcessXml()和postProcessXml()都是空方法，核心就是parseBeanDefinitions()方法。这里又把BeanDefinition解析和注册的工作，委托给了BeanDefinitionParserDelegate对象，在parseBeanDefinitions()方法中完成总的来说，解析工作的委托链是这样的：ClassPathXmlApplicationContext，XmlBeanDefinitionReader，DefaultBeanDefinitionDocumentReader，BeanDefinitionParserDelegateClassPathXmlApplicationContext作为最外围的组件，发起解析的请求XmlBeanDefinitionReader将配置文件路径封装为Resource，读取出w3c定义的Document对象，然后委托给DefaultBeanDefinitionDocumentReaderDefaultBeanDefinitionDocumentReader就开始做实际的解析工作了，但是涉及到bean的具体解析，它还是会继续委托给BeanDefinitionParserDelegate来做。接下来在parseBeanDefinitions()方法中发生了什么，以及BeanDefinitionParserDelegate类完成的工作，在下一篇博客中继续介绍]]></content>
      <categories>
        <category>源码分析</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Ioc 源码分析(四)--parseBeanDefinitions()与BeanDefinitionParserDelegate]]></title>
    <url>%2F2017%2F11%2F14%2Foriginal_code_Spring_anyliz_parseBeanDefinitions_BeanDefinitionParserDelegate_4%2F</url>
    <content type="text"><![CDATA[上一篇博客说到，BeanDefinition的解析,已经走到了DefaultBeanDefinitionDocumentReader里，这时候配置文件已经被加载，并解析成w3c的Document对象。这篇博客就接着介绍，DefaultBeanDefinitionDocumentReader和BeanDefinitionParserDelegate类，是怎么协同完成bean的解析和注册的。123456BeanDefinitionParserDelegate parent = this.delegate;this.delegate = createHelper(readerContext, root, parent);preProcessXml(root);parseBeanDefinitions(root, this.delegate);postProcessXml(root);this.delegate = parent; 这段代码，创建了一个BeanDefinitionParserDelegate组件，然后就是preProcessXml()、parseBeanDefinitions()、postProcessXml()方法其中preProcessXml()和postProcessXml()默认是空方法，接下来就看下parseBeanDefinitions()方法1234567891011121314151617181920protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; else &#123; delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125; &#125; 从这个方法开始，BeanDefinitionParserDelegate就开始发挥作用了，判断当前解析元素是否属于默认的命名空间，如果是的话，就调用parseDefaultElement()方法，否则调用delegate上parseCustomElement()方法123456public boolean isDefaultNamespace(String namespaceUri) &#123; return (!StringUtils.hasLength(namespaceUri) || BEANS_NAMESPACE_URI.equals(namespaceUri)); &#125; public boolean isDefaultNamespace(Node node) &#123; return isDefaultNamespace(getNamespaceURI(node)); &#125; 只有http://www.springframework.org/schema/beans，会被认为是默认的命名空间。也就是说，beans、bean这些元素，会认为属于默认的命名空间，而像task:scheduled这些，就认为不属于默认命名空间。根节点beans的一个子节点bean，是属于默认命名空间的，所以会进入parseDefaultElement()方法123456789101112131415private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; importBeanDefinitionResource(ele); &#125; else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; processAliasRegistration(ele); &#125; else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; processBeanDefinition(ele, delegate); &#125; else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // recurse doRegisterBeanDefinitions(ele); &#125; &#125; 这里可能会有4种情况，import、alias、bean、beans，分别有一个方法与之对应，这里解析的是bean元素，所以会进入processBeanDefinition()方法12345678910111213141516protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &#123; bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; // Register the final decorated instance. BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error(&quot;Failed to register bean definition with name &apos;&quot; + bdHolder.getBeanName() + &quot;&apos;&quot;, ele, ex); &#125; // Send registration event. getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125; &#125; 这里主要有3个步骤，先是委托delegate对bean进行解析，然后委托delegate对bean进行装饰，最后由一个工具类来完成BeanDefinition的注册可以看出来，DefaultBeanDefinitionDocumentReader不负责任何具体的bean解析，它面向的是xml Document对象，根据其元素的命名空间和名称，起一个类似路由的作用（不过，命名空间的判断，也是委托给delegate来做的）。所以这个类的命名，是比较贴切的，突出了其面向Document的特性。具体的工作，是由BeanDefinitionParserDelegate来完成的下面就看下parseBeanDefinitionElement()方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public BeanDefinitionHolder parseBeanDefinitionElement(Element ele, BeanDefinition containingBean) &#123; String id = ele.getAttribute(ID_ATTRIBUTE); String nameAttr = ele.getAttribute(NAME_ATTRIBUTE); List&lt;String&gt; aliases = new ArrayList&lt;String&gt;(); if (StringUtils.hasLength(nameAttr)) &#123; String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, MULTI_VALUE_ATTRIBUTE_DELIMITERS); aliases.addAll(Arrays.asList(nameArr)); &#125; String beanName = id; if (!StringUtils.hasText(beanName) &amp;&amp; !aliases.isEmpty()) &#123; beanName = aliases.remove(0); if (logger.isDebugEnabled()) &#123; logger.debug("No XML 'id' specified - using '" + beanName + "' as bean name and " + aliases + " as aliases"); &#125; &#125; if (containingBean == null) &#123; checkNameUniqueness(beanName, aliases, ele); &#125; AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, containingBean); if (beanDefinition != null) &#123; if (!StringUtils.hasText(beanName)) &#123; try &#123; if (containingBean != null) &#123; beanName = BeanDefinitionReaderUtils.generateBeanName( beanDefinition, this.readerContext.getRegistry(), true); &#125; else &#123; beanName = this.readerContext.generateBeanName(beanDefinition); // Register an alias for the plain bean class name, if still possible, // if the generator returned the class name plus a suffix. // This is expected for Spring 1.2/2.0 backwards compatibility. String beanClassName = beanDefinition.getBeanClassName(); if (beanClassName != null &amp;&amp; beanName.startsWith(beanClassName) &amp;&amp; beanName.length() &gt; beanClassName.length() &amp;&amp; !this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) &#123; aliases.add(beanClassName); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Neither XML 'id' nor 'name' specified - " + "using generated bean name [" + beanName + "]"); &#125; &#125; catch (Exception ex) &#123; error(ex.getMessage(), ele); return null; &#125; &#125; String[] aliasesArray = StringUtils.toStringArray(aliases); return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray); &#125; return null; &#125; 这个方法很长，可以分成三段来看123456789101112131415161718String id = ele.getAttribute(ID_ATTRIBUTE); String nameAttr = ele.getAttribute(NAME_ATTRIBUTE); List&lt;String&gt; aliases = new ArrayList&lt;String&gt;(); if (StringUtils.hasLength(nameAttr)) &#123; String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, MULTI_VALUE_ATTRIBUTE_DELIMITERS); aliases.addAll(Arrays.asList(nameArr)); &#125; String beanName = id; if (!StringUtils.hasText(beanName) &amp;&amp; !aliases.isEmpty()) &#123; beanName = aliases.remove(0); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;No XML &apos;id&apos; specified - using &apos;&quot; + beanName + &quot;&apos; as bean name and &quot; + aliases + &quot; as aliases&quot;); &#125; &#125; if (containingBean == null) &#123; checkNameUniqueness(beanName, aliases, ele); &#125; 这一段，主要是处理一些跟alias，id等标识相关的东西1AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, containingBean); 这一行是核心，进行实际的解析1234567891011121314151617181920212223242526272829303132if (beanDefinition != null) &#123; if (!StringUtils.hasText(beanName)) &#123; try &#123; if (containingBean != null) &#123; beanName = BeanDefinitionReaderUtils.generateBeanName( beanDefinition, this.readerContext.getRegistry(), true); &#125; else &#123; beanName = this.readerContext.generateBeanName(beanDefinition); // Register an alias for the plain bean class name, if still possible, // if the generator returned the class name plus a suffix. // This is expected for Spring 1.2/2.0 backwards compatibility. String beanClassName = beanDefinition.getBeanClassName(); if (beanClassName != null &amp;&amp; beanName.startsWith(beanClassName) &amp;&amp; beanName.length() &gt; beanClassName.length() &amp;&amp; !this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) &#123; aliases.add(beanClassName); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Neither XML &apos;id&apos; nor &apos;name&apos; specified - &quot; + &quot;using generated bean name [&quot; + beanName + &quot;]&quot;); &#125; &#125; catch (Exception ex) &#123; error(ex.getMessage(), ele); return null; &#125; &#125; String[] aliasesArray = StringUtils.toStringArray(aliases); return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray); &#125; 这段是后置处理，对beanName进行处理前置处理和后置处理，不是核心，就不细看了，重点看下核心的那一行调用123456789101112131415161718192021222324252627282930313233343536373839public AbstractBeanDefinition parseBeanDefinitionElement( Element ele, String beanName, BeanDefinition containingBean) &#123; this.parseState.push(new BeanEntry(beanName)); String className = null; if (ele.hasAttribute(CLASS_ATTRIBUTE)) &#123; className = ele.getAttribute(CLASS_ATTRIBUTE).trim(); &#125; try &#123; String parent = null; if (ele.hasAttribute(PARENT_ATTRIBUTE)) &#123; parent = ele.getAttribute(PARENT_ATTRIBUTE); &#125; AbstractBeanDefinition bd = createBeanDefinition(className, parent); parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT)); parseMetaElements(ele, bd); parseLookupOverrideSubElements(ele, bd.getMethodOverrides()); parseReplacedMethodSubElements(ele, bd.getMethodOverrides()); parseConstructorArgElements(ele, bd); parsePropertyElements(ele, bd); parseQualifierElements(ele, bd); bd.setResource(this.readerContext.getResource()); bd.setSource(extractSource(ele)); return bd; &#125; catch (ClassNotFoundException ex) &#123; error("Bean class [" + className + "] not found", ele, ex); &#125; catch (NoClassDefFoundError err) &#123; error("Class that bean class [" + className + "] depends on not found", ele, err); &#125; catch (Throwable ex) &#123; error("Unexpected failure during bean definition parsing", ele, ex); &#125; finally &#123; this.parseState.pop(); &#125; return null; &#125; 这个方法也挺长的，拆开看看12345this.parseState.push(new BeanEntry(beanName)); String className = null; if (ele.hasAttribute(CLASS_ATTRIBUTE)) &#123; className = ele.getAttribute(CLASS_ATTRIBUTE).trim(); &#125; 这段是从配置中抽取出类名。接下来的长长一段，把异常处理先抛开，看看实际的业务12345678910111213141516String parent = null;if (ele.hasAttribute(PARENT_ATTRIBUTE)) &#123; parent = ele.getAttribute(PARENT_ATTRIBUTE);&#125;AbstractBeanDefinition bd = createBeanDefinition(className, parent);parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT));parseMetaElements(ele, bd);parseLookupOverrideSubElements(ele, bd.getMethodOverrides());parseReplacedMethodSubElements(ele, bd.getMethodOverrides());parseConstructorArgElements(ele, bd);parsePropertyElements(ele, bd);parseQualifierElements(ele, bd);bd.setResource(this.readerContext.getResource());bd.setSource(extractSource(ele));return bd; 这里每个方法的命名，就说明了是要干什么，可以一个个跟进去看，本文就不细说了。总之，经过这里的解析，就得到了一个完整的BeanDefinitionHolder。只是说明一下，如果在配置文件里，没有对一些属性进行设置，比如autowire-candidate等，那么这个解析生成的BeanDefinition，都会得到一个默认值然后，对这个Bean做一些必要的装饰12345678910111213141516171819public BeanDefinitionHolder decorateBeanDefinitionIfRequired( Element ele, BeanDefinitionHolder definitionHolder, BeanDefinition containingBd) &#123; BeanDefinitionHolder finalDefinition = definitionHolder; // Decorate based on custom attributes first. NamedNodeMap attributes = ele.getAttributes(); for (int i = 0; i &lt; attributes.getLength(); i++) &#123; Node node = attributes.item(i); finalDefinition = decorateIfRequired(node, finalDefinition, containingBd); &#125; // Decorate based on custom nested elements. NodeList children = ele.getChildNodes(); for (int i = 0; i &lt; children.getLength(); i++) &#123; Node node = children.item(i); if (node.getNodeType() == Node.ELEMENT_NODE) &#123; finalDefinition = decorateIfRequired(node, finalDefinition, containingBd); &#125; &#125; return finalDefinition; &#125; 持续单步调试，代码继续运行到DefaultBeanDefinitionDocumentReader中的processBeanDefinition中的registerBeanDefinition()12BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); 单步进入代码发现BeanDefinitionReaderUtils静态方法registerBeanDefinition()123456789101112131415public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &#123; // Register bean definition under primary name. String beanName = definitionHolder.getBeanName(); // 其实调用的是DefaultListableBeanFactory中的registerBeanDefinition方法 registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // Register aliases for bean name, if any. String[] aliases = definitionHolder.getAliases(); if (aliases != null) &#123; for (String aliase : aliases) &#123; registry.registerAlias(beanName, aliase); &#125; &#125; &#125; 解释一下其实调用的是DefaultListableBeanFactory中的registerBeanDefinition方法这句话，因为DefaultListableBeanFactory实现BeanDefinitionRegistry接口，BeanDefinitionRegistry接口中定义了registerBeanDefinition()方法看下DefaultListableBeanFactory中registerBeanDefinition()实例方法的具体实现：123456789101112131415161718192021222324252627282930313233343536public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; Assert.hasText(beanName, "Bean name must not be empty"); Assert.notNull(beanDefinition, "BeanDefinition must not be null"); if (beanDefinition instanceof AbstractBeanDefinition) &#123; try &#123; ((AbstractBeanDefinition) beanDefinition).validate(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, "Validation of bean definition failed", ex); &#125; &#125; synchronized (this.beanDefinitionMap) &#123; Object oldBeanDefinition = this.beanDefinitionMap.get(beanName); if (oldBeanDefinition != null) &#123; if (!this.allowBeanDefinitionOverriding) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, "Cannot register bean definition [" + beanDefinition + "] for bean '" + beanName + "': There is already [" + oldBeanDefinition + "] bound."); &#125; else &#123; if (this.logger.isInfoEnabled()) &#123; this.logger.info("Overriding bean definition for bean '" + beanName + "': replacing [" + oldBeanDefinition + "] with [" + beanDefinition + "]"); &#125; &#125; &#125; else &#123; this.beanDefinitionNames.add(beanName); this.frozenBeanDefinitionNames = null; &#125; this.beanDefinitionMap.put(beanName, beanDefinition); resetBeanDefinition(beanName); &#125; &#125; 代码追溯之后发现这个方法里，最关键的是以下2行：12this.beanDefinitionNames.add(beanName);this.beanDefinitionMap.put(beanName, beanDefinition); 前者是把beanName放到队列里，后者是把BeanDefinition放到map中，到此注册就完成了。在后面实例化的时候，就是把beanDefinitionMap中的BeanDefinition取出来，逐一实例化BeanFactory准备完毕之后，代码又回到了ClassPathXmlApplicationContext里1234567891011121314151617181920212223242526272829303132333435363738public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &apos;active&apos; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; &#125; &#125; 也就是obtainFreshBeanFactory()方法执行之后，再进行下面的步骤。总结来说，ApplicationContext将解析配置文件的工作委托给BeanDefinitionReader，然后BeanDefinitionReader将配置文件读取为xml的Document文档之后，又委托给BeanDefinitionDocumentReaderBeanDefinitionDocumentReader这个组件是根据xml元素的命名空间和元素名，起到一个路由的作用，实际的解析工作，是委托给BeanDefinitionParserDelegate来完成的BeanDefinitionParserDelegate的解析工作完成以后，会返回BeanDefinitionHolder给BeanDefinitionDocumentReader，在这里，会委托给DefaultListableBeanFactory完成bean的注册XmlBeanDefinitionReader（计数、解析XML文档），BeanDefinitionDocumentReader（依赖xml文档，进行解析和注册），BeanDefinitionParserDelegate（实际的解析工作）。可以看出，在解析bean的过程中，这3个组件的分工是比较清晰的，各司其职，这种设计思想值得学习到此为止，bean的解析、注册、spring ioc 容器的实例化过程就基本分析结束了。]]></content>
      <categories>
        <category>源码分析</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Ioc 源码分析(一)--Spring Ioc容器的加载]]></title>
    <url>%2F2017%2F11%2F14%2Foriginal_code_Spring_anyliz_1%2F</url>
    <content type="text"><![CDATA[1.目标：熟练使用spring，并分析其源码，了解其中的思想。这篇主要介绍spring ioc 容器的加载2.前提条件：会使用debug3.源码分析方法：Intellj idea debug 模式下源码追溯通过ClassPathXmlApplicationContext 进行xml 件的读取，从每个堆栈中读取程序的运行信息4.注意：由于Spring的类继承体系比较复杂,不能全部贴图，所以只将分析源码之后发现的最主要的类继承结构类图贴在下方。5.关于Spring Ioc Demo：我们从demo入手一步步进行代码追溯。 1.Spring Ioc Demo 1.定义数据访问接口IUserDao.java123public interface IUserDao &#123; public void InsertUser(String username,String password);&#125; 2.定义IUserDao.java实现类IUserDaoImpl.java123456public class UserDaoImpl implements IUserDao &#123; @Override public void InsertUser(String username, String password) &#123; System.out.println(&quot;----UserDaoImpl --addUser----&quot;); &#125;&#125; 3.定义业务逻辑接口UserService.java123public interface UserService &#123; public void addUser(String username,String password);&#125; 4.定义UserService.java实现类UserServiceImpl.java12345678910public class UserServiceImpl implements UserService &#123; private IUserDao userDao; //set方法 public void setUserDao(IUserDao userDao) &#123; this.userDao = userDao; &#125; @Override public void addUser(String username,String password) &#123; userDao.InsertUser(username,password); &#125;&#125; bean.xml配置文件1234567891011&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd "&gt; &lt;!--id名字自己取，class表示他代表的类，如果在包里的话需要加上包名--&gt; &lt;bean id="userService" class="UserServiceImpl" &gt; &lt;!--property代表是通过set方法注入,ref的值表示注入的内容--&gt; &lt;property name="userDao" ref="userDao"/&gt; &lt;/bean&gt; &lt;bean id="userDao" class="UserDaoImpl"/&gt;&lt;/beans&gt; 2.ApplicationContext 继承结构： 1.顶层接口：ApplicationContext2.ClassPathXmlApplicationContext实现类继承AbstractXmlApplication 抽象类3.AbstractXmlApplication 继承AbstractRefreshableConfigApplicationContext4.AbstractRefreshableConfigApplicationContext抽象类继承AbstractRefreshableApplicationContext5.AbstractRefreshableApplicationContext 继承 AbstractApplicationContext6.AbstractApplicationContext 实现ConfigurableApplicationContext 接口7.ConfigurableApplicationContext 接口继承ApplicationContext接口总体来说继承实现结构较深，内部使用了大量适配器模式。以ClassPathXmlApplicationContext为例，继承类图如下图所示： 3.Spring Ioc容器加载过程源码详解 在开始之前，先介绍一个整体的概念。即spring ioc容器的加载，大体上经过以下几个过程：资源文件定位、解析、注册、实例化 1.资源文件定位其中资源文件定位，一般是在ApplicationContext的实现类里完成的，因为ApplicationContext接口继承ResourcePatternResolver 接口，ResourcePatternResolver接口继承ResourceLoader接口，ResourceLoader其中的getResource()方法，可以将外部的资源，读取为Resource类。 2.解析DefaultBeanDefinitionDocumentReader，解析主要是在BeanDefinitionReader中完成的，最常用的实现类是XmlBeanDefinitionReader，其中的loadBeanDefinitions()方法，负责读取Resource，并完成后续的步骤。ApplicationContext完成资源文件定位之后，是将解析工作委托给XmlBeanDefinitionReader来完成的解析这里涉及到很多步骤，最常见的情况，资源文件来自一个XML配置文件。首先是BeanDefinitionReader，将XML文件读取成w3c的Document文档。DefaultBeanDefinitionDocumentReader对Document进行进一步解析。然后DefaultBeanDefinitionDocumentReader又委托给BeanDefinitionParserDelegate进行解析。如果是标准的xml namespace元素，会在Delegate内部完成解析，如果是非标准的xml namespace元素，则会委托合适的NamespaceHandler进行解析最终解析的结果都封装为BeanDefinitionHolder，至此解析就算完成。后续会进行细致讲解。 3.注册然后bean的注册是在BeanFactory里完成的，BeanFactory接口最常见的一个实现类是DefaultListableBeanFactory，它实现了BeanDefinitionRegistry接口，所以其中的registerBeanDefinition()方法，可以对BeanDefinition进行注册这里附带一提，最常见的XmlWebApplicationContext不是自己持有BeanDefinition的，它继承自AbstractRefreshableApplicationContext，其持有一个DefaultListableBeanFactory的字段，就是用它来保存BeanDefinition所谓的注册，其实就是将BeanDefinition的name和实例，保存到一个Map中。刚才说到，最常用的实现DefaultListableBeanFactory，其中的字段就是beanDefinitionMap，是一个ConcurrentHashMap。代码如下：&gt;1.DefaultListableBeanFactory继承实现关系 1234567891011121314public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; // DefaultListableBeanFactory的实例中最终保存了所有注册的bean beanDefinitionMap /** Map of bean definition objects, keyed by bean name */ private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;String, BeanDefinition&gt;(64); //实现BeanDefinitionRegistry中定义的registerBeanDefinition()抽象方法 public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; &#125; &gt;2.BeanDefinitionRegistry接口123public interface BeanDefinitionRegistry extends AliasRegistry &#123; //定义注册BeanDefinition实例的抽象方法 void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException; 4.实例化 注册也完成之后，在BeanFactory的getBean()方法之中，会完成初始化，也就是依赖注入的过程大体上的流程就是这样，下一篇博客，再具体地从代码层面进行介绍。]]></content>
      <categories>
        <category>源码分析</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoSql-Redis入门（事务）]]></title>
    <url>%2F2017%2F11%2F14%2FNoSql-Redis-transaction%2F</url>
    <content type="text"><![CDATA[定义 Redis 事务可以一次执行多个命令， 并且带有以下两个重要的保证：1.事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。2.事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。一个事务从开始到执行会经历以下三个阶段：1.开始事务。2.命令入队。3.执行事务。 for example以下是一个事务的例子， 它先以 multi 开始一个事务， 然后将多个命令入队到事务中， 最后由 exec 命令触发事务， 一并执行事务中的所有命令：123456789101112131415161718127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set username 张晓QUEUED127.0.0.1:6379&gt; get usernameQUEUED127.0.0.1:6379&gt; sadd persons-info 张咪 张冲 张明QUEUED127.0.0.1:6379&gt; smembers persons-infoQUEUED127.0.0.1:6379&gt; execOK张晓3张明张咪张冲127.0.0.1:6379&gt; 没啥可说的，大家都看的懂，多熟悉命令。惟一觉得有用的东西就是Redis中对事务中一系列操作命令的队列式存储。以及事务执行的四大约束原则，也算是特性：原子性、完整性、隔离性、持久性 ，也就是ACID。 还有一点，我在学习发布订阅的时候发现如果发布的信息是中文的话，在subscribe端接收的信息是乱码，这个可以在打开客户端的时候使用./redis-cli –raw避免]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>NoSql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Node.js Event-loop事件循环]]></title>
    <url>%2F2017%2F11%2F14%2Fnode%2F</url>
    <content type="text"><![CDATA[node.js事件循环 Node.js 是单进程单线程应用程序，但是通过事件和回调支持并发，所以性能非常高。Node.js 的每一个 API 都是异步的，并作为一个独立线程运行，使用异步函数调用，并处理并发。Node.js 基本上所有的事件机制都是用设计模式中观察者模式实现。Node.js 单线程类似进入一个while(true)的事件循环，直到没有事件观察者退出，每个异步事件都生成一个事件观察者，如果有事件发生就调用该回调函数. 事件驱动程序 想要理解Event Loop，就要从程序的运行模式讲起。运行以后的程序叫做“进程”（process），一般情况下，一个进程一次只能执行一个任务。如果有很多任务需要执行，不外乎三种解决方法。 （1）排队:因为一个进程一次只能执行一个任务，只好等前面的任务执行完了，再执行后面的任务。（2）新建进程:使用fork命令，为每个任务新建一个进程。（3）新建线程:因为进程太耗费资源，所以如今的程序往往允许一个进程包含多个线程，由线程去完成任务。（进程和线程的详细解释，请看这里。） 以JavaScript语言为例，它是一种单线程语言，所有任务都在一个线程上完成，即采用上面的第一种方法。一旦遇到大量任务或者遇到一个耗时的任务，网页就会出现”假死”，因为JavaScript停不下来，也就无法响应用户的行为。你也许会问，JavaScript为什么是单线程，难道不能实现为多线程吗？这跟历史有关系。JavaScript从诞生起就是单线程。原因大概是不想让浏览器变得太复杂，因为多线程需要共享资源、且有可能修改彼此的运行结果，对于一种网页脚本语言来说，这就太复杂了。后来就约定俗成，JavaScript为一种单线程语言。（Worker API可以实现多线程，但是JavaScript本身始终是单线程的。）如果某个任务很耗时，比如涉及很多I/O（输入/输出）操作，那么线程的运行大概是下面的样子。 上图的绿色部分是程序的运行时间，红色部分是等待时间。可以看到，由于I/O操作很慢，所以这个线程的大部分运行时间都在空等I/O操作的返回结果。这种运行方式称为”同步模式”（synchronous I/O）或”堵塞模式”（blocking I/O）。如果采用多线程，同时运行多个任务，那很可能就是下面这样。 上图表明，多线程不仅占用多倍的系统资源，也闲置多倍的资源，这显然不合理。Event Loop就是为了解决这个问题而提出的。Wikipedia这样定义： Event Loop是一个程序结构，用于等待和发送消息和事件。（a programming construct that waits for and dispatches events or messages in a program.） 简单说，就是在程序中设置两个线程：一个负责程序本身的运行，称为”主线程”；另一个负责主线程与其他进程（主要是各种I/O操作）的通信，被称为”Event Loop线程”（可以译为”消息线程”）。 上图主线程的绿色部分，还是表示运行时间，而橙色部分表示空闲时间。每当遇到I/O的时候，主线程就让Event Loop线程去通知相应的I/O程序，然后接着往后运行，所以不存在红色的等待时间。等到I/O程序完成操作，Event Loop线程再把结果返回主线程。主线程就调用事先设定的回调函数，完成整个任务。可以看到，由于多出了橙色的空闲时间，所以主线程得以运行更多的任务，这就提高了效率。这种运行方式称为”异步模式“（asynchronous I/O）或”非堵塞模式”（non-blocking mode）。这正是JavaScript语言的运行方式。单线程模型虽然对JavaScript构成了很大的限制，但也因此使它具备了其他语言不具备的优势。如果部署得好，JavaScript程序是不会出现堵塞的，这就是为什么node.js平台可以用很少的资源，应付大流量访问的原因。 代码体现 创建一个main.js文件1234567891011121314151617181920//引入events模块var events = require(&apos;events&apos;);//创建eventEmitter对象 内部类对象var eventEmitter = new events.EventEmitter();//创建事件处理程序var connectHandler = function connected() &#123; console.log(&apos;连接成功&apos;)； //触发data_received事件 evenEmitter.emit(&apos;data_received&apos;);&#125;//创建 名为connection 事件，并将事件处理程序（回调函数）绑定到事件上eventEmitter.on(&apos;connection&apos;,connectHandler);//创建名为data_reveived事件，并将匿名处理函数（回调函数）绑定到事件上eventEmitter.on(&apos;data_received&apos;,function() &#123; console.log(&apos;数据接收成功&apos;)；&#125;)//触发connection 事件eventEmitter.emit(&apos;connection&apos;);console.log(&quot;程序执行完毕&quot;)； 接下来让我们执行以上代码： 1234$ node main.js连接成功数据接收成功程序执行完毕 看了上面的程序如果还不懂的话，请看下面的这幅图，并结合最后一段话去理解： 事件相当于一个主题(Subject)，而所有注册到这个事件上的处理函数相当于观察者(Observer)。要点： 1.观察者相当于事件处理程序–被回调的函数。 2.事件就相当于我们认为的任务，比如程序执行期间需要等待I/O这就是一个事件。 3.我们可以把node.js的主线程想像成一个来者不拒的主人，这个人遇到什么事情都不拒绝，但是他处理事情也要找其他人（I/O）帮忙。 他有一个管家叫event loop线程，当事情来得时候，主人告诉管家这个事情，并让管家去找能够解决这个问题的人，然后继续接事情，当能够解决这个事情的人解决了事情，管家就把事情的结果告诉给主人，这里的回调函数可以想象成信鸽，主人将事情的结果放在信鸽身上（结果为参数，信鸽为回调函数载体），完成整个任务，这就说明node.js是异步执行的语言，非阻塞的语言，这也就是node.js性能高的原因。 4.node.js使用的是javascript语法，javascript语法是单线程的，当用户触发事件，事件会产生消息，消息会进入消息列表，在消息进入列表的同时，回调函数也进入列表，当消息出队列时，回调函数被调用。整个底层过程就是这样的 吴海星译 谢天谢地，实际情况不是这样的。当浏览器中有I/O操作时，该操作会在事件轮询的外面执行（脚本执行的主顺序之外），然后当这个I/O操作完成时，它会发出一个“事件”，①会有一个函数（通常称作“回调”）处理它，如图1-1所示。]]></content>
      <categories>
        <category>Node.js</category>
      </categories>
      <tags>
        <tag>Node</tag>
        <tag>事件循环</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node.js中缓冲区--Buffer]]></title>
    <url>%2F2017%2F11%2F14%2Fnode-Buffer%2F</url>
    <content type="text"><![CDATA[Node.js中Buffer简介： JavaScript 语言自身只有字符串数据类型，没有二进制数据类型。但在处理像TCP流或文件流时，必须使用到二进制数据。因此在 Node.js中，定义了一个 Buffer 类，该类用来创建一个专门存放二进制数据的缓存区。在 Node.js 中，Buffer 类是随 Node 内核一起发布的核心库。Buffer 库为 Node.js 带来了一种存储原始数据的方法，可以让 Node.js 处理二进制数据，每当需要在 Node.js 中处理I/O操作中移动的数据时，就有可能使用 Buffer 库。原始数据存储在 Buffer 类的实例中。一个 Buffer 类似于一个整数数组，但它对应于 V8 堆内存之外的一块原始内存。 Buffer常用API 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/*1.Node.js中Buffer是一个典型的javascript与c++结合的模块，它将性能相关的部分用 c++实现，将非性能的部分用javascript实现。 2.纯javascript对字符友好但是i无法很好的处理二进制数据，在java与node中buffer中存 储的是二进制数据。当我们面对TCP流或者文件系统时，是需要处理八位流的，因此在Node.js中定义了一个Buffer类，该类用来创建一个专门的存放二进制数据的缓冲区。 3.代码演示：*///buffer的创建，一共有三种创建方式：从不同维度进行创建，1创建长度为n的buffer实例，创建数组为arr的buffer实例，创建字符串str的buffer实例 //&lt;1创建buffer实例 var buff; //buff = new Buffer(n);//创建长度为n的Buffer实例 //buff = new Buffer(arr);//创建数组为arr的buffer实例 //buff = new Buffer(str,encoding);//创建字符串Str的Buffer实例 buff = new Buffer(10); buff = new Buffer([10,20,30,40,50]); buff = new Buffer(&quot;www.funoob.com&quot;,&quot;utf-8&quot;);//&lt;2写入缓冲区 buff = new Buffer(256); len = buff.write(&quot;www.runoob.com&quot;); console.log(&quot;写入字节数为：&quot;+ len);//&lt;3从缓冲区中读数据buf = new Buffer(26);for(var i = 0 ; i &lt; 26 ; i++) &#123; buf[i]=+97;&#125;console.log(buf.toString(&apos;ascii&apos;));console.log(buf.toString(&apos;ascii&apos;,0,5));//截前不截后console.log(buf.toString(&apos;utf8&apos;,0,5));console.log(buf.toString(undefined,0,5));//使用utf8编码，并输出abcde//&lt;4将Buffer转换为json对象，语法如下：buf.toJson()var buf = new Buffer(&quot;www.runoob.com&quot;);var json = buf.toJSON(buf);console.log(json);var buf = new Buffer(&apos;我爱 node.js&apos;);var json = buf.toJSON(buf);console.log(json);//&lt;5 缓冲区合并var buffer1 = new Buffer(&apos;菜鸟教程&apos;);var buffer2 = new Buffer(&apos;www.runoob.com&apos;);var buffer3 = Buffer.concat([buffer1,buffer2]);console.log(&quot;buffer3 的内容是: &quot;+buffer3.toString());//&lt;6 缓冲区比较/* Node Buffer 比较的函数如下所示 buf.compare(otherBuffer)*/var buff1 = new Buffer(&apos;ABC&apos;);var buff2 = new Buffer(&apos;ABCD&apos;);var result = buff1.compare(buff2);if(result &lt; 0) &#123; console.log(buff1 + &quot;在&quot; + buff2 + &quot;之前&quot;);&#125;else if(result == 0) &#123; console.log(buff1 + &quot;在&quot; + buff2 + &quot;相同&quot;);&#125;else &#123; console.log(buff1 + &quot;在&quot; + buff2 + &quot;之后&quot;);&#125;//&lt;7 拷贝缓冲区/* 语法为 buf.copy(targetBuffer) 将调用copy方法 的缓冲区中内容拷贝到targetBuffer中*/var buffer1 = new Buffer(&apos;ABC&apos;);var buffer2 = new Buffer(3);buffer1.copy(buffer2);console.log(&quot;buffer2&apos;s content is : &quot;+ buffer2.toString());//&lt;8 缓冲区裁剪var buffer1 = new Buffer(&apos;runoob&apos;);var buffer2 = buffer1.slice(0,2);//裁剪是包前不包后end索引指向的元素并不被包含在裁剪之后的内容当中console.log(&quot;buffer2&apos;s content is : &quot;+buffer2.toString());//&lt;9 缓冲区长度/*缓冲区长度计算语法如下所示： buf.length; 返回值： 返回buffer对象所占据的内存长度*/var buffer = new Buffer(&apos;我爱 www.runoob.com &apos;);var len = buffer.length;//计算的是buff中字节的个数，而非传统的java中length的字符长度console.log(&quot;buffer&apos;s length is : &quot;+len); 注意：以上代码可以直接拷贝至node.js文件当中 运行结果12345678910111213141516$ node buff.js写入字节数为：14abcdefghijklmnopqrstuvwxyzabcdeabcdeabcde&#123; type: &apos;Buffer&apos;, data: [ 119, 119, 119, 46, 114, 117, 110, 111, 111, 98, 46, 99, 111, 109 ] &#125;&#123; type: &apos;Buffer&apos;, data: [ 230, 136, 145, 231, 136, 177, 32, 110, 111, 100, 101, 46, 106, 115 ] &#125;buffer3 的内容是: 菜鸟教程www.runoob.comABC在ABCD之前buffer2&apos;s content is : ABCbuffer2&apos;s content is : rubuffer&apos;s length is : 22 完。]]></content>
      <categories>
        <category>Node.js</category>
      </categories>
      <tags>
        <tag>Node</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoSql入门概述]]></title>
    <url>%2F2017%2F11%2F14%2FNoSql-des%2F</url>
    <content type="text"><![CDATA[首先应该说的是：所有天上飞的理念都会有落地实现。所以我觉得还是从数据存储处理的发展简史来引入NoSQL更为贴切，也能让自己有更细致的认识。数据存储与处理技术的发展有这么几个时间跨度 1.单机MySQL的美好时代 2.Memcached(缓存)＋MySQL＋垂直分离 3.MySQL主从读写分离 4.分库分表＋水平拆分＋mysql集群 5.MySQL的扩展性瓶颈 6.今天的架构 7.为什么使用NoSQL 1.单机MySQL的美好时代 在90年代，一个网站的访问量并不大，用单个数据库完全可以轻松应对，那个时候，更多的都是静态网页，动态交互型的网站并不多。网站的架构设计如下图所示： 大学期间我们大都用的是这个简单原始的架构来做网站，在数据量不是很大的情况下，是完全应付的来的。 那么上述架构能带来什么问题呢？ 1.数据量太大，一个机器放不下时。 MySQL5.7单表500w数量已经很棒，但是300w时就应该优化了。2.数据的索引（B+Tree）一个机器的内存放不下时。 索引是加速数据库访问效率的一种机制，但是索引是存储在内存当中的，如果数据量太大，那么意味着内存中存储的索引也会很大，在每一次加入数据的时候，数据库都需要维持索引，这样假设索引跟数据量同处一个机器，而不做优化，那么数据访问将非常之缓慢。3.访问量（读写混合）一个实例并不能承受。 如果满足不了上述当中的1-3个，请演化。 2.Memcached(缓存)＋MySQL＋垂直分离 2.1 Memcached(缓存) 随着访问量的上升，几乎大部分使用MySQL架构的网站在数据库上都出现了性能问题，web程序不再仅仅关注在功能上，同时也开始追求性能，程序员们开始大量的使用缓存技术来缓解数据库的压力，优化数据库的结构和索引，开始比较流行的是通过文件缓存来缓解数据库的压力，但是当访问量继续增大的时候，多台web服务器通过文件缓存不能共享，大量的小文件缓存也带来了比较高的IO压力，在这个时候，Memcached(缓存)自然成为一个非常时尚的技术产品。缓存的实质是替数据库挡了一层。频繁被访问的数据可以被放置于缓存当中，以供频繁访问。 架构图如下所示： 2.2 垂直拆分 什么是垂直拆分？ 举个例子，淘宝的数据库服务器是要进行定性 的，比如说有四台数据库服务器，两台进行买家数据的存储，两台进行卖家数据的存储，将原本一台数据库实例需要做的事情，均摊给四台服务器。DB数据操作能力会有很大提升。 ####3. MySQL主从读写分离 1 什么是主从复制？ 多搞几个数据库来存储数据，假设有三台数据库，一主二仆，即一台主服务器，两台从服务器，当新增数据至主数据库服务器的时候，那么同时复制此数据进入到从数据库服务器当中。数据复制是为了容灾备份，缓存备份，保证数据的完整性。2 什么是读写分离？ 增删改是写，查为读。 读就去职能为被查询的数据库服务器去读。 写就去职能为写数据的数据库服务器去写。 分工明确，结合缓存能实现性能的一大提升 架构图如下所示： 其中的M是master 即主DB Server ,S为slaver即从属DB Server,各有分工。写操作在 M，读操作在S。S的数据是从master方复制的。 4.分库分表＋水平拆分＋MySQL集群 承接主从复制，读写分离，以及Memcached的使用，这时MySQL主库的写压力开始出现瓶颈，而数据量的持续猛增，由于MYISAM使用表锁，在高并发下会出现严重的锁问题，大量的高并发MySQL应用开始使用InnoDB引擎代替MYISAM,由于数据量的指数级增长，只能继续对架构进行演变。与此同时，开始流行使用分库分表来缓解写压力和数据增长的扩展问题。这个时候，MySQL推出了还不太稳定的表分区，这也给技术实力一般的公司带来了希望。虽然MySQL推出了MySQL cluster集群，单性能也不能很好的满足互联网的要求，知识在高可靠性上提供了非常大的保证。 1 基本思想之什么是分库分表？ 从字面上简单理解，就是把原本存储于一个库的数据分块存储到多个库上，把原本存储于一个表的数据分块存储到多个表上。2 基本思想之为什么要分库分表？ 数据库中的数据量不一定是可控的，在未进行分库分表的情况下，随着时间和业务的发展，库中的表会越来越多，表中的数据量也会越来越大，相应地，数据操作，增删改查的开销也会越来越大；另外，由于无法进行分布式式部署，而一台服务器的资源（CPU、磁盘、内存、IO等）是有限的，最终数据库所能承载的数据量、数据处理能力都将遭遇瓶颈。3 分库分表的实施策略。 分库分表有垂直切分和水平切分两种。3.1 何谓垂直切分: 即将表按照功能模块、关系密切程度划分出来，部署到不同的库上。例如，我们会建立定义数据库workDB、商品数据库payDB、用户数据库userDB、日志数据库logDB等，分别用于存储项目数据定义表、商品定义表、用户数据表、日志数据表等。3.2 何谓水平切分: 当一个表中的数据量过大时，我们可以把该表的数据按照某种规则，例如userID散列，进行划分，然后存储到多个结构相同的表，和不同的库上。例如，我们的userDB中的用户数据表中，每一个表的数据量都很大，就可以把userDB切分为结构相同的多个userDB：part0DB、part1DB等，再将userDB上的用户数据表userTable，切分为很多userTable：userTable0、userTable1等，然后将这些表按照一定的规则存储到多个userDB上。 5.MySQL的扩展性瓶颈 视频、图片大数据量的数据时不能存储到数据库当中的，假设一个视频1.8G,MySQL中肯定是不能进行存储的。下图是淘宝分享出来的一种架构方式： 6.今天的架构 答案就是NoSQL。NoSQL(NoSQL ＝ Not Only SQL),意为”不仅仅是SQL”。泛指非关系型数据库。随着互联网2.0网站的兴起，传统的关系型数据库在应付web2.0网站，特别是超大规模和高并发的SNS类型的web2.0动态网站已经显得力不从心，暴露了很多难以克服的问题，而非关系型数据库则由于其本身的特点得到了非常迅速的发展。NoSQL数据库的产生就是为了解决大规模数据集合以及多中数据带来的挑战，尤其是大数据应用难题，包括大规模数据的存储。例如：谷歌活着Facebook每天为他们的用户收集万亿比特的数据。这些数据的存储不需要固定的模式，无需多余的操作就可以横向扩展。 下一节继续！]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>NoSql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoSql-Redis入门（事务）]]></title>
    <url>%2F2017%2F11%2F14%2FNoSql-Redis%2F</url>
    <content type="text"><![CDATA[定义 Redis 事务可以一次执行多个命令， 并且带有以下两个重要的保证：1.事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。2.事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。 一个事务从开始到执行会经历以下三个阶段： 1.开始事务。2.命令入队。3.执行事务。 for example以下是一个事务的例子， 它先以 multi 开始一个事务， 然后将多个命令入队到事务中， 最后由 exec 命令触发事务， 一并执行事务中的所有命令：123456789101112131415161718127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set username 张晓QUEUED127.0.0.1:6379&gt; get usernameQUEUED127.0.0.1:6379&gt; sadd persons-info 张咪 张冲 张明QUEUED127.0.0.1:6379&gt; smembers persons-infoQUEUED127.0.0.1:6379&gt; execOK张晓3张明张咪张冲127.0.0.1:6379&gt; 没啥可说的，大家都看的懂，多熟悉命令。惟一觉得有用的东西就是Redis中对事务中一系列操作命令的队列式存储。以及事务执行的四大约束原则，也算是特性：原子性、完整性、隔离性、持久性 ，也就是ACID。 还有一点，我在学习发布订阅的时候发现如果发布的信息是中文的话，在subscribe端接收的信息是乱码，这个可以在打开客户端的时候使用./redis-cli –raw避免]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>NoSql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 数据库规范--调优篇(终结篇)]]></title>
    <url>%2F2017%2F11%2F14%2FMySQL-%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"><![CDATA[前言 这篇是MySQL 数据库规范的最后一篇–调优篇，旨在提供我们发现系统性能变弱、MySQL系统参数调优，SQL脚本出现问题的精准定位与调优方法。 目录 1.MySQL 调优金字塔理论 2.MySQL 慢查询分析–mysqldumpslow、pt_query_digest工具的使用(SQL脚本层面) 3.选择合适的数据类型 4.去除无用的索引–pt_duplicate_key_checker工具的使用(索引层面) 5.反范式化设计(表结构) 6.垂直水平分表 7.MySQL 重要参数调优(系统配置) 1.MySQL 调优金字塔理论 如下图所示： 如上图所示: 数据库优化维度有四个:硬件、系统配置、数据库表结构、SQL及索引优化成本:硬件&gt;系统配置&gt;数据库表结构&gt;SQL及索引优化效果:硬件&lt;系统配置&lt;数据库表结构&lt;SQL及索引 2.MySQL 慢查询分析 对于系统中慢查询的分析，有助于我们更高效的定位问题，分析问题。mysqldumpslow、pt_query_digest是进行慢查询分析的利器。 前置条件1.查看本机MySQL Server 慢查询是否打开1show variables like &apos;slow%&apos;; 慢查询打开的情况如下所示： 若慢查询未打开则通过如下脚本设置慢查询：1234set global slow_query_log = on;即set global [上图中选项] = [你要设置的参数值]注意 slow_query_log_file 路径要加单引号，因为路径varchar 类型的。 2.1 mysqldumpslow分析慢查询mysqldumpslow 是MySQL自带的分析数据库慢查询的原生利器，使用方法如下：12mysqldumpslow -t 3 /data/mysql/log/mysql_slow_query.log | more \G;-t 3 显示前3条慢查询。 慢查询信息及分析但是 mysqldumpslow 显示的信息比较少，比如说此条sql执行次数在整体的执行次数中占用的百分比。类似于上述信息在 mysqldumpslow 的分析结果中是不存在的。 接下里我们介绍另一种工具 pt_query_digest 2.2 pt_query_digest分析慢查询之所以使用 pt_query_digest 工具对慢查询日志进行分析，主要原因是上述工具分析的内容更佳丰富，更加方便我们分析慢查询。前置条件安装 pt_query_digest ,Google搜索应该一大把。 确保 pt_query_digest 安装成功 执行如下操作：1pt-query-digest /data/mysql/log/mysql_slow_query.log &gt; slow_log.report 上述命令表示分析本机慢查询，并输出报表(文件)接下来分析生成的报表：1tail slow_log.report 按如下图所示信息： 我们对以上红色框图标记的报表信息进行详细描述，事实上这也是我们需要掌握的重点： 1.pct :sql语句某执行属性占所有慢查询语句某执行属性的百分比1.total：sql语句某执行属性的所有属性时间。2.Count：sql语句执行的次数，对应的pct 表示此sql 语句执行次数占所有慢查询语句执行次数的％比。上图为25%，total:表示总共执行了1次。3.Exec time:sql执行时间4.Lock time:sql执行期间被锁定的时间5.Rows sent:传输的有效数据，在select 查询语句中才有值6.Rows examine:总共查询的数据，非目标数据。7.Query_time distribution:查询时间分布8.SQL 语句:上图中为 select * from payment limit 10\G; 举例说明：加入某执行次数(count) 占比较高的sql语句，执行时间很长，Rows sent 数值很小，Rows examine 数值很大则表明(I/O较大)。那就表明有可能 sql 查询语句走了全表扫描，或者全索引扫描。那么就要建立合适索引或者优化sql语句了。如下很好的展示了我们在分析慢查询时需要着重分析的三点： 3.选择合适的数据类型可以参考MySQL开发规范–设计篇中的1.6 数据表设计与规划 如下图是常用字段类型的选择建议： 4.去除无用的索引–pt_duplicate_key_checker工具的使用(索引层面)此工具可以分析选定的 database 中的所有表中建立的index 中可能重复的索引，并给出了删除建议。 5.反范式化设计(表结构)关于范式的理解，请参考–MySQL 数据库规范–设计篇1.1 数据库表的设计范式(三范式&amp;反范式)先看一个不满足第三范式的数据表设计： 不满足第三范式产生的问题：假如将表中属于饮料分类的数据全部删除了，那么饮料分类也就不存在了，饮料的分类描述也就没了，查询不到了。这明显是不合理的。 重点：满足第三范式要求非键属性之间没有任何依赖关系，上图中分类与分类描述存在直接依赖关系。所以不符合第三范式的要求，那么要让表符合第三范式需要怎样做呢？ 拆分后满足第三范式的表： 我们采用一张 分类–商品名称 中间表来充当分表之后的中间桥梁。 当然如果一直遵循范式化设计，什么设计都向第三范式靠拢，当查询需要连接很多表的时候，建立索引已经起不到什么作用了，因为字段都不在同一张表中，所以建立索引是无用功，那么就要考虑反范式化的设计了。 6.垂直、水平分表原则上当表中数据记录的数量超过3000万条，再好的索引也已经不能提高数据查询的速度了，这时候就需要将表拆分成更多的小表，来进行查询。分表的机制有两种: 垂直分表:也就是将一部分列割裂开将数据放置在新设置的表中，优先选择字段值长度较长，类型较重的字段进行垂直分离。水平分表:将表中数据水平切分，可以按照范围、取模运算、hash运算进行数据切割，每张表的结构信息都是一样的。 7.MySQL 重要参数调优(系统配置)7.1 操作系统配置优化 简要介绍一下：1231.tcp连接配置，超时时间配置2.linux上文件打开数量限制3.除此之外，最好在MySQL 服务器上关闭iptables,selinux 等防火墙软件。 7. 2 MySQL 配置文件优化 MySQL 可以通过启动时制定配置参数和使用配置文件两种方法进行配置，在大多数情况下配置文件位于/etc/my.cnf或是/etc/mysql/my.cnf MySQL查找配置文件顺序可以通过以下方法获得：1$ /usr/sbin/mysqld --verbose --help | grep -A 1 &apos;Default options&apos; 注意:如果多个位置存在配置文件，后面的会覆盖前面的 7.2.1 innodb_buffer_pool_size innodb_buffer_pool_size 是非常重要的一个参数，用户配置Innodb 的缓冲池大小。如果数据库中只有Innodb表，则推荐配置量为总内存的75%。一般情况下运行如下命令，即可获得配置innodb_buffer_pool_size 参数的最佳值：123select engine round(sum(data_length+index_length)/1024/1024,1) as &apos;total MB&apos; from information_schema.tables where table_schema not in (&quot;information_schema&quot;,&quot;performance_schema&quot;) group by engine;Innodb_buffer_pool_size &gt; Total MB; 7.2.2 innodb_buffer_pool_instance MySQL 系统中有一些资源是需要独占使用的，比如缓冲去就是这样一种资源,因此如果系统中只有一个缓冲池，那么会增加阻塞的几率。我们多分成多个，则可以增加并发性能。 7.2.3 innodb_log_buffer_size innodb log缓冲的大小，设置大小只能能容得下1s中产生的事务日志就可以。 7.2.4 innodb_flush_log_at_trx_commit 关键参数，对innodb 的I/O影响很大。默认值为1，可以去0，1，2三个值，一般建议为2，但如果数据安全性要求较高则默认使用1。 0:每隔1s中才将事务提交的变更记录刷新到磁盘 1:每一次事务提交都把变更日志刷新到磁盘（最安全的方式） 2:每一次提交将日志刷新到缓冲区，隔1s之后会将日志刷新到磁盘。 7.2.5 innodb_read_io_threads &amp;&amp; innodb_write_io_threads 这两个参数决定了Innodb读写的I/O进程数，默认为4。决定这两个参数数值的因素也有两个：cpu核数、应用场景中读写事务比例。 7.2.6 innodb_file_per_table 关键参数，默认情况下配置为off。 控制innodb每一个表使用独立的表空间，默认情况下，所有的表都会建立在共享表空间当中。使用共享表空间会带来什么问题：12 1.多个表对共享表空间的操作，是顺序进行的，这样的话操作效率在并发情况下回降低。2.如果现在要删除一张表，会导致共享表空间先要将数据导出来，再重组。 7.2.7 innodb_stats_on_metadata 作用：决定了MySQL在什么情况下会刷新innodb表的统计信息。保证数据库优化器能使用到最新的索引，但不能太频繁，一般设置为off。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务特征、数据库隔离级别，以及各级别数据库加锁情况(含实操)--read uncommitted篇]]></title>
    <url>%2F2017%2F11%2F14%2Fmysql-isolation-read-uncommitted%2F</url>
    <content type="text"><![CDATA[1.目的 1.1 合适人群12341.数据库事务特征我只是背过，并没有很深刻的理解。2.数据库事务的隔离级别只是了解，并没有深刻理解，也没有在实际工作中体验使用过。3.经常面试被人问起数据库加锁情况，一头雾水，很懵。4.在网上找过很多博客，有的写得太多没耐心看，有的写得摘抄的定义，泛泛而谈，没有实操更没有讲解。 1.2 关于这篇分享对以上问题的解决1231.实践出真知，如果认真读完，并实操，实操过后反复咀嚼，相信上面的问题，除了你有没有耐心看等主观因素，其他的都能一一解决。2.希望这是理解数据库事务问题的一篇好文章。3.如果有什么问题，请评论下， 我们多交流谢谢。 2.事务本质剖析 2.1 什么是事务？2.2.1 如下表格所示： 事务类别(不考虑分布式事物) 事务本质 并发事务解决方案 并发事务方案解决的问题 并发事务解决方案实现原理 数据库事务(狭义理解) 数据库sql执行过程 控制事务隔离级别 确保数据完整、安全、一致性，在此基础上实现高性能访问（鱼和熊掌不可兼得） 不同的加锁策略 应用层事务(广义理解) 业务逻辑 制定多线程访问策略，如悲观锁(同步)、乐观锁（无锁，CAS思想） 确保线程之间操作不会相互影响，保证各访问能保证得到期望结果，并在此基础上实现最大可能性的高性能访问 不同的加锁策略 2.2.2 对上述表格内容的解释12345678910#### msyql事务1.mysql:传统理解 mysql 中的一次操作过程(sql 执行)是一次事务。2.mysql:那么多个线程 同时操作 mysql 中的数据（同一条数据，一个范围内数据）就叫并发事务。3.mysql:数据库层面使用不同的事务隔离级别来进行并发事务的控制，不同的隔离级别是因为数据库中内部锁机制的使用方式不同，例如有的是在select完成之后立马释放锁，有的是在整个事务commit 之后释放锁。--------------------------------------------------------------------------------------------------------------#### 应用层事务1.应用：其实每一个线程调用服务本质上也是事务。2.应用：多个线程同时调用服务，叫并发调用服务，也可以叫并发事务。3.应用：应用层应对并发事务(访问)解决方案有同步(悲观锁)、乐观锁(无锁CAS)。我们对并发访问做系统应用层控制也会使用到锁。 个人理解这就是事务的本质。事务不应该只仅限于数据库。2.2 关于ACID举例子说明12341.A 原子性：事务可以简单理解为一次数据库操作，也就是执行sql的过程，要么执行，要么不执行，整个执行结果只有两种执行成功，执行失败。2.C 一致性：A有100块钱，转1块钱给另外一个帐户，还有99块钱，在整个事务执行过程中，钱数总是100块，不会变，这就是一致性。3.I 隔离性：事务执行过程相互隔离，不会相互之间产生影响（这只是美好的愿望）。意思是多个事务并发执行的话，结果应该与多个事务串行执行效果是一样的。但并发情况下需要考虑性能，所以就需要在隔离性上做些手脚（妥协），也就是制定不同的隔离级别达到不同的并发性能。4.D 持久性：事务每一次的执行结果都应该持久化（存储）到数据库中（磁盘数据）。想想除了select，其他的update/delete/insert都会产生这样的结果，持久化在应用场景中是必须的，除非你写了假接口。哈哈。 3.数据库事务的隔离级别 3.1 为什么需要隔离级别?12341.四个特性之隔离性的体现。2.对不同并发事务应用场景提供不同解决方案。解决方案本质，加锁。3.如果不需要隔离别会出现什么情况？ 假设一个场景，数据库中任何数据在被并发 curd 时不设置隔开级别，也就是不加锁，情景平移，我们学习多线程时，对线程对公共变量的并发操作不加锁会导致各种异常情况的发生。所以不设置数据库隔离级别，数据的变化我们是不能祈求数据库中数据按照我们预期去改变的。 现在我们知道数据库 隔离级别 的必要性，接下来讨论不同隔离级别会带来的问题。 3.2 不同隔离级别带来的问题（重要！含实操部分，最好可以实践下）1.前置条件–几个概念的理解（重要）123456789101112131415161718192021不同隔离级别带来的数据操作问题： 1.脏读：两个事务，t1事务可以读取到t2事务正在做更改的数据的中间状态(t2事务执行过程中)，而这个数据的更改有可能不会被持久化(commit)，而是rollback，导致t1在同一事务内的两次读取同一行数据得到结果不同。 2.不可重复读：t1事务在整个事务执行过程中读取某一条记录多次，发现读取的此条记录不是每次都一样。 3.幻读：t1事务在整个事务执行过程中读取某一范围内的数据，在第二次读取时发现多了几行或者少了几行。-----------------------------------------------------------------------------------------------数据库中的几种隔离级别read uncommited--读未提交 该隔离级别指即使一个事务的更新语句没有提交,但是别的事务可以读到这个改变，几种异常情况都可能出现。极易出错，没有安全性可言，基本不会使用。read committed --读已提交 该隔离级别指一个事务只能看到其他事务的已经提交的更新，看不到未提交的更新，消除了脏读和第一类丢失更新，这是大多数数据库的默认隔离级别，如Oracle,Sqlserver。repeatable read --可重复读 该隔离级别指一个事务中进行两次或多次同样的对于数据内容的查询，得到的结果是一样的，但不保证对于数据条数的查询是一样的，只要存在读改行数据就禁止写，消除了不可重复读和第二类更新丢失，这是Mysql数据库的默认隔离级别。serializable --序列化读 意思是说这个事务执行的时候不允许别的事务并发写操作的执行.完全串行化的读，只要存在读就禁止写,但可以同时读，消除了幻读。这是事务隔离的最高级别，虽然最安全最省心，但是效率太低，一般不会用。------------------------------------------------------------------------------------------------数据库中的锁：1.共享锁（Share locks简记为S锁）：也称读锁，事务A对对象T加s锁，其他事务也只能对T加S，多个事务可以同时读，但不能有写操作，直到A释放S锁。2.排它锁（Exclusivelocks简记为X锁）：也称写锁，事务A对对象T加X锁以后，其他事务不能对T加任何锁，只有事务A可以读写对象T直到A释放X锁。3.更新锁（简记为U锁）：用来预定要对此对象施加X锁，它允许其他事务读，但不允许再施加U锁或X锁；当被读取的对象将要被更新时，则升级为X锁，主要是用来防止死锁的。因为使用共享锁时，修改数据的操作分为两步，首先获得一个共享锁，读取数据，然后将共享锁升级为排它锁，然后再执行修改操作。这样如果同时有两个或多个事务同时对一个对象申请了共享锁，在修改数据的时候，这些事务都要将共享锁升级为排它锁。这些事务都不会释放共享锁而是一直等待对方释放，这样就造成了死锁。如果一个数据在修改前直接申请更新锁，在数据修改的时候再升级为排它锁，就可以避免死锁。 接下来化繁为简，配合实操，来看看每种隔离级别场景。不要觉得繁琐，一定要读下去。 123演示场景配置：数据库：mysql 5.7命令行工具：iterm2.0 1.read uncommited–读未提交前置条件：1.开启两个 mysql 客户端终端2.查看当前客户端事务隔离级别1命令为：select @@session.tx_isolation; 3.选择数据库，建立演示表test，并设置当前客户端事务隔离级别为read uncommitted.12345678910111.mysql&gt; show databases;2.mysql&gt; use 你的演示数据库3.mysql&gt; CREATE TABLE `test` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=20 DEFAULT CHARSET=utf8;4.insert into test values(1,&apos;张三&apos;),(2,&apos;李四&apos;),(3,&apos;王五&apos;); 4.select @@session.tx_isolation;5.set session transaction isolation level read uncommitted;6.select @@session.tx_isolation; 注意：两个客户端都需执行set session transaction isolation level read uncommitted; 4.客户端1，客户端2设置事务提交模式为 set autocommit = 0;表示关闭默认的自动提交事务功能。1命令：set autocommit = 0; 5.开启事务1begin; 6.客户端1 执行 如下脚本1select name from test where id = 1 ; 结果如下图所示： 7.客户端2 执行如下脚本1update test set name = &apos;张八&apos; where id = 1; 结果如下图所示：8.切换到客户端1执行如下脚本1select name from test where id = 1; 结果如下图所示： 我们发现此时客户端1再次读id = 1的记录时，name 已经从 ‘张三’ 更改为 ‘张八’。 我们继续执行下一步操作9.客户端2执行回滚操作,脚本如下所示1rollback; 结果如下所示： 10.客户端1继续查看id ＝ 1的记录,如下脚本1select name from test where id = 1; 结果如下所示： 我们发现在客户端1的一次事务中id ＝ 1 的记录的name 发生了变化，这种变化就称之为脏读。下面我们分析下 read uncommitted 情况下的加锁情况。吐槽一句，现在网上的博客对这个隔离级别的加锁分析五花八门。分为三大门派：12341.美团博客说不加锁，链接在这：http://tech.meituan.com/innodb-lock.html 2.还有说读不加锁（这个我认同），写加行级共享锁。链接在这：[http://www.hollischuang.com/archives/943](http://www.hollischuang.com/archives/943)3.还有说读不加锁，写加行级排他锁（这个我也认同，我做过实践，稍后会演示），但是说写完立马释放行级排他锁。 那么到底是什么样子呢，我们看一下：演示过程，打开3个命令行终端，其中两个做演示，最后一个客户端查询当前 innodb 锁状态 设置事务隔离级别为read uncommitted。做如下演示：1.客户端1做如下操作：1update test set name = &apos;fxliutao&apos; where id = 32; 2.客户端2做与客户端相同操作，如下所示1update test set name = &apos;fxliutao&apos; where id = 32; 我们发现update 操作并没有执行，而是静止了如下图所示我们分析了在客户端2锁等待情况下的加锁情况：命令为：1select * from information_schema.INNODB_LOCKS\G; 可以得出结论，read uncommitted 隔离级别下，写操作是有锁的，而且是 X 排他锁，可以灭掉上述两个门派。 并且我们看下上述客户端2情景下的事务状态如下图所示： trx_id 为208579的代表的就是客户端2的事务，trx_state代表的是锁状态，代表 客户端2的事务 处于锁等待状态，为什么是锁等待状态呢，因为 客户端2的事务在更改 id ＝ 32 的记录时在主键上添加了 X(行级排他锁) 锁，你可能会有疑问，客户端1 的更新动作不是已经完成了么，那么 客户端1 肯定已经释放了在主键 id = 32 上的排他锁了呀，要不为什么客户端2 能读到客户端1 更改 id = 32 记录后的脏数据呢？但是真正的真相是客户端1在更新完后并没有释放排他锁，因为如果释放成功，那么客户端2的事务是能将 id ＝ 32 的记录更新成功的，但是并没有。那既然客户端1在更新完后并没有释放排他锁，那客户端2为什么还能读到脏数据呢，这跟排他锁的属性是相悖的呀(排他锁会阻塞除当前操作外的其他事务的所有读写操作)。这就是最矛盾的问题，我再SqlServer的官网上找到这句话，事实上也正是这句话让我茅塞顿开，如下：1Transactions running at the READ UNCOMMITTED level do not issue shared locks to prevent other transactions from modifying data read by the current transaction. READ UNCOMMITTED transactions are also not blocked by exclusive locks that would prevent the current transaction from reading rows that have been modified but not committed by other transactions. When this option is set, it is possible to read uncommitted modifications, which are called dirty reads. Values in the data can be changed and rows can appear or disappear in the data set before the end of the transaction. This option has the same effect as setting NOLOCK on all tables in all SELECT statements in a transaction. This is the least restrictive of the isolation levels. 翻译是：1在READ UNCOMMITTED级别运行的事务不会发出共享锁，以防止其他事务修改当前事务读取的数据。读取UNCOMMITTED事务也不被排他锁阻止，这将阻止当前事务读取已被修改但未被其他事务提交的行。设置此选项时，可以读取未提交的修改，称为脏读。可以更改数据中的值，并且行可以在事务结束之前在数据集中显示或消失。此选项与在事务中的所有SELECT语句中的所有表上设置NOLOCK具有相同的效果。这是隔离级别的最小限制。 看到了吧读取UNCOMMITTED事务也不被排他锁(排他锁将阻止当前事务读取已被修改但未被其他事务提交的行)阻止其实想想也对，应为排它锁对任何其他的事务开始之前申请的排它锁，共享锁都不兼容。但是如果我读不申请锁，就不会产生上述问题了呀。 所以最终结论是：read uncommitted 读不加锁，写加排他锁，并到事务结束之后释放。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务特征、数据库隔离级别，各级别数据库加锁情况(含实操)--read committed与 MVCC]]></title>
    <url>%2F2017%2F11%2F14%2FMySQL-ReadCommitted-MVCC%2F</url>
    <content type="text"><![CDATA[上节回顾 上篇记录了我对MySQL 事务 隔离级别 read uncommitted 的理解。这篇记录我对 MySQL 事务隔离级别 read committed &amp; MVCC 的理解。前言 可以很负责人的跟大家说，MySQL 中的此隔离级别不单单是通过加锁实现的，实际上还有repeatable read 隔离级别，其实这两个隔离级别效果的实现还需要一个辅助，这个辅助就是MVCC-多版本并发控制，但其实它又不是严格意义上的多版本并发控制，是不是很懵，没关系，我们一一剖析。 目录 1.单纯加锁是怎么实现 read committed 的?2.真实的演示情况是什么样子的？3.MVCC 实现原理？4.对于InnoDB MVCC 实现原理的反思 1.单纯加锁是怎么实现 read committed 的? 从此隔离级别效果入手：事务只能读其他事务已提交的的记录。 数据库事务隔离级别的实现，InnoDB 支持行级锁，写时加的是行级排他锁(X lock)，那么当其他事务访问另一个事务正在update (除select操作外其他操作本质上都是写操作)的同一条记录时，事务的读操作会被阻塞。所以只能等到记录(其实是索引上的锁)上的排他锁释放后才能进行访问，也就是事务提交的时候。这样确实能实现read commited隔离级别效果。 数据库这样做确实可以实现 事务只能读其他事务已提交的的记录 的效果，但是这是很低效的一种做法，为什么呢？因为对于大部分应用来说，读操作是多于写操作的，当写操作加锁时，那么读操作全部被阻塞，这样会导致应用的相应能力受数据库的牵制。 2.真实的演示情况是什么样子的？ 看如下操作：1.开启两个客户端实例,设置事务隔离级别为read committed，并各自开启事务。 123set transaction isolation level read committed;set autocommit = 0;begin； 2.客户端1做更新操作：1update test set name = &apos;测试&apos; where id =32; 结果如下图所示： 3.客户端2做查询操作：1select name from test where id = 32; 结果如下所示： 这时估计你有疑问了，正在 被客户端1 upate 的记录，客户端2还能无阻塞的读到，而且读到的是未更改之前的数据。那就是 InnoDB 的辅助打得好，因为内部使用了 MVCC 机制，实现了一致性非阻塞读，大大提高了并发读写效率，写不影响读，且读到的事记录的镜像版本。 下面开始介绍 MVCC 原理。 3.MVCC 实现原理 网上对 MVCC 实现原理 的讲述五花八门，良莠不齐。包括《高性能MySQL》对 MVCC 的讲解只是停留在表象，并没有结合源码去分析。当然绝大多数人还是相信这本书的，从来没有进行深剖，思考。如下是 《高性能MySQL》对 MVCC实现原理 的描述：123&quot;InnoDB的 MVCC ，是通过在每行记录的后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存了行的过期时间，当然存储的并不是实际的时间值，而是系统版本号。&quot; 就是这本书，蒙蔽了真理，害人不浅。 我们还是看源码吧： 1.记录的隐藏列其实有三列123456789在Mysql中MVCC是在Innodb存储引擎中得到支持的，Innodb为每行记录都实现了三个隐藏字段：6字节的事务ID（DB_TRX_ID）7字节的回滚指针（DB_ROLL_PTR）隐藏的ID6字节的事物ID用来标识该行所述的事务，7字节的回滚指针需要了解下Innodb的事务模型。 2.MVCC 实现的依赖项MVCC 在mysql 中的实现依赖的是 undo log 与 read view。121.undo log: undo log中记录的是数据表记录行的多个版本，也就是事务执行过程中的回滚段,其实就是MVCC 中的一行原始数据的多个版本镜像数据。2.read view: 主要用来判断当前版本数据的可见性。 3.undo log undo log是为回滚而用，具体内容就是copy事务前的数据库内容（行）到undo buffer，在适合的时间把undo buffer中的内容刷新到磁盘。undo buffer与redo buffer一样，也是环形缓冲，但当缓冲满的时候，undo buffer中的内容会也会被刷新到磁盘；与redo log不同的是，磁盘上不存在单独的undo log文件，所有的undo log均存放在主ibd数据文件中（表空间），即使客户端设置了每表一个数据文件也是如此。 我们通过行的更新过程来看下undo log 是如何形成的？ 3.1 行的更新过程下面演示下事务对某行记录的更新过程： 初始数据行F1～F6是某行列的名字，1～6是其对应的数据。后面三个隐含字段分别对应该行的事务号和回滚指针，假如这条数据是刚INSERT的，可以认为ID为1，其他两个字段为空。2.事务1更改该行的各字段的值当事务1更改该行的值时，会进行如下操作：用排他锁锁定该行记录redo log把该行修改前的值Copy到undo log，即上图中下面的行修改当前行的值，填写事务编号，使回滚指针指向undo log中的修改前的行3.事务2修改该行的值与事务1相同，此时undo log，中有有两行记录，并且通过回滚指针连在一起。 4.read view 判断当前版本数据项是否可见 在innodb中，创建一个新事务的时候，innodb会将当前系统中的活跃事务列表（trx_sys-&gt;trx_list）创建一个副本（read view），副本中保存的是系统当前不应该被本事务看到的其他事务id列表。当用户在这个事务中要读取该行记录的时候，innodb会将该行当前的版本号与该read view进行比较。具体的算法如下: 设该行的当前事务id为trx_id_0，read view中最早的事务id为trx_id_1, 最迟的事务id为trx_id_2。 如果trx_id_0&lt; trx_id_1的话，那么表明该行记录所在的事务已经在本次新事务创建之前就提交了，所以该行记录的当前值是可见的。跳到步骤6. 如果trx_id_0&gt;trx_id_2的话，那么表明该行记录所在的事务在本次新事务创建之后才开启，所以该行记录的当前值不可见.跳到步骤5。 如果trx_id_1&lt;=trx_id_0&lt;=trx_id_2, 那么表明该行记录所在事务在本次新事务创建的时候处于活动状态，从trx_id_1到trx_id_2进行遍历，如果trx_id_0等于他们之中的某个事务id的话，那么不可见。跳到步骤5. 从该行记录的DB_ROLL_PTR指针所指向的回滚段中取出最新的undo-log的版本号，将它赋值该trx_id_0，然后跳到步骤2. 将该可见行的值返回。 需要注意的是，新建事务(当前事务)与正在内存中commit 的事务不在活跃事务链表中。 对应代码如下： 函数：read_view_sees_trx_id。read_view中保存了当前全局的事务的范围：【low_limit_id， up_limit_id】1. 当行记录的事务ID小于当前系统的最小活动id，就是可见的。 if (trx_id &lt; view-&gt;up_limit_id) { return(TRUE); }2. 当行记录的事务ID大于当前系统的最大活动id，就是不可见的。 if (trx_id &gt;= view-&gt;low_limit_id) { return(FALSE); }3. 当行记录的事务ID在活动范围之中时，判断是否在活动链表中，如果在就不可见，如果不在就是可见的。 for (i = 0; i &lt; n_ids; i++) { trx_id_t view_trx_id = read_view_get_nth_trx_id(view, n_ids - i - 1); if (trx_id &lt;= view_trx_id) { return(trx_id != view_trx_id); } } 5 事务隔离级别的影响 但是：对于两张不同的事务隔离级别 tx_isolation=’READ-COMMITTED’: 语句级别的一致性：只要当前语句执行前已经提交的数据都是可见的。 tx_isolation=’REPEATABLE-READ’; 语句级别的一致性：只要是当前事务执行前已经提交的数据都是可见的。针对这两张事务的隔离级别，使用相同的可见性判断逻辑是如何做到不同的可见性的呢？ 6.不同隔离级别下read view的生成原则 这里就要看看read_view的生成机制：1. read-commited: 函数：ha_innobase::external_lock if (trx-&gt;isolation_level &lt;= TRX_ISO_READ_COMMITTED &amp;&amp; trx-&gt;global_read_view) { / At low transaction isolation levels we let each consistent read set its own snapshot / read_view_close_for_mysql(trx);即：在每次语句执行的过程中，都关闭read_view, 重新在row_search_for_mysql函数中创建当前的一份read_view。这样就可以根据当前的全局事务链表创建read_view的事务区间，实现read committed隔离级别。2. repeatable read： 在repeatable read的隔离级别下，创建事务trx结构的时候，就生成了当前的global read view。 使用trx_assign_read_view函数创建，一直维持到事务结束，这样就实现了repeatable read隔离级别。 正是因为6中的read view 生成原则，导致在不同隔离级别()下,read committed 总是读最新一份快照数据，而repeatable read 读事务开始时的行数据版本。 4.InnoDB MVCC 实现原理的深刻反思 上述更新前建立undo log，根据各种策略读取时非阻塞就是MVCC，undo log中的行就是MVCC中的多版本，这个可能与我们所理解的MVCC有较大的出入。 一般我们认为MVCC有下面几个特点： 每行数据都存在一个版本，每次数据更新时都更新该版本修改时Copy出当前版本随意修改，个事务之间无干扰保存时比较版本号，如果成功（commit），则覆盖原记录；失败则放弃copy（rollback）就是每行都有版本号，保存时根据版本号决定是否成功，听起来含有乐观锁的味道。。。，而 Innodb的实现方式是： 事务以排他锁的形式修改原始数据把修改前的数据存放于undo log，通过回滚指针与主数据关联修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback） 二者最本质的区别是，当修改数据时是否要排他锁定，如果锁定了还算不算是MVCC？ Innodb的实现真算不上MVCC，因为并没有实现核心的多版本共存，undolog中的内容只是串行化的结果，记录了多个事务的过程，不属于多版本共存。但理想的MVCC是难以实现的，当事务仅修改一行记录使用理想的MVCC模式是没有问题的，可以通过比较版本号进行回滚；但当事务影响到多行数据时，理想的MVCC据无能为力了。 比如，如果Transaciton1执行理想的MVCC，修改Row1成功，而修改Row2失败，此时需要回滚Row1，但因为Row1没有被锁定，其数据可能又被Transaction2所修改，如果此时回滚Row1的内容，则会破坏Transaction2的修改结果，导致Transaction2违反ACID。 理想MVCC难以实现的根本原因在于企图通过乐观锁代替二段提交。修改两行数据，但为了保证其一致性，与修改两个分布式系统中的数据并无区别，而二提交是目前这种场景保证一致性的唯一手段。二段提交的本质是锁定，乐观锁的本质是消除锁定，二者矛盾，故理想的MVCC难以真正在实际中被应用，Innodb只是借了MVCC这个名字，提供了读的非阻塞而已。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务特征、数据库隔离级别，各级别数据库加锁情况(含实操)--Repeatable Read与MVCC]]></title>
    <url>%2F2017%2F11%2F14%2FMySQL-RepeatableRead-MVCC%2F</url>
    <content type="text"><![CDATA[上节回顾 上两篇记录了我对MySQL 事务 隔离级别 read uncommitted 、MySQL 事务隔离级别 read committed＋MVCC 的理解。这篇记录我对 Repeatable Read 的理解。前言 MySQL在 read committed、Repeatable Read 两个级别下都会使用到MVCC, 并且只在这两个级别下使用。 目录 1.单纯加锁是怎么实现 Repeatable Read 的?2.真实的情况是什么样子的？ 1.单纯加锁是怎么实现 Repeatable Read 的 1.多线程同时更新同一条记录，加X锁。所以并发场景下的 update 是串行执行的。 2.工业定义上的 select 一条记录，这个时候会在记录上加读共享锁(S锁)，并到事务结束，因为在这种情况下才能实现记录在事务时间跨度上的可重复读。在读的时候不允许其他事务修改这条记录。 3.update 一条语句，这个时候会在记录上加行级排他锁(X锁)，并到事务结束，这中场景下，其他读事务会被阻塞。 2.真实的情况是什么样子的？ 读不影响写，写不影响读。 1.读不影响写：事务以排他锁的形式修改原始数据，读时不加锁，因为 MySQL 在事务隔离级别Read committed 、Repeatable Read下，InnoDB 存储引擎采用非锁定性一致读－－即读取不占用和等待表上的锁。即采用的是MVCC中一致性非锁定读模式。因读时不加锁，所以不会阻塞其他事物在相同记录上加 X锁来更改这行记录。2.写不影响读：事务以排他锁的形式修改原始数据，当读取的行正在执行 delete 或者 update 操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB 存储引擎会去读取行的一个快照数据。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 数据库索引原理与分类]]></title>
    <url>%2F2017%2F11%2F14%2FMySQL-%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[前言 数据库索引本质上是一种数据结构(存储结构+算法)，目的是为了加快目标数据检索的速度。 目录 1.索引的本质与原理？2.索引的分类？ 1.索引的本质与原理 我们先看一个问题：假设现在有100000条从0到10000且从大到小排列的整型数据，1条数据的大小假设(真的只是假设)是1KB,操作系统的每次I/O数据块(页)大小是8KB。如果现在我要查找其中 50001 这个数据值，有如下几个方式：1.最蠢的方式，遍历，每次遍历到一个值，就用这个值跟目标值做对比，如果不等于那么查找下一个。这样的话那么每次I/O是8条数据，目标数据在50001/8 约6600多次I/O 才能找到目标数据。2.二分查找，最好一次性将100000条数据全部读到内存，这样查找也是很快的。 但是即使二分查找很快，但这些数据也不能单单通过一次I/O全部进入内存，进行运算。 那么怎样在I/O 块大小 的限制下快速利用二分查找找到目标值呢？我们得引入新的数据结构，B+树正好可以解决上述I/O块大小的限制，解决限制不是说增大了限制范围，而是我们在此限制上改变了数据的存储结构，即在同等限制条件下，快速检索到目标数据，如下是B+树的原理讲解： 注意，我们主要讲解索引的原理，没有必要过于纠结B+树的各种操作，及代码实现 1.1 B+ 树根据上图所示，及其论文定义： 1.图上蓝色的块为关键字，我们发现所有的关键字最终都会被包含在叶子节点当中。 图上的黄色区块表示的是子树的指针域，比如根节点下的P2指向的就是28-65之间的索引。 2.所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。 (而B 树的叶子节点并没有包括全部需要查找的信息) 3.所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 (而B 树的非终节点也包含需要查找的有效信息) 现在我们来看下查找数据 60 的 查找过程，如下所示:1231.I/O第一次：读入5、28、65 数据块，在此同级别节点块上，60在28到65之间(其实是二分查找)，那走P2指针指向的子树。2.I/O第二次：读入28、35、56 数据块，在此同级别节点块上，60大于56，所以走P3指针指向的子树(上图中就是叶子节点)。3.I/O第三次：读入叶子节点，在这个叶子节点中，使用二分查找算法找到目标值60。 由上述查找过程所示统共需要三次I/O就能查到目标值，性能大大提升。 2.索引的分类？ 2.1 聚簇索引 &amp; 非聚簇索引 InnoDB 主键使用的是聚簇索引，MyISAM 不管是主键索引，还是二级索引使用的都是非聚簇索引。 下图形象说明了聚簇索引表(InnoDB)和非聚簇索引(MyISAM)的区别： 1.对于非聚簇索引表来说（右图），表数据和索引是分成两部分存储的，主键索引和二级索引存储上没有任何区别。使用的是B+树作为索引的存储结构，所有的节点都是索引，叶子节点存储的是索引+索引对应的记录的地址。 2.对于聚簇索引表来说（左图），表数据是和主键一起存储的，主键索引的叶结点存储行数据(包含了主键值)，二级索引的叶结点存储行的主键值。使用的是B+树作为索引的存储结构，非叶子节点都是索引关键字，但非叶子节点中的关键字中不存储对应记录的具体内容或内容地址。叶子节点上的数据是主键与具体记录(数据内容)。 聚簇索引的优点 1.当你需要取出一定范围内的数据时，用聚簇索引也比用非聚簇索引好。 2.当通过聚簇索引查找目标数据时理论上比非聚簇索引要快，因为非聚簇索引定位到对应主键时还要多一次目标记录寻址,即多一次I/O。 聚簇索引的缺点 1.插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键。2.更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新。3.二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。二级索引的叶节点存储的是主键值，而不是行指针（非聚簇索引存储的是指针或者说是地址），这是为了减少当出现行移动或数据页分裂时二级索引的维护工作，但会让二级索引占用更多的空间。4.采用聚簇索引插入新值比采用非聚簇索引插入新值的速度要慢很多，因为插入要保证主键不能重复，判断主键不能重复，采用的方式在不同的索引下面会有很大的性能差距，聚簇索引遍历所有的叶子节点，非聚簇索引也判断所有的叶子节点，但是聚簇索引的叶子节点除了带有主键还有记录值，记录的大小往往比主键要大的多。这样就会导致聚簇索引在判定新记录携带的主键是否重复时进行昂贵的I/O代价。 唯一索引 主键就是唯一索引，但是唯一索引不一定是主键，唯一索引可以为空，但是空值只能有一个，主键不能为空。普通唯一索引：单个字段上建立唯一索引，需要此字段所在的列上不能有重复的值，属于二级索引。复合唯一索引：多个字段上联合建立唯一索引，属于二级索引。 覆盖索引 查找的目标数据， 包含在索引中，如建立idx_colum1_colum2. 1select colum1 from table where colum1 = ? and colum2 &gt; ? 通过查询索引就能确定最终的数据，不用再利用叶子节点中存储的主键值去查询对应的数据。覆盖索引的性能是极高的。 索引原理篇讲述完，下一篇讲解索引的优化，以及 explain 工具的使用。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[存储过程]]></title>
    <url>%2F2017%2F11%2F14%2FMySQL-%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[存储过程简介 存储过程（Stored Procedure）是数据库系统中，一组为了完成特定功能的SQL 语句集，经编译后存储在数据库中，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。在数据库系统中，存储过程和触发器具有很重要的作用。无论是存储过程还是触发器，都是SQL 语句和流程控制语句的集合。 存储过程分类1系统存储过程 以sp开头,用来进行系统的各项设定.取得信息.相关管理工作。2本地存储过程 用户创建的存储过程是由用户创建并完成某一特定功能的存储过程，这跟各种编程语言里用户自己写的函数非常类似。我们一般所说的存储过程就是指本地存储过程。今天我们重点介绍本地存储过程，其他存储过程了解即可。3临时存储过程 分为两种存储过程：一是本地临时存储过程，以“#”开头，这样的存储过程就是存放在tempdb数据库中的本地临时存储过程，且只有创建它的用户才能执行它; 二是全局临时存储过程，以“##”开头，这样的存储过程就是存储在tempdb数据库中的全局临时存储过程，全局临时存储过程一旦创建，以后连接到服务器的任意用户都可以执行它，而且不需要特定的权限。4远程存储过程 在SQL Server2005中，远程存储过程(Remote Stored Procedures)是位于远程服务器上的存储过程，通常可以使用分布式查询和EXECUTE命令执行一个远程存储过程。5扩展存储过程 扩展存储过程(Extended Stored Procedures)是用户可以使用外部程序语言编写的存储过程，而且扩展存储过程的名称通常以xp开头。 创建存储过程的基本代码结构：12345678910 create procedure Procedure_Name //Procedure_Name为存储过程（不能以阿拉伯数字开头），在一个数据库中触发器名是唯一的。 @Param1 int ,@Param2 int//@Param1和 @Param2为存储过程的参数，DataType为参数类型，多个参数采用“,”隔开AS//存储uguocheng要执行的操作BEGIN --begin跟end组成，可以不写，如果执行sql语句较为麻烦，则使用BEGIN END会使得代码更加整齐，容易理解ENDGO //操作完成exec Procedure_Name[采纳数名] //调用存储过程 存储过程优缺点总结：优点 1.存储过程只在创造时进行编译，以后每次执行存储过程都不需再重新编译，而一般SQL语句每执行一次就编译一次,所以使用存储过程可提高数据库执行速度。 2.当对数据库进行复杂操作时(如对多个表进行Update,Insert,Query,Delete时)，可将此复杂操作用存储过程封装起来与数据库提供的事务处理结合一起使用。 3.存储过程可以重复使用,可减少数据库开发人员的工作量(复用性高，面向对象的编程思想) 4.安全性高,可设定只有某些用户才具有对指定存储过程的使用权缺点 1.调试麻烦，但是用 PL/SQL Developer 调试很方便！弥补这个缺点。 2.移植问题，数据库端代码当然是与数据库相关的。但是如果是做工程型项目，基本不存在移植问题。 3.重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运行时刻自动编译）。 4.如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，接着就是系统的相关问题了，最后如果用户想维护该系统可以说是很难很难、而且代价是空前的，维护起来更麻烦。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 数据库索引使用场景与注意事项]]></title>
    <url>%2F2017%2F11%2F14%2FMySQL-index-notice-issue%2F</url>
    <content type="text"><![CDATA[目录 1.何种查询支持索引？ 2.注意事项和建议 一 何种查询支持索引？ 1 MySQL 目前支持前导列 12345678910就目前来说，mysql 暂时只支持最左前缀原则进行筛选。例子：创建复合索引create index idx_a_b_c on tb1(a,b,c)只有使用如下条件才可能应用到这个复合索引1.where a=?2.where a = ? and b = ?3.where a = ? and b = ? and c = ?但4.where a = ? and c ＝ ？只会使用到mysql 索引 a 列的信息 2.索引列上的范围查找 1234对于某个条件进行范围查找时，如果这个列上有索引，且使用 where ... between and ... &gt; ,&lt; 等范围操作，那么可能用到索引范围查找，如果索引范围查找的成本太高，数据库可能会选择全表扫描的方式。注意 in 不属于范围查找的范畴 3.join 列 123在联合查询两个表时，比如查询语句为 select a.col1,b.col2 from a join b on a.id = b.id,其中id 为两个表的主键，如果a是小表，那么a 就被视为驱动表，那么数据库可能全表扫描a 表，并用 a表的每个id 去探测b表的索引查询匹配的记录。 4.where 子句 1234567891011121314151617181920形如：where a = ? and b = ? and c&gt;1000where a = ? and b = ? and c = ? and d&gt;1000where 子句的条件列是复合索引前面的索引列＋另一个列的范围查找create index idx_a_b_c_d on tb1(a,b,c,d);形如：where a = ? and b = ? and c&gt;1000where a = ? and b = ? and c = ? and d&gt;1000才会用到这个索引下面两个查询：where a = ? and b =? and c&gt;10000 and d&lt; 10000这个例子中d d &lt;10000这个操作不会走索引where a &gt;? and b =? and c&gt;10000 and d&lt; 10000这个例子中a列上有范围查找，那么b、c、d列上的索引信息都不能被利用原则，创建索引，考虑把复合索引的范围查找放到最后。 5.mysql 优化器 1mysql 优化器会做一些特殊优化，比如对于索引查找max(索引列)可以直接进行定位。遇到max，min 是可以在列上做索引。 二 注意事项和建议 1.where 条件中的索引列不能是表达式的一部分，mysql 不支持函数索引 2.InnoDB 二级索引底层叶子极点存储的是索引+主键值1InnoDB 的非主键索引存储的不是实际的记录的指针，而是主键的值，所以主键最好是整数型，如自增ID ,基于主键存取数据是最高效的，使用二级索引存取数据则需要进行二次索引查找。 3.索引尽量是高选择性的12345而且要留意基数值，基数值指的是一个列中不同值的个数，显然，最大基数意味着该列中的每个值都是唯一的，最小基数意味着该列中的所有值都是相同的，索引列的基数相对于表的行数较高时，也就重复值更少，索引的工作效果更好。有种情况虽然基数很小，但由于数据分布很不均匀因此也会导致某些记录数很小，那么这种情况也适合建立索引加速查找这部分数据。 4.使用更短的索引123456789可以考虑前缀索引，但应确保选择的前缀的长度可以保证大部分值是唯一的。如：alter table test add key(col(6))衡量不同前缀索引唯一值比例。select count(distinct left(col_name,5))/count(*) As sele5，select count(distinct left(col_name,6))/count(*) As sele6，select count(distinct left(col_name,7))/count(*) As sele7，select count(distinct left(col_name,8))/count(*) As sele8，select count(distinct left(col_name,9))/count(*) As sele9from table_name; 5.避免创建过多的索引123索引过多可能会浪费大量空间尤其本身字段量较大的字符串，索引过多可能会浪费空间，且降低修改数据的速度，所以，不要创建过多的索引，也不要创建重复的索引。 6.如果是唯一值得列，创建唯一索引会更佳，也可以确保不会出现重复数据. 7.使用覆盖索引能大大提高性能12345覆盖索引：所有数据都可以从索引中得到，而不需要去读物理记录。例如某个复合索引idx_a_b_c 建立在表tb1 的 a、b、c 列上，那么对于如下的sql 语句select a,b from tb1 where a = ? and b = ? and c =?mysql可以直接从索引idx_a_b_c 中获取数据。使用覆盖索引也可以避免二次索引查找。使用explain 命令输出查询计划，如果extra列是“using index ” 那就表示使用的是覆盖索引。 8.利用索引来排序12345678mysql 有两种方式可以产生有序结果，一种是使用文件排序，另一种是扫描有序的索引，我们尽量使用索引来排序 注意事项： 1. 尽量保证索引列和order by 的列相同，且各列按照相同的顺序排序。 比如在表table1 的复合索引idx_a_b_c（创建在a,b,c上)； 如：select * from table1 order by a,b,c; select * from table1 where a=? and b =? order by c 以上查询都可以利用有序索引来加速检索顺序。 2.如果连接多张表，那么order by 引用的列需要再表连接顺序的首张表内。 9 添加冗余索引需要权衡:123如果一个索引column A 那么一个新的索引（columnA,columnB）就是冗余索引一般情况下不论是新增冗余索引，还是扩展原索引为冗余索引，都会导致索引文件的增大，并且增加了维护索引的开销。比如更改了列值，并且在此列上建立了索引，那么这个列值更改之后，索引是要进行重新排序的。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[where与having的区别]]></title>
    <url>%2F2017%2F11%2F14%2Fmysql-where-having%2F</url>
    <content type="text"><![CDATA[区别概述： 1.where是一个约束声明，使用where约束来自数据库的数据，where是在结果集返回之前起作用的，where中不能使用聚合函数。注意：返回结果集之前起作用2.having是一个过滤声明，是在查询返回结果集以后对查询结果进行过滤操作，在Having中可以使聚合函数。注意：返回结果集之后起作用3.在查询过程中where子句、聚合语句、having子句，的执行优先级为where&gt;group by&gt;聚合语句(sum、count、avg、max、min)&gt;having子句 举例说明： &lt;1.假设有数据表：1234567CREATE TABLE `test`.`salary_info` ( `id` int(10) unsigned NOT NULL auto_increment, `department` varchar(16) NOT NULL default &apos;&apos;, `name` varchar(16) NOT NULL default &apos;&apos;, `salary` int(10) unsigned NOT NULL default &apos;0&apos;, PRIMARY KEY (`id`) ) ENGINE=MyISAM AUTO_INCREMENT=7 DEFAULT CHARSET=utf8; example 1: 要查找平均工资大于3000的部门1select department,avg(salary) from salary_info group by department having avg(salary)&gt;3000 解释：此时我们只能用having，而不能使用where子句。1.sql语句中使用了聚合函数。2.对聚合后的结果进行筛选。所以不能使用where。3.可以从题目中看出平均工资3000，是必须要知道总额之后才能计算出平均值，也就是在知道结果集之后才能计算出avg，这就是使用having的原因 example 2: 要查询每个部门工资大于3000的员工个数12select department,count(*) as c from salary_info wheresalary&gt;3000 group by department 解释：1.此处的sql执行顺序是这样的 where语句在没有获得结果集之前对数据进行约束，符合条件的数据被筛选出来，然后对数据分组，然后对每个分组的数据进行count统计。这个执行顺序是跟区别概述中第三条对应的，这也是优先级是以上所述的原因。 2.可以从题目中看出个人工资大于3000的员工个数，则在count之前，必须把工资大于3000的员工晒寻出来。在返回结果集之前先得把这些人筛选出来，而返回结果集之前的操作使用where。 &lt;2.假设有数据表：Orders1234567o_Id | OrderDate | OrderPrice | Customer 1 2008/12/29 1000 yy 2 2008/11/23 2000 xx 3 2008/10/05 1600 mm 4 2008/09/28 700 hh 5 2008/08/06 300 gg 6 2008/07/21 100 uu example 1: 计算”OrderPrice” 字段的平均值1select avg(OrderPrice) as v from Orders; example 2:找到OrderPrice 大于OrderPrice平均值的客户12select Customer From Orders where OrderPrice&gt;(select avg(OrderPrice) as v from Orders);//这个（）语句是第一个where语句的子查询，先执行子查询，再以子查询的结果作为筛选条件，过滤出结果集]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 数据库规范--开发篇]]></title>
    <url>%2F2017%2F11%2F14%2FMySQL-develop%2F</url>
    <content type="text"><![CDATA[目录 1.sql语句编写 2.explain 工具的使用–重点 1.sql语句编写 SQL编写1234567891011121314151617181920212223241.执行大的delete、update、insert操作要慎重，特别是对业务繁忙的系统，要尽量避免对线上业务产生影响。 解决办法是：大操作切割为小操作，使用limit子句限制每次操作的记录数，也可以利用一些日期字段基于更小粒度的时间范围进行操作。2.避免使用select * 语句，select语句之用于获取需要的字段。3.使用预编译语句，可以提高性能并且防范 sql注入 攻击。4.一般情况下update,delete 语句中不要使用limit。5.where 条件语句中必须使用合适的类型，避免mysql进行隐式转换。6.insert into 必须显式指明字段名称，不要使用insert into table()。7.避免在sql 语句中进行数学运算或函数运算，避免将业务逻辑和数据存储耦合在一起。8.insert 语句如果使用批量提交，如insert into table values(),()...那么values 的个数不应过多。一次性提交过多记录，会导致I/O紧张，出现慢查询。9.避免使用存储过程、触发器、函数等，这些特性会将业务逻辑与数据库耦合在一起，并且MySQL的存储过程，触发器，函数中可能存在bug。10.尽量避免使用子查询，连接。尽量将子查询转化为连接查询，mysql 查询优化器会优化连接查询，但连接的表要尽可能的少，如果很多，可以考虑反范式设计。即对设计阶段做一些改造。11.使用合理的sql语句以减少与数据库的交互次数。12.建议使用合理的分页技术以提高操作效率。 2.explain 工具的使用 explain工具的作用1231.使用 explain 工具可以确认执行计划是否良好，查询是否走了合理的索引。2.不同版本MySQL 优化器各有不同，一些优化规则随着版本的发展可能有变化， 查询的执行计划随着数据的变化也可能发生变化，这类情况就需要使用explain 来验证自己的判断。 explain 工具实操执行如下脚本，观察控制台输出1explain select name from test where id = 32; 注意数据表使用如下脚本：12345CREATE TABLE `test` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=41 DEFAULT CHARSET=utf8; table name = test、column1 = id、column2 = name. 执行结果如下所示： 下面详细阐述explain 输出的各项内容： id: 包含一组数字，表示查询中执行 select子句 或操作表的顺序。如果 id 相同，则执行顺序由上到下。 select_type: 表示查询中每个 select 子句的类型(是简单还是复杂)输出结果类似如下：1.simple查询中不包含子查询或者union2.primary查询中若包含任何复杂子查询，最外层查询被标记为primary3.subquery在select 或 where 列表中包含了子查询，则该查询被标记为subquery4.derived在from列表中包含的子查询被标记为derived(衍生)5.union若第二个select出现在union之后，则被标记为derived。6.union result从union表中获取结果的select将被标记为 union result。select_type 只需要了解分类即可，这个信息并不是最有价值的。 type:最有价值信息之一 type表示 MySQL 在表中找到所需行的方式，又称为“访问类型”，常见的类型如下所示：all、index、range、ref、eq_ref、const,system,null以上类型，由左至右，由最差到最好。all: Full Table Scan,MySQL 将遍历全表以找到匹配的行。index:Full Index Scan,index 与 all 区别为index类型只遍历索引树。假设表中有主键字段id,则select id from table_name；type即为Full Index Scan。range:索引扫描范围，对索引的扫描开始于某一点，返回匹配的域或行，常见于between、&lt;、&gt;等的查询。ref:非唯一性索引扫描，将返回匹配某个单独值得所有行。常见于使用非唯一索引或唯一索引的非唯一前缀的查找。eq_ref:唯一性索引扫描，对于每个索引键表中只有一条记录与之匹配。常见于主键或唯一索引扫描。const、system:当MySQL对查询的某部分进行优化，并转化为一个常量时，可使用这些类型进行访问。如果主键置于where列表中，MySQL就能将该查询转换为一个常量，system是const的一个特例，当查询的表只有一行的情况下，即可使用system。null:MySQL 在优化过程中分解语句，执行时甚至不用访问表或索引，举例如下：explain select from (select from t1 where id = 1)d1; possible_keys possible_keys 将指出MySQL能使用哪个索引在表中找到行，查询涉及的字段上若存在索引，则该索引将被列出，但不一定会被查询使用。 key:最有价值信息之二 key 将显示MySQL在查询中实际使用到的索引，若没有使用索引，则显示为null。查询中若使用到了覆盖索引，则该索引仅仅出现在 key 列表中，possible_keys中并不显示。 key_len key_len表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。 ref ref表示上述表的连接匹配条件，即哪些列或常亮被用于查找索引列上的值。 rows:最有价值信息之三 rows 表示MySQL根据表统计信息及索引选用的情况， 估算查找所需记录需要读取的行数。使用到索引一般情况下会使得rows的值降低。 Extra:最有价值信息之四 Extra 包含不适合在其他列中显示但十分重要的额外信息。可能包如下4种信息。 1.Using index该值表示相应的select操作中使用到了覆盖索引，包含满足查询需要的数据的索引称为覆盖索引。2.Using where如果查询未能使用索引，则Using where 的作用只是提醒我们 MySQL 将用where 子句来过滤结果集。3.Using temporary表示MySQL需要使用临时表来存储结果集，常见于order by 与 group by，事实上group by会进行隐式的order by。如果我们在group by 时利用索引分组(其实包含排序的过程)排序，则可以提高性能，因为不会此时查询输出里没有了Using temporary,Using filesort。 4.Using filesortUsing filesort 即文件排序，MySQL 中将无法使用索引完成的排序操作，称为文件排序。 上文篇幅有点长，但都是必须了解的概念。最有价值信息是我们判断sql语句执行是否高效的基准，了解四个最有价值信息是最重要的。 继续演示explain的使用，使用上文的评判标准来看下语句的执行效率：1.主键查询 上述为主键查询的explain信息type ＝ const 效率很高key ＝ primary 实际使用的索引为主键rows ＝ 1 查找的记录数为1extra = null ,没有任何额外信息总体来说，性能是极高。 2.主键范围查询 上述为主键范围查询的explain信息type ＝range 范围查询，效率不是最低key ＝ primary 实际使用的索引为主键rows ＝ 7 查找的记录数为7extra = Using where ,最终使用where 做结果集过滤，未使用到覆盖索引。总体来说，性能是很高。 3.未带索引查询 如上图所示，name 并未做索引。type ＝ALL Full Table Scan 全表查询key ＝NULL 未使用索引rows ＝ 7 10数据库中所有记录extra = Using where ,最终使用where 做结果集过滤，未使用到覆盖索引。总体来说，性能极差。（这也是我司内部deviceId接口出问题的终极原因）。 4.未带索引的分组查询 如上图所示，name 并未做索引。type ＝ALL Full Table Scan 全表查询key ＝NULL 未使用索引rows ＝ 7 10数据库中所有记录extra = Using where ,最终使用where 做结果集过滤，未使用到覆盖索引。并使用到了temporary,filesort 临时表与文件查询。总体来说，性能极差。 5.带索引的分组查询 我们现在为4与3中 name 创建索引，再来看看分析结果创建索引脚本如下alter table test add index idx_name(name);再运行3 和 4中的查询语句结果如下图所示：type ＝ref 非唯一索引扫描，效率不是最低key ＝name 实际使用的索引name索引（注意：idx_name与name都是在name字段上建立的索引）。rows ＝ 1 查找的记录数为1extra = Using index ,最终使用到覆盖索引。总体来说，查询性能是极高的。type ＝range 范围扫描，效率不是最低key ＝name 实际使用的索引name索引（注意：idx_name与name都是在name字段上建立的索引）。rows ＝ 1 查找的记录数为1extra = Using index ,最终使用where 做结果集过滤，使用到覆盖索引。总体来说，查询性能是极高的。 当然上述演示比较简单，也不是非常具备实战色彩，对于explain的使用，我们还应在更多的数据库操作场景中多多使用，这是sql调优的利器。为我们后期的调优减轻了负担，可以说如果在这一步做好了sql脚本的设计，那么后期关于 sql调优 问题会非常少。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 数据库规范--设计篇]]></title>
    <url>%2F2017%2F11%2F14%2FMySQL-design%2F</url>
    <content type="text"><![CDATA[目录 1.设计阶段 2.开发阶段 3.调优阶段(未开发，pt_query_digest、show_slow_log、查询优化等) 1.设计阶段 1.1 数据库表的设计范式(三范式&amp;反范式) 为什么需要范式12优点：编程相对简单，数据量更小，更适合放入内存，更新更快，只需要更新少量的数据，更少的冗余意味着更少的需要group distinct 之类的操作。 第一范式1数据表每一列都是不可分割的基本数据项。举例一个人有多个手机号 第二范式12数据表里的所有数据都要和该数据表里的主键有完全相依赖的关系，不能只依赖部分。举例：用户名&amp;用户技能 是主键，用户居住地 ，那么用户名为主键就可以了。 第三范式1缺点：非键属性都只和候选属性相关，非间属性之间没有关系。举例冠军表中冠军名&amp;冠军生日。 范式的缺陷1查询变得相当复杂，查询时需要更多的连接join ，一些复合索引的列由于范式化的需要被分割到不同的表中，导致索引策略不佳。 反范式12优点：减少了连接，可以更好的利用索引进行筛选和排序，对查询操作可以提高性能。缺点：要在数据一致性与查询之间找到平衡点，符合业务场景的设计才是好的设计 数据库设计准则1设计的数据库应该按照用户可能的访问路径，访问习惯进行设计，而不是严格按照数据范式来设计 1.2 存储引擎的选择 存储引擎分类InnoDB:12345671.灾难恢复性好2.支持4中级别的事务，默认事务的隔离级别是Repeatable Read，事务支持是通过MVCC多版本并发控制来提供的。3.使用行级锁，并发性能高。4.使用此存储引擎的表，数据的物理组织形式是簇表，数据按主键来组织，即主键索引和数据是在一起的，B+树就是这样的5.实现缓冲管理，能缓存索引也能缓存数据。6.支持外键7.支持热备份 MyISAM:12345671.配合锁，实现操作系统下的复制备份，迁移2.使用表记锁并发性差3.支持全文索引4.主机宕机后，表容易损坏，灾难恢复性不佳5.无事务支持6.只缓存索引，数据缓存利用操作系统缓冲区实现的，引发过多系统调用，性能不佳。7.数据紧凑存储，可以获得更快的索引和更快的全表扫描性能。 存储引擎的选择:1设计阶段我们选用InnoDB存储引擎作为数据的存储模式,使用事务、且并发性高，支持外键，支持外键索引。 1.3 字符集选择 12字符编码采用utf-8字符校验采用utf-8-cgi 1.4 命名约定 规范的必要性P187121.年前bug就是因为没有建立索引导致的一系列Bug，所以建立规范，刻不容缓。2.命名没有强制约定，但在一个应用中建议风格统一。 命名约定123456789101.命名有意义，一眼知道这张表是干什么用的2.数据库，表都用小写 数据库形如：backend 数据表形如：client_device_info(客户端设备信息)，不要缩写，字母全小写3.索引命名以idx_为前缀4.命名不要过长（应尽量少于25字符）5.不要使用保留字6.同一字段在不同的表中也应是相同的类型和长度7.同一数据库下有不同的模块，可以考虑对表名用不同的前缀标识8.备份表时加上时间标识 1.5 索引设计 直接参考MySQL 数据库索引使用场景&amp;注意事项 1.6 数据表设计与规划 表设计123456789101112131415161718191.如果没有特殊情况，建议选择InooDB索引2.每个表都应该有主键，可选择自增字段，或整型字段。例外情况，一些应用会频繁的基于某些字段进行检索，设计人员可能认为这些字段／ 字组合更适合做主键，因为更自然、更高效。3.(不做强制要求)尽量将字段设置为NOT NULL。因为NULL值的存储需要额外的空间，且会导致比较运算更为复杂，会使得优化器更难以 优化sql。null 值虽然会导致比较运算更加复杂，但这比因此定义了not null带来应用逻辑异要好。4.使用更短小的列，比如整型列。整型列的执行速度往往更快。5.存储精确浮点数必须使用DECIMAL代替float和double。6.建议使用unsigned类型存储非负值7.建议使用 int unsigned存储ipv48.整型定义中不添加显示长度的值，使用int，而不是int(4)9.尽可能不要使用text,blob类型10.varchar（n） n表示字符数而不是字节数，比如varchar（255）最大可存储255个汉字，需根据实际字符长度选择n的值。11.字符集建议选择utf-812.存储年时使用year类型13.存储日期时使用date类型14.存储时间时，建议使用timestamp类型，因为timestamp使用的是4字节，datetime使用的是8字节。15.不要在数据库中使用varbinary或blob存储图片及文件，mysql 并不适合大量存储这类型文件16.join 操作的字段，在不同表中的类型及命名要一致17.如果更改表结构会影响性能，需要我司后台(有DBA尽可能找DBA)进行联合评审。 数据表规划1234 查看数据表大小的脚本 select sum(data_length+index_length) from information_schema.tables where table_schema = ‘app_backend’ and table_name = ‘client_device_info’;其中data_length是记录大总大小，index_length 为索引的大小，table_schema 是数据库名table_name 是数据表名。 1.7 慎用外键 外键的使用1234561.外键的优点：外键约束使得程序员更不容易将不一致性引入数据库，而且设计合适外键有助于以文档方式记录表间关系。2.外键的缺点但这些优点是以服务器为执行必要的检查而花费额外的开销为代价的。服务器进行额外的检查会影响性能。其次外键对并发性能的影响很大，因每次修改数据都需要去另外一个表检查数据，需要获取额外的锁（以确保事务完成之前，父表的记录不会被删除）高并发环境下出现性能问题，更好的办法是在应用层实现外键约束。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java NIO(一)－I/O模型： 阻塞、非阻塞、I/O复用、同步、异步]]></title>
    <url>%2F2017%2F11%2F14%2Fjava_nio%2F</url>
    <content type="text"><![CDATA[目的 为后期学习 Netty框架打好理论基础，并且在分布式RPC 服务中对客户端与服务端之间服务的调用，底层数据通讯可以使用Netty 进行封装。 记录结构 Java NIO(一)–I/O模型： 阻塞、非阻塞、I/O复用、同步、异步地址：http://www.jianshu.com/writer#/notebooks/5970279/notes/7531041/preview Java NIO(二)–Channel、Buffer、Selector地址：待定 Java NIO(三)–多路复用之TCP传输中的NIO应用地址：待定 今天记录I/O模型中的阻塞、非阻塞、I/O复用、同步、异步。##混沌的概念##对于上述四种概念，常常使我陷入混沌，我经常这样想同步不就是阻塞的么？异步不就是非阻塞的么？我也会去看下别人写的博客以验证我的想法是正确的，事实上，大多博客也这样举例子：同步类似于你叫某人吃饭，某人不应答你，你就一直等着他，这期间你什么事情都不能做，也就是说你在等待某人去吃饭这个时刻内一直都是阻塞的。针对于上述的举例，我一直深信不疑，一句话，没毛病。但直到我看到UNIX 网络编程之后，才发现理解有偏差，起码我之前的理解是将I/O操作中的概念结合起来记忆。即：同步==阻塞 异步==非阻塞。 但其实，以上的记忆有点以偏概全，或者说根本没有清晰的认识。 话不多说，开始记录。 1. 明确I/O考察的对象和流程 1.1 参考Unix网络编程，一个输入操作通常包括两个不同的阶段： 等待数据准备好； 从内核向进程复制数据。 1.2 对于一个套接字的输入操作: 通常涉及等待数据从网络到达，当所等待分组到达时，被复制到内核的某个缓冲区; 把数据从内核缓冲区复制到应用进程缓冲区。 注意： 理解上述两个不同阶段对于后续理解I/O模型尤其是非阻塞I/O与同步I/O关系十分必要。 2. I/O模型 2.1 阻塞式I/O模型阻塞式I/O是最流行的I/O，也是所有套接字默认的I/O。Java BIO中对socket 网络数据通信的封装 就采用的是这种方式。当然效率也是低下的。 阻塞式I/O是最流行的I/O，也是所有套接字默认的I/O。 （注：所有图片来源 Unix网络编程卷1，第三版） 如图所示，进程调用recvfrom系统调用，直到网络数据报到达且被复制到应用进程缓冲区中或发生错误才返回。 注意：也就是说，进程从调用recvfrom开始到返回的整个时段都是阻塞的（上述1.1两个阶段都是阻塞），recvfrom成功返回后，应用进程才开始处理数据报。 上述的注意读三遍 2.2 非阻塞I/O模型直接上图: 如图所示，不同于阻塞式I/O，非阻塞I/O在第一阶段数据没有准备好的时候，不阻塞，而是直接返回一个错误（EWOULDBLOCK）。 所以一般采用轮询（polling）的方式，应用进程持续轮询内核，查看数据是否准备好。当数据准备好时，被复制到应用进程缓冲区（第二阶段）。 注意：值得注意的一点是，当第一阶段数据准备完成后，进入第二阶段，内核向内存的复制。这一阶段仍然是阻塞的，这对于后续理解非阻塞与同步的关系十分重要。 上述注意项读三遍。 2.3 I/O多路复用模型I/O复用最常见的就是select和epoll，其阻塞发生在上述两个系统调用之一，而不是真正的I/O系统调用上。 Java NIO 对TCP 网络通信的封装内部采用的就是这种原理。 当用户进程调用了select，那么整个进程会被阻塞与select。内核会“监视”所有select负责的套接字，当任何一个套接字中的数据准备好了，select就会返回。(进程阻塞) 这时候进入第二阶段，完成内核向内存的数据复制。（进程阻塞） 注意:I/O复用的优势在于同时等待多个描述符就绪，单就一个描述符可言，其没有优势，反而还会因为多一次select系统调用存在劣势。 上述注意项读三遍。 2.4 异步I/O模型异步I/O的工作机制是告知内核启动某个操作，并让内核在整个操作（包括第二阶段数据从内核向内存的复制）完成后告知我们。 如下图所示： 注意：异步I/O要通过调用特殊API实现（如POSIX的aio_read），可以看出，其在两个阶段都是没有对于用户进程的阻塞的，依靠信号通知进程整个过程完成。 上述注意读三遍 2.5 同步、异步与阻塞、非阻塞、I/O复用的关系在了解了阻塞式I/O、非阻塞式I/O、I/O多路复用、异步I/O后我们看下这几个模式的I/O模型与同步异步模型有什么关系。注意：重头戏，接下来就是彻底领悟这几个概念之间关系，让你不再混沌，请保持接受状态，保持信心看下去。 首先先来再明确一下同步、异步I/O之间的区别。书中所述，POSIX把两种术语定义如下：同步I/O：导致请求进程阻塞，直到I/O操作完成；(两个阶段(等待网络数据到达内核空间缓存区域，以及将内核空间缓存区域中的数据复制到用户进程缓存中)中只要有一个阶段阻塞，那整个I/O操作就就是同步)异步I/O：不导致请求进程阻塞。 （两个阶段都不阻塞，那么就是异步I/O） 注意：所以说，阻塞式I/O， 非阻塞I/O， I/O复用由于都导致了请求进程阻塞，所以均属于同步I/O。（值得注意的是非阻塞I/O，正如之前提示要注意的，其在第二阶段内核向内存复制数据是会导致用户进程的阻塞，所以也属于同步I/O 上述注意读三遍 3. 总结如下图所示：（暂时忽略信号驱动I/O） 可以看出阻塞式、非阻塞式、与I/O复用，其不同之处在于第一阶段，第二阶段的处理方式相同（均阻塞与recvfrom调用），这也是刚才说到的将他们归于同步I/O的原因。 注意：异步I/O不存在请求进程阻塞的情况。同时注意前三种I/O模型在第一阶段的处理方式（阻塞，返回+轮询，阻塞于select等），区分这三种I/O模型。 上述注意读三遍 完。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>高并发</tag>
        <tag>I/O模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellj Idea中查看类继承面板]]></title>
    <url>%2F2017%2F11%2F14%2FIntelljIdea-see-implements%2F</url>
    <content type="text"><![CDATA[前言：在分析 Spring 源码时，因框架类图之间的关系错综复杂，所以需要借助类继承面板来查看类之间的关系。 1.查看类继承面板 1.查看类继承面板 Mac快捷键 使用control+H调出类继承面板： 如下图所示：初始显示的面板不是非常友好，而且并不是我们通常所熟悉的显示结构，那么点击如下按钮： 状态变为： 并且初始面板是折叠的，如果需要时展开状态，那么点击如下按钮： 最终的显示状态是： 这种继承结构图跟eclipse显示的结构图是相同的。但是界面更佳又好，单击其中的某个类，就可以看到具体类的具体代码。 windows快捷键使用ctrl+H调出类继承面板：]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>编程实操</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij Idea--Debug使用（Mac）]]></title>
    <url>%2F2017%2F11%2F14%2FIntellijIdea-Mac-use-debug%2F</url>
    <content type="text"><![CDATA[前言：本文的核心是记录debug的使用，与具体的操作系统无关。 1.什么是Debug Debug是程序的一种运行模式。用来发掘程序的走向，以及程序在运行过程中参数的变化。 2.Debug的作用 debug用来追溯代码的运行流程，通常在程序运行跟预期结果不符合的时（程序运行时出现异常），那么启动debug模式可以分析定位异常发生的位置，帮助程序员更好的fix bug 3.Debug的使用 主要讲解intellj中debug的使用 ，此篇不会讲解debug时可用的快捷键。配合idea中图形界面来进行讲解。 3.1.程序打上断点首先为程序打上断点，我采用的是spring demo，因为这样可以演示给第三方spring jar包如何打上断点。主程序上断点如下图所示：第三方jar包反编译源代码断点如下图所示：3.2单步调试3.2.1 Step Over:点击红色箭头指向的按钮，程序向下执行一行。但有一种情况需要注意，如果在一个顺序执行的程序文件中打上断点，而第一行被打上断点的代码调用了其他方法，而且这个被调用的方法上也有断点，那么这样单步执行的顺序是，先祝程序文件中第一行被打断点的程序运行，接下来是被调用方法中打了断点的那一行代码，最后接着顺序运行此主程序文件中其它被打了断点的代码。3.2.2 Step Into:点击红色箭头指向的按钮，程序向下执行一行。如果该行有自定义方法，则运行进入自定义方法,如果有第三方类库方法，则在idea 中可以进入第三方代码中。具体步骤如下：在程序第十三行设置断点，然后点击上图中红色箭头指向的按钮，程序运行至第三方类库当中代码，代码如下图所示：3.2.3 step out如果在调试的时候你进入了一个方法，并觉得该方法没有问题，你就可以使用stepout跳出该方法，返回到该方法被调用处的下一行语句。值得注意的是，该方法已执行完毕。3.2.4 Drop frame点击该按钮后，你将返回到当前方法的调用处（如上图，程序会回到main()中）重新执行，并且所有上下文变量的值也回到那个时候。只要调用链中还有上级方法，可以跳到其中的任何一个方法。3.2.5 纯断点运行所谓纯断点运行表示：程序只在断点处停留。发现上述两个按钮都可以实现效果3.2.6 查看断点按如下按钮可以查看程序中所有的断点：效果图如下所示：你可以从中删除不想要的断点。重新debug3.2.7 变量值查看idea中变量值的查看非常简单如下图：两个红色箭头所指的地方都可以查看debug过程中变量值的变化情况。]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>编程实操</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Intellij Idea＋Gradle 搭建Java 本地开发环境]]></title>
    <url>%2F2017%2F11%2F14%2FIntellijIdea-JavaWEB%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Java 本地开发环境搭建 项目搭建采用技术栈为：Spring+Spring MVC+Hibernate+Jsp+Gradle＋tomcat+mysql5.6 搭建环境文档目录结构说明： 使用Intellj Idea 搭建项目过程详解 项目各配置文件讲解及部署 各层包功能讲解&amp;项目搭建完毕最终效果演示图 项目中重要代码讲解 webapp文件夹下分层详解 配置tomcat 运行环境 1. 使用Intellj Idea 搭建项目过程详解 1.1 打开Intellj Idea 1.2 操纵 Intellj Idea 工具栏 新建项目 需要说明的是，最初创建的项目视图是不完整的，包括webapp文件夹下没有web.xml，以及src包下缺少Java文件夹(放置java源代码文件)，Resources文件夹（放置项目配置文件）。我们继续做以下操作，使得项目的结构符合web 应用项目的层级标准。 出现如下视图： 接下来：单击main文件夹按照如下操作： 点击ok，再按照上图操作操作一遍，输入文件名为resources最终的结构图如下图所示： 2. 项目各配置文件讲解及部署 完成了项目的初始化结构创建，接下来我们需要来创建配置文件。首先是resources文件夹下的配置文件2.1 resources下资源文件截图:(最终配置的结果)2.2 data-access-applicationContext.xml主要管理数据库访问组件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd "&gt; &lt;!-- 配置自动扫描的包 --&gt; &lt;context:component-scan base-package="com.fxmms" use-default-filters="false"&gt; &lt;context:include-filter type="regex" expression="com.fxmms.*.*.dao.*"/&gt; &lt;context:include-filter type="regex" expression="com.fxmms.*.dao.*"/&gt; &lt;/context:component-scan&gt; &lt;!-- 配置数据源 --&gt; &lt;context:property-placeholder location="classpath:db.properties"/&gt; &lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driverClass&#125;"/&gt; &lt;property name="url" value="$&#123;jdbc.jdbcUrl&#125;"/&gt; &lt;property name="username" value="$&#123;jdbc.user&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt; &lt;/bean&gt; &lt;!--配置hibernate SessionFactory--&gt; &lt;bean id="sessionFactory" class="org.springframework.orm.hibernate4.LocalSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;property name="hibernateProperties"&gt; &lt;props&gt; &lt;prop key="hibernate.dialect"&gt;$&#123;dataSource.hibernate.dialect&#125;&lt;/prop&gt; &lt;prop key="hibernate.show_sql"&gt;$&#123;dataSource.hibernate.show_sql&#125;&lt;/prop&gt; &lt;prop key="hibernate.format_sql"&gt;true&lt;/prop&gt; &lt;!--负责自动创建数据表，基本上不能打开注释，否则所有的数据库中表信息都会被删除，重新创建--&gt; &lt;!-- &lt;prop key="hibernate.hbm2ddl.auto"&gt;create&lt;/prop&gt; --&gt; &lt;/props&gt; &lt;/property&gt; &lt;!-- &lt;property name="hibernate.jdbc.batch_size" value="50"&gt;&lt;/property&gt; --&gt; &lt;property name="packagesToScan"&gt; &lt;list&gt; &lt;value&gt;com.fxmms.*.*.domain&lt;/value&gt; &lt;value&gt;com.fxmms.*.domain&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--jdbcTemplate start --&gt; &lt;bean id="jdbcTemplate" class="org.springframework.jdbc.core.JdbcTemplate"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--Spring JDBC 中操作 LOB 数据 --&gt; &lt;bean id="lobHandler" class="org.springframework.jdbc.support.lob.DefaultLobHandler" lazy-init="true"&gt;&lt;/bean&gt; &lt;!-- 配置JPA部分 --&gt; &lt;!-- 配置JPA的EntityManagerFactory --&gt; &lt;!-- &lt;bean id="entityManagerFactory" class="org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;property name="jpaVendorAdapter"&gt; &lt;bean class="org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter"&gt;&lt;/bean&gt; &lt;/property&gt; &lt;property name="packagesToScan" value="com.fxmms"&gt;&lt;/property&gt; &lt;property name="jpaProperties"&gt; &lt;props&gt; &lt;prop key="hibernate.ejb.naming_strategy"&gt;org.hibernate.cfg.ImprovedNamingStrategy&lt;/prop&gt; &lt;prop key="hibernate.hbm2ddl.auto"&gt;update&lt;/prop&gt; &lt;prop key="hibernate.show_sql"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.format_sql"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.dialect"&gt;org.hibernate.dialect.MySQL5InnoDBDialect&lt;/prop&gt; &lt;prop key="hibernate.cache.use_second_level_cache"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.cache.region.factory_class"&gt;org.hibernate.cache.ehcache.EhCacheRegionFactory &lt;/prop&gt; &lt;prop key="hibernate.cache.use_query_cache"&gt;true&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;!–使用二級緩存–&gt; &lt;property name="sharedCacheMode" value="ENABLE_SELECTIVE"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!– 配置事务 –&gt; &lt;bean id="transactionManager" class="org.springframework.orm.jpa.JpaTransactionManager"&gt; &lt;property name="entityManagerFactory" ref="entityManagerFactory"&gt;&lt;/property&gt; &lt;/bean&gt;--&gt; &lt;!-- &lt;!– 配置SpringData部分 –&gt; &lt;jpa:repositories base-package="com.fxmms" entity-manager-factory-ref="entityManagerFactory"&gt; &lt;/jpa:repositories&gt;--&gt;&lt;/beans&gt; 2.3 service-applicationContext.xml主要管理业务逻辑组件，包括对数据库访问的事务控制，以及定时任务。123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:task="http://www.springframework.org/schema/task" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd"&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;!--设置定时任务--&gt; &lt;task:annotation-driven/&gt; &lt;context:component-scan base-package="com.fxmms.www" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Service"/&gt; &lt;/context:component-scan&gt; &lt;!-- enable the configuration of transactional behavior based on annotations --&gt; &lt;tx:annotation-driven transaction-manager="txManager"/&gt; &lt;bean id="txManager" class="org.springframework.orm.hibernate4.HibernateTransactionManager"&gt; &lt;property name="sessionFactory" ref="sessionFactory"/&gt; &lt;/bean&gt;&lt;/beans&gt; 2.4 default-servlet.xml设置springmvc-applicationContext.xml,前端控制器将请求转发到相应的controller层中的处理方法上。1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt; &lt;!----&gt; &lt;mvc:annotation-driven&gt; &lt;!--json解析--&gt; &lt;mvc:message-converters&gt; &lt;bean class="org.springframework.http.converter.StringHttpMessageConverter"/&gt; &lt;bean class="org.springframework.http.converter.json.MappingJackson2HttpMessageConverter"/&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; &lt;context:component-scan base-package="com.fxmms.www.controller"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;/context:component-scan&gt; &lt;!--因为web.xml中defaultDispatcherServlet对所有请求进行了拦截，所以对一些.css .jpg .html .jsp也进行了拦截，所以此配置项 保证对对静态资源不拦截--&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!--视图解析器--&gt; &lt;bean id="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/views/"/&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt; &lt;!--配置文件上上传--&gt; &lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;property name="defaultEncoding" value="utf-8"/&gt; &lt;property name="maxUploadSize" value="10485760000"/&gt; &lt;property name="maxInMemorySize" value="40960"/&gt; &lt;/bean&gt;&lt;/beans&gt; 2.5 spring-security.xml设置spring－security 权限控制配置文件，项目中权限的控制统一在此配置文件中配置，包括从数据库中获取用户的相关信息，以及配置相应pattern的请求过滤规则。1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:sec="http://www.springframework.org/schema/security" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/security http://www.springframework.org/schema/security/spring-security-3.2.xsd"&gt; &lt;!-- &lt;sec:http pattern="/**/*.jpg" security="none"&gt;&lt;/sec:http&gt; &lt;sec:http pattern="/**/*.jpeg" security="none"&gt;&lt;/sec:http&gt; &lt;sec:http pattern="/**/*.gif" security="none"&gt;&lt;/sec:http&gt; &lt;sec:http pattern="/**/*.png" security="none"&gt;&lt;/sec:http&gt;s &lt;sec:http pattern="/getCode" security="none" /&gt;&lt;!– 不过滤验证码 –&gt; &lt;sec:http pattern="/test/**" security="none"&gt;&lt;/sec:http&gt;&lt;!– 不过滤测试内容 –&gt;--&gt; &lt;!--spring security 权限管理配置文件--&gt; &lt;context:component-scan base-package="com.fxmms.common.security"&gt; &lt;/context:component-scan&gt; &lt;context:property-placeholder location="classpath:db.properties"&gt;&lt;/context:property-placeholder&gt; &lt;!--权限控制--&gt; &lt;sec:http auto-config="true" use-expressions="true"&gt; &lt;sec:intercept-url pattern="/superadmin/**" access="hasRole('superadmin')"/&gt; &lt;sec:intercept-url pattern="/admin/**" access="hasRole('admin')"/&gt; &lt;sec:intercept-url pattern="/customer/**" access="hasRole('customer')"/&gt; &lt;!--自定义登陆页面,权限验证失败页面，登录成功页面--&gt; &lt;sec:form-login login-page="/login.jsp" authentication-failure-url="/login.jsp" login-processing-url="/j_spring_security_check" authentication-success-handler-ref="loginSuccessHandler"/&gt; &lt;!--用户权限不一致出现的权限不可得情况，默认情况下跳转到403页面--&gt; &lt;sec:access-denied-handler ref="accessDeniedServletHandler" /&gt; &lt;sec:logout logout-success-url="/login.jsp" /&gt; &lt;/sec:http&gt; &lt;sec:authentication-manager&gt; &lt;sec:authentication-provider&gt; &lt;!--配置从数据库查询用户权限 and isDelete = 0 and enable = 1--&gt; &lt;sec:jdbc-user-service data-source-ref="dataSource" users-by-username-query="select userName,password,enable from mms_admin where userName=? and isDelete = 0 and enable = 1" authorities-by-username-query="select userName,role from mms_admin where username=?" &gt;&lt;/sec:jdbc-user-service&gt; &lt;/sec:authentication-provider&gt; &lt;/sec:authentication-manager&gt;&lt;/beans&gt; 2.6 db.properties数据库访问配置文件12345678910111213jdbc.user=rootjdbc.password=feixun*123jdbc.driverClass=com.mysql.jdbc.Driver#jdbc.jdbcUrl=jdbc:mysql://localhost/fxmms?useUnicode=true&amp;characterEncoding=UTF-8jdbc.jdbcUrl=jdbc:mysql://222.73.156.132:13306/fxmms?useUnicode=true&amp;characterEncoding=UTF-8jdbc.initPoolSize=5jdbc.maxPoolSize=20dataSource.hibernate.dialect=org.hibernate.dialect.MySQL5Dialect######################### local #########################dataSource.hibernate.show_sql=true 2.7 log4j.properties配置项目日志文件，日志输出模式为Console12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152############################################################################ Properties file for the log4j logger system## Note: During the uPortal build, the file at /properties/Logger.properties is copied# to the log4j standard location /WEB-INF/classes/log4j.properties . This means that editing the file# at /properties/Logger.properties in a deployed uPortal will have no effect.## Please read the instructions for the Log4J logging system at# http://jakarta.apache.org/log4j/ if you want to modify this.############################################################################ You should probably replace the word &quot;debug&quot; with &quot;info&quot; in the# following line after everything is running. This will turn off# the tons of debug messages, and leave only INFO, WARN, ERROR, etc.#log4j.rootLogger = info,stdout,D,E#配置stdoutlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target=System.outlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH\:mm\:ss,SSS&#125; [%p]-[%l] %m%n#配置D 保存info debug级别的系统日志信息log4j.appender.D = org.apache.log4j.DailyRollingFileAppender#/Users/mark/mms/log.log 指定info debug级别日志信息存储位置log4j.appender.D.File = /Users/mark/mms/log.loglog4j.appender.D.Append = truelog4j.appender.D.Threshold = INFO,DEBUGlog4j.appender.D.layout = org.apache.log4j.PatternLayoutlog4j.appender.D.layout.ConversionPattern = %d&#123;yyyy-MM-dd HH\:mm\:ss,SSS&#125; [%p]-[%l] %m%n#配置E 保存系统异常日志 log4j.appender.E = org.apache.log4j.DailyRollingFileAppender#/Users/mark/mms/error.log 指定info debug级别日志信息存储位置log4j.appender.E.File = /Users/mark/mms/error.loglog4j.appender.E.Append = truelog4j.appender.E.Threshold = ERRORlog4j.appender.E.layout = org.apache.log4j.PatternLayoutlog4j.appender.E.layout.ConversionPattern = %d&#123;yyyy-MM-dd HH\:mm\:ss,SSS&#125; [%p]-[%l] %m%n#log4j.logger.org.hibernate=INFO### Log all JDBC parameters#log4j.logger.org.hibernate.type=ALL##Hibernate begin 打印每次数据访问产生的sql语句至log.log 文件当中##log4j.logger.org.hibernate=info#配置SQL打印与输出log4j.logger.org.hibernate.SQL=DEBGlog4j.logger.org.hibernate.HQL=DEGUG#log4j.logger.org.hibernate.type=ALL 2.8 web.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1"&gt; &lt;!--配置需要加载的spring配置文件，这些文件中的配置的类都是被&lt;context:component-scan&gt;扫描到的，比如@Repository @Component @Service @Controller等--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:data-access-applicationContext.xml;classpath:spring-security.xml;classpath:service-applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!--配置日志监听 ，如果配置文件报红，没有关系可以正常运行，这个与idea的验证规则有关--&gt; &lt;context-param&gt; &lt;param-name&gt;log4jConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:log4j.properties&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.Log4jConfigListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!--配置权限过滤器，注意必须配置在springmvc 之前，因为对用户访问资源的权限判断与控制是在访问特定url之前发生的--&gt; &lt;filter&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 配置字符编码过滤器 必须配置在所有过滤器的最前面 --&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--超级管理员 --&gt; &lt;!-- &lt;filter&gt; &lt;filter-name&gt;superAdminFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.fxmms.filter.SuperAdminFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;superAdminFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/fxmms/superadmin/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;adminFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.fxmms.filter.AdminFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;adminFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/fxmms/admin/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;customerFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.fxmms.filter.CustomerFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;customerFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/fxmms/customer/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;servlet&gt; &lt;servlet-name&gt;LoginServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.fxmms.servlet.LoginServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet&gt; &lt;servlet-name&gt;InvalidateServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.fxmms.servlet.InvalidateServlet&lt;/servlet-class&gt; &lt;/servlet&gt;- &lt;servlet-mapping&gt; &lt;servlet-name&gt;LoginServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/loginServlet&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;InvalidateServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/invalidateServlet&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;--&gt; &lt;!-- 配置看可以把POST请求转为PUT，DELETE请求的Filter --&gt; &lt;filter&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--配置中央控制器，对所有请求进行拦截并做请求路径，与处理请求桩模块之间的映射--&gt; &lt;servlet&gt; &lt;servlet-name&gt;defaultDispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation &lt;/param-name&gt; &lt;param-value&gt;classpath:default-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;!--这里是拦截所有--&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;defaultDispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 2.9 build.gradle项目构建脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758group &apos;com.fxmms&apos;version &apos;1.0-SNAPSHOT&apos;apply plugin: &apos;java&apos;apply plugin: &apos;idea&apos;apply plugin: &apos;war&apos;sourceCompatibility = 1.8repositories &#123; maven &#123; url &quot;http://maven.aliyun.com/nexus/content/groups/public/&quot; &#125; mavenLocal() jcenter() maven &#123; url &quot;http://repo.maven.apache.org/maven2/&quot;&#125; maven &#123; url &apos;https://repo.spring.io/libs-milestone&apos;&#125; mavenCentral()&#125;dependencies &#123; testCompile group: &apos;junit&apos;, name: &apos;junit&apos;, version: &apos;4.12&apos; // servlet-api compile group: &apos;javax.servlet&apos;, name: &apos;servlet-api&apos;, version: &apos;2.5&apos; //spring相关 compile group: &apos;org.springframework&apos;, name: &apos;spring-webmvc&apos;, version: &apos;4.3.3.RELEASE&apos; compile group: &apos;org.springframework&apos;, name: &apos;spring-orm&apos;, version: &apos;4.3.3.RELEASE&apos; compile group: &apos;org.springframework&apos;, name: &apos;spring-aspects&apos;, version: &apos;4.3.3.RELEASE&apos; compile group: &apos;org.springframework.security&apos;, name: &apos;spring-security-config&apos;, version: &apos;3.2.0.RELEASE&apos; compile group: &apos;org.springframework.security&apos;, name: &apos;spring-security-taglibs&apos;, version: &apos;3.2.0.RELEASE&apos; compile &apos;org.springframework.security:spring-security-web:3.2.0.RELEASE&apos; //hibernate相关 compile &apos;org.hibernate:hibernate-core:4.3.6.Final&apos; //c3p0连接池 compile group: &apos;org.hibernate&apos;, name: &apos;hibernate-c3p0&apos;, version: &apos;4.3.6.Final&apos; //ehcahe二级缓存 compile group: &apos;org.hibernate&apos;, name: &apos;hibernate-ehcache&apos;, version: &apos;4.3.6.Final&apos; //mysql compile group: &apos;mysql&apos;, name: &apos;mysql-connector-java&apos;, version: &apos;5.1.39&apos; //springData compile group: &apos;org.springframework.data&apos;, name: &apos;spring-data-jpa&apos;, version: &apos;1.10.3.RELEASE&apos; // https://mvnrepository.com/artifact/log4j/log4j日志 compile group: &apos;log4j&apos;, name: &apos;log4j&apos;, version: &apos;1.2.17&apos; //json解析相关 compile group: &apos;com.fasterxml.jackson.core&apos;, name: &apos;jackson-databind&apos;, version: &apos;2.5.4&apos; compile group: &apos;com.fasterxml.jackson.core&apos;, name: &apos;jackson-core&apos;, version: &apos;2.5.4&apos; //迅雷接口有关jar 包 compile &apos;org.apache.httpcomponents:httpclient:4.4&apos; compile &apos;org.json:json:20141113&apos; compile group: &apos;org.apache.clerezza.ext&apos;, name: &apos;org.json.simple&apos;, version: &apos;0.4&apos; //https://mvnrepository.com/artifact/org.apache.commons/commons-io 读取文件相关 compile group: &apos;org.apache.commons&apos;, name: &apos;commons-io&apos;, version: &apos;1.3.2&apos; // https://mvnrepository.com/artifact/org.apache.poi/poi 文件读取相关 apache-poi compile group: &apos;org.apache.poi&apos;, name: &apos;poi&apos;, version: &apos;3.9&apos; // https://mvnrepository.com/artifact/org.apache.poi/poi-ooxml 解决execl 版本差异 compile group: &apos;org.apache.poi&apos;, name: &apos;poi-ooxml&apos;, version: &apos;3.9&apos; // https://mvnrepository.com/artifact/commons-io/commons-io 文件上传 compile group: &apos;commons-io&apos;, name: &apos;commons-io&apos;, version: &apos;1.3.1&apos; // https://mvnrepository.com/artifact/commons-fileupload/commons-fileupload compile group: &apos;commons-fileupload&apos;, name: &apos;commons-fileupload&apos;, version: &apos;1.2.2&apos;&#125; 3. 各层包功能讲解&amp;项目搭建完毕最终效果演示图 3.1 项目中各层包功能讲解项目中Java源代码层级结构如下图所示： 对于www包中的各分层，我们对照上图重点说明： controller:用于路由各种HTTP访问，其中可以实现对前台页面参数的对象化绑定，这个功能的实现是依赖于spring mvc中的参数绑定功能，以及返回向前端页面返回数据。也可以实现基于Restful 风格API的编写。dao：用于实现对数据库的操作，包中的代码继承并实现自common中的dao 层代码，采用的是类的适配器模式实现的，这里的代码值得细细品味，可以说是整个项目的灵魂所在之处，稍后说明。domain:项目中的所有实体类都存在于这个包中，其中的每个具体实体类与数据库表相对应。dto:实现了序列化的数据传输层对象，可用于接收前台参数，前台参数被封装成dto 对象传输至后台。同时也负责对从数据库中查询数据的封装。qo:模糊查询对象所在的包，用于封装QBC动态查询参数。rowmapper：用于映射jdbcTemplate查询数据库返回对象的数据集，并将数据集依照以此对象为集合的实例进行封装。schedulejob：定时任务类所在的包，在此包中的类上都要加上@Service注解，因为定时任务注解配置在service-applicationContext.xml中，包扫描组件的规则是只扫描类上有@Service注解的组件类。service:业务逻辑层，所有的业务逻辑组件Bean都放置在这个保重，其中的类中的业务逻辑方法调用了dao实现类中的方法，并且每个有关于数据库操作的方法上都加上了@Transaction注解，用于实现对数据库操作的事务管理。@Transaction是Spring Framework对AOP 的另一种区别于拦截器的自定义注解实现。 4.项目中重要代码讲解 主要讲解一下Dao层中代码对适配器设计模式的应用：4.1 首先看下commom层中 BaseDao.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153package com.fxmms.common.dao;import com.fxmms.common.ro.Dto;import com.fxmms.common.ro.DtoResultWithPageInfo;import com.fxmms.common.ro.PageQo;import org.hibernate.Criteria;import org.springframework.stereotype.Repository;import java.io.Serializable;import java.util.List;import java.util.Map;/** * * @param &lt;T&gt; * @usage 数据库公共操作接口 */@Repositorypublic interface BaseDao&lt;T&gt; &#123; /** * * * @param id * @usage 根据id获取数据库中唯一纪录，封装成java对象并返回 * @return T */ public T getById(Serializable id); /** * * * @param id * @usage 根据id懒加载数据库中唯一纪录，封装成java对象并返回 * @return T */ public T load(Serializable id); /** * * * @param columnName * * @param value * * @usage 根据列名，以及对应的值获取数据库中惟一纪录，封装成Java对象并返回 * * @return */ public T getByUniqueKey(String columnName, Object value); /** * * * @param nameValuePairs * * @return T */ public T getUniqueResult(Map&lt;String, Object&gt; nameValuePairs); /** * * * @param columnName * * @param value * * @param sort * * @param order * asc/desc * @return List&lt;T&gt; */ public List&lt;T&gt; getListByColumn(String columnName, Object value, String sort, String order); public List&lt;T&gt; getListByColumn(String columnName, Object value); /** * ͨ * * @param nameValuePairs * * @param sort * * @param order * asc/desc * @return List&lt;T&gt; */ public List&lt;T&gt; getListByColumns(Map&lt;String, Object&gt; nameValuePairs, String sort, String order); public List&lt;T&gt; getListByColumns(Map&lt;String, Object&gt; nameValuePairs); /** * * * @return List&lt;T&gt; */ public List&lt;T&gt; getAll(); /** * * * @param t * @return Serializable id */ public Serializable save(T t); /** * * * @param t */ public void update(T t); /** * * * @param t */ public void delete(T t); /** * QBC * @return */ public Criteria createCriteria(); /** * @param &lt;E&gt; * @param &lt;D&gt; * @param criteria * @param pageNo * @param pageSize * @param dtoClazz * @return */ public &lt;E, D extends Dto&gt; DtoResultWithPageInfo&lt;D&gt; queryPageListByCriteria( Criteria criteria, int pageNo, int pageSize, Class&lt;D&gt; dtoClazz); /** * @param &lt;E&gt; * @param &lt;D&gt; * @param criteria * @param qo * @param class1 * @return */ public &lt;E, D extends Dto&gt; DtoResultWithPageInfo&lt;D&gt; queryPageListByCriteriaWithQo(PageQo qo, Class&lt;D&gt; dtoClazz);&#125; 其中定义了一些对数据库的抽象公共操作方法，代码中有注释，可以对照理解。 4.2 看下HibernateTemplateDao.java对BaseDao.java的抽象实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473package com.fxmms.common.dao.hib;import com.fxmms.common.dao.BaseDao;import com.fxmms.common.ro.Dto;import com.fxmms.common.ro.DtoResultWithPageInfo;import com.fxmms.common.ro.PageInfo;import com.fxmms.common.ro.PageQo;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.hibernate.Criteria;import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.criterion.Order;import org.hibernate.criterion.Projections;import org.hibernate.criterion.Restrictions;import org.springframework.beans.BeanUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.stereotype.Repository;import org.springframework.util.StringUtils;import java.io.Serializable;import java.util.ArrayList;import java.util.List;import java.util.Map;/** * * @param &lt;T&gt; * @usage 应用数据访问的灵魂，抽象出各种模型类进行数据库访问的公共操作。 * 主要使用到QBC动态查询。主要思想是利用反射。 */@Repositorypublic abstract class HibernateTemplateDao&lt;T&gt; implements BaseDao&lt;T&gt; &#123; protected static final Log log = LogFactory .getLog(HibernateTemplateDao.class); //通过反射，可以实现对不同类对应的数据表的操作 protected abstract Class&lt;?&gt; getEntityClass(); protected SessionFactory sessionFactory; @Autowired @Qualifier("sessionFactory") public void setSessionFactory(SessionFactory sessionFactory) &#123; this.sessionFactory = sessionFactory; &#125; public Session getSession() &#123; return sessionFactory.getCurrentSession(); &#125; public Session openNewSession() &#123; return sessionFactory.openSession(); &#125; @Override @SuppressWarnings("unchecked") public T getById(Serializable id) &#123; return (T) getSession().get(getEntityClass(), id); &#125; @Override @SuppressWarnings("unchecked") public T getByUniqueKey(String columnName, Object value) &#123; return (T) getSession().createCriteria(getEntityClass()) .add(Restrictions.eq(columnName, value)).uniqueResult(); &#125; @Override @SuppressWarnings("unchecked") public List&lt;T&gt; getListByColumn(String columnName, Object value,String sort,String order) &#123; Criteria criteria = getSession().createCriteria(getEntityClass()); criteria.add(Restrictions.eq(columnName, value)); if(StringUtils.hasText(sort) &amp;&amp; StringUtils.hasText(order))&#123; if("asc".equals(order))&#123; criteria.addOrder(Order.asc(sort)); &#125;else if("desc".equals(order))&#123; criteria.addOrder(Order.desc(sort)); &#125; &#125; List&lt;T&gt; list = criteria.list(); return list; &#125; @Override @SuppressWarnings("unchecked") public List&lt;T&gt; getListByColumn(String columnName, Object value) &#123; Criteria criteria = getSession().createCriteria(getEntityClass()); criteria.add(Restrictions.eq(columnName, value)); List&lt;T&gt; list = criteria.list(); return list; &#125; @Override @SuppressWarnings("unchecked") public List&lt;T&gt; getListByColumns(Map&lt;String, Object&gt; nameValuePairs,String sort,String order)&#123; Criteria criteria = getSession().createCriteria(getEntityClass()); for (Map.Entry&lt;String, Object&gt; entry : nameValuePairs.entrySet()) &#123; criteria.add(Restrictions.eq(entry.getKey(), entry.getValue())); &#125; if(StringUtils.hasText(sort) &amp;&amp; StringUtils.hasText(order))&#123; if("asc".equals(order))&#123; criteria.addOrder(Order.asc(sort)); &#125;else if("desc".equals(order))&#123; criteria.addOrder(Order.desc(sort)); &#125; &#125; List&lt;T&gt; list = criteria.list(); return list; &#125; @Override @SuppressWarnings("unchecked") public List&lt;T&gt; getListByColumns(Map&lt;String, Object&gt; nameValuePairs)&#123; Criteria criteria = getSession().createCriteria(getEntityClass()); for (Map.Entry&lt;String, Object&gt; entry : nameValuePairs.entrySet()) &#123; criteria.add(Restrictions.eq(entry.getKey(), entry.getValue())); &#125; List&lt;T&gt; list = criteria.list(); return list; &#125; @Override @SuppressWarnings("unchecked") public List&lt;T&gt; getAll() &#123; return getSession().createCriteria(getEntityClass()).list(); &#125; @Override @SuppressWarnings("unchecked") public T getUniqueResult(Map&lt;String, Object&gt; nameValuePairs) &#123; Criteria criteria = getSession().createCriteria(getEntityClass()); for (Map.Entry&lt;String, Object&gt; entry : nameValuePairs.entrySet()) &#123; criteria.add(Restrictions.eq(entry.getKey(), entry.getValue())); &#125; return (T) criteria.uniqueResult(); &#125; @Override @SuppressWarnings("unchecked") public T load(Serializable id)&#123; return (T) getSession().load(getEntityClass(), id); &#125; @Override public Serializable save(T t) &#123; return getSession().save(t); &#125; @Override public void update(T t) &#123; Session session = this.getSession(); session.update(t); //强制刷新缓存中数据至数据库中，防止大批量数据更新之后出现脏数据 session.flush(); &#125; @Override public void delete(T t) &#123; this.getSession().delete(t); &#125; /** * QO DtoResultWithPageInfo&lt;dtoClazz&gt;list+ҳϢ * * @param page * @param pageSize * @param qo * @param dtoClazz * @return *//* public &lt;Q extends QueryObject, D extends Dto&gt; DtoResultWithPageInfo&lt;D&gt; queryPageListByQueryObject( int page, int pageSize,Q qo, Class&lt;D&gt; dtoClazz)&#123; Criteria criteria = QueryObjectHelper.buildCriteria(qo, getSession()); return queryPageListByCriteria(criteria, page, pageSize, dtoClazz); &#125;*/ /** * QO List&lt;dtoClazz&gt; * @param qo * @param dtoClazz * @return */ /*public &lt;Q extends QueryObject,E, D extends Dto&gt; List&lt;D&gt; queryListByQueryObject( Q qo, Class&lt;D&gt; dtoClazz)&#123; Criteria criteria = QueryObjectHelper.buildCriteria(qo, getSession()); @SuppressWarnings("unchecked") List&lt;E&gt; list = criteria.list(); List&lt;D&gt; resultsDtoList = new ArrayList&lt;D&gt;(); for(E entity:list)&#123; try &#123; D dto = dtoClazz.newInstance(); BeanUtils.copyProperties(entity, dto); resultsDtoList.add(dto); &#125; catch (InstantiationException e) &#123; log.error("dtoʵ쳣ExMsg==&gt;"+e.getMessage()); &#125; catch (IllegalAccessException e) &#123; log.error("dtoʵ쳣ExMsg==&gt;"+e.getMessage()); &#125; &#125; return resultsDtoList; &#125;*/ /** * queryPageListByCriteria * * ͨcriteria DtoResultWithPageInfo&lt;dtoClazz&gt;list+ҳϢ * * @param criteria * ѯ * @param pageNo * ǰҳ * @param pageSize * ÿҳʾ * @param dtoClass * ݴݶclass * */ /*public &lt;E, D extends Dto&gt; DtoResultWithPageInfo&lt;D&gt; queryPageListByCriteria( Criteria criteria, int pageNo, int pageSize, Class&lt;D&gt; dtoClazz) &#123; PageInfo pageInfo = getInstancePageInfoWithCriteria(criteria, pageNo, pageSize); criteria.setProjection(null);// ͶӰ criteria.setFirstResult(pageInfo.getFirstResultNum()); criteria.setMaxResults(pageInfo.getPageSize()); @SuppressWarnings("unchecked") List&lt;E&gt; resultsList = criteria.list(); List&lt;D&gt; resultsDtoList = new ArrayList&lt;D&gt;(); for (E result : resultsList) &#123; D dto; try &#123; dto = dtoClazz.newInstance(); try &#123; BeanUtils.copyProperties(result, dto); &#125; catch (Exception e) &#123; log.error("ҳѯ쳣bean쳣"); e.printStackTrace(); &#125; &#125; catch (InstantiationException e) &#123; log.error("ҳѯ쳣dtoʼ쳣"); e.printStackTrace(); dto = null; &#125; catch (IllegalAccessException e) &#123; log.error("ҳѯ쳣dtoʼ쳣"); e.printStackTrace(); dto = null; &#125; resultsDtoList.add(dto); &#125; DtoResultWithPageInfo&lt;D&gt; resultWithPageInfo = new DtoResultWithPageInfo&lt;D&gt;( resultsDtoList, pageInfo); return resultWithPageInfo; &#125;*/ /** * ͨcriteria List&lt;dtoClazz&gt; * * @param criteria * @param dtoClazz * @return */ /*public &lt;E, D extends Dto&gt; List&lt;D&gt; queryListByCriteria( Criteria criteria,Class&lt;D&gt; dtoClazz) &#123; @SuppressWarnings("unchecked") List&lt;E&gt; resultsList = criteria.list(); List&lt;D&gt; resultsDtoList = new ArrayList&lt;D&gt;(); for (E result : resultsList) &#123; D dto; try &#123; dto = dtoClazz.newInstance(); try &#123; BeanUtils.copyProperties(result, dto); &#125; catch (Exception e) &#123; log.error("ҳѯ쳣bean쳣"); e.printStackTrace(); &#125; &#125; catch (InstantiationException e) &#123; log.error("ҳѯ쳣dtoʼ쳣"); e.printStackTrace(); dto = null; &#125; catch (IllegalAccessException e) &#123; log.error("ҳѯ쳣dtoʼ쳣"); e.printStackTrace(); dto = null; &#125; resultsDtoList.add(dto); &#125; return resultsDtoList; &#125;*/ /*public DataTablePageList queryDataTablePageListByCriteria( Criteria criteria, String displayStart, String displayLength) &#123; // ܼ¼ long totalRecords = 0L; criteria.setProjection(Projections.rowCount()); totalRecords = (Long) criteria.uniqueResult(); // criteria.setProjection(null); criteria.setFirstResult(Integer.parseInt(displayStart)); criteria.setMaxResults(Integer.parseInt(displayLength)); @SuppressWarnings("rawtypes") List resultsList = criteria.list(); DataTablePageList dtpl = new DataTablePageList( String.valueOf((int) totalRecords), resultsList); return dtpl; &#125; */ /** * ͨѯʼҳϢ * * @param criteria * @param pageNo * @param pageSize * @return *//* private PageInfo getInstancePageInfoWithCriteria(Criteria criteria, int pageNo, int pageSize) &#123; long totalQuantity = 0L; criteria.setProjection(Projections.rowCount()); totalQuantity = (Long) criteria.uniqueResult(); PageInfo pageInfo = PageInfo.getInstance(pageNo, pageSize, totalQuantity); return pageInfo; &#125;*/ @Override public Criteria createCriteria() &#123; // TODO Auto-generated method stub return getSession().createCriteria(getEntityClass()); &#125; /** * queryPageListByCriteria * * ͨcriteria DtoResultWithPageInfo&lt;dtoClazz&gt;list+ҳϢ * * @param criteria * ѯ * @param pageNo * ǰҳ * @param pageSize * ÿҳʾ * @param dtoClass * ݴݶclass * ص DtoResultWithPageInfo * * Ϊ queryPageListByCriteria */ @Override public &lt;E, D extends Dto&gt; DtoResultWithPageInfo&lt;D&gt; queryPageListByCriteria( Criteria criteria, int pageNo, int pageSize, Class&lt;D&gt; dtoClazz) &#123; //˷ĵãpageinfoѾfirstResult maxresult PageInfo pageInfo = getInstancePageInfoWithCriteria(criteria, pageNo, pageSize); criteria.setProjection(null);// ͶӰ criteria.setFirstResult(pageInfo.getFirstResultNum()); criteria.setMaxResults(pageInfo.getPageSize()); @SuppressWarnings("unchecked") List&lt;E&gt; resultsList = criteria.list(); List&lt;D&gt; resultsDtoList = new ArrayList&lt;D&gt;(); for (E result : resultsList) &#123; D dto; try &#123; dto = dtoClazz.newInstance(); try &#123; BeanUtils.copyProperties(result, dto); &#125; catch (Exception e) &#123; log.error("ҳѯ쳣bean쳣"); e.printStackTrace(); &#125; &#125; catch (InstantiationException e) &#123; log.error("ҳѯ쳣dtoʼ쳣"); e.printStackTrace(); dto = null; &#125; catch (IllegalAccessException e) &#123; log.error("ҳѯ쳣dtoʼ쳣"); e.printStackTrace(); dto = null; &#125; resultsDtoList.add(dto); &#125; DtoResultWithPageInfo&lt;D&gt; resultWithPageInfo = new DtoResultWithPageInfo&lt;D&gt;( resultsDtoList, pageInfo); return resultWithPageInfo; &#125; /** * queryPageListByCriteriaWithQo * * ͨcriteria DtoResultWithPageInfo&lt;dtoClazz&gt;list+ҳϢ * * @param criteria * ѯ * @param pageNo * ǰҳ * @param pageSize * ÿҳʾ * @param dtoClass * ݴݶclass * ص DtoResultWithPageInfo * * Ϊ queryPageListByCriteria */ @Override public &lt;E, D extends Dto&gt; DtoResultWithPageInfo&lt;D&gt; queryPageListByCriteriaWithQo(PageQo qo, Class&lt;D&gt; dtoClazz) &#123; //˷ĵãpageinfoѾfirstResult maxresult Criteria criteria = this.createCriteria(); qo.add(criteria); PageInfo pageInfo = getInstancePageInfoWithCriteria(criteria, qo.getPage(),qo.getRows()); criteria.setProjection(null);// ͶӰ criteria.setFirstResult(pageInfo.getFirstResultNum()); criteria.setMaxResults(pageInfo.getPageSize()); @SuppressWarnings("unchecked") List&lt;E&gt; resultsList = criteria.list(); List&lt;D&gt; resultsDtoList = new ArrayList&lt;D&gt;(); for (E result : resultsList) &#123; D dto; try &#123; dto = dtoClazz.newInstance(); try &#123; BeanUtils.copyProperties(result, dto); &#125; catch (Exception e) &#123; log.error("ҳѯ쳣bean쳣"); e.printStackTrace(); &#125; &#125; catch (InstantiationException e) &#123; log.error("ҳѯ쳣dtoʼ쳣"); e.printStackTrace(); dto = null; &#125; catch (IllegalAccessException e) &#123; log.error("ҳѯ쳣dtoʼ쳣"); e.printStackTrace(); dto = null; &#125; resultsDtoList.add(dto); &#125; DtoResultWithPageInfo&lt;D&gt; resultWithPageInfo = new DtoResultWithPageInfo&lt;D&gt;( resultsDtoList, pageInfo); return resultWithPageInfo; &#125; /** * ͨѯʼҳϢ * * @param criteria * @param pageNo * @param pageSize * @return */ private PageInfo getInstancePageInfoWithCriteria(Criteria criteria, int pageNo, int pageSize) &#123; long totalQuantity = 0L; // ܵtotalQuality criteria.setProjection(Projections.rowCount()); totalQuantity = (Long) criteria.uniqueResult(); PageInfo pageInfo = PageInfo.getInstance(pageNo, pageSize, totalQuantity); return pageInfo; &#125;&#125; 这个方法是极为重要的 protected abstract Class&lt;?&gt; getEntityClass();后续介绍，现在暂时有个印象。在www中的dao层有与各具体类(数据表)相对应的数据库操作实现：上图声明了三个具体类对应的接口声明：AdminDao、MacDao、TaskDao。对应三个接口有三个具体的实现类：AdminDaoImpl、MacDaoImpl、TaskDaoImpl。我们以与Admin类相关的dao层操作为例：Admin.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package com.fxmms.www.domain;import org.hibernate.annotations.GenericGenerator;import javax.persistence.*;/** * Created by mark on 16/11/2. * @usage 管理员实体类，与数据库中表相对应 */@Entity@Table(name = "mms_admin")public class Admin &#123; @Id @GeneratedValue(generator = "increment") @GenericGenerator(name = "increment", strategy = "increment") @Column private int id; @Column private String userName; @Column private String password; @Column private String role; @Column private int enable; @Column private int isDelete; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getRole() &#123; return role; &#125; public void setRole(String role) &#123; this.role = role; &#125; public int getEnable() &#123; return enable; &#125; public void setEnable(int enable) &#123; this.enable = enable; &#125; public int getIsDelete() &#123; return isDelete; &#125; public void setIsDelete(int isDelete) &#123; this.isDelete = isDelete; &#125;&#125; AdminDao.java123456789101112package com.fxmms.www.dao;import com.fxmms.common.dao.BaseDao;import com.fxmms.www.domain.Admin;/** * Created by mark on 16/10/31. * @usage 操作管理员数据库访问接口 */public interface AdminDao extends BaseDao&lt;Admin&gt; &#123;&#125; AdminDaoImpl.java123456789101112131415161718package com.fxmms.www.dao.hib;import com.fxmms.common.dao.hib.HibernateTemplateDao;import com.fxmms.www.dao.AdminDao;import com.fxmms.www.domain.Admin;/** * Created by mark on 16/11/2. * @usage 使用适配器模式，将common层中定义的公共访问数据库方法实现嫁接到Admin类的接口中。 */public class AdminDaoImpl extends HibernateTemplateDao&lt;Admin&gt; implements AdminDao &#123; @Override protected Class&lt;?&gt; getEntityClass() &#123; // TODO Auto-generated method stub return Admin.class; &#125;&#125; 可以看到，在具体类相关的数据库操作实现类中，我们只需要实现HibernateTemplateDao中抽象方法protected Class&lt;?&gt; getEntityClass()；即可。给我们的感觉就是这个方法的实现是画龙点睛之笔。回过头去看，在HibernateTemplateDao类中所有与数据库操作有关的方法：例如：123456@Override@SuppressWarnings("unchecked")public T getByUniqueKey(String columnName, Object value) &#123; return (T) getSession().createCriteria(getEntityClass()) .add(Restrictions.eq(columnName, value)).uniqueResult();&#125; getEntityClass()方法最终都会被具体的类所实现。这个设计真的是很巧妙。 5.webapp文件夹下分层详解 webapp下有res文件夹，用于存储静态文件，WEB-INF文件夹下有view文件夹用于放置应用中jsp页面。文件组织结构如下图所示： 6.配置tomcat 运行环境 项目搭建已经完毕，接下来需要做的就是配置项目的运行环境了，这里我们采用tomcat来充当应用服务器。6.1 去官网下载tomcat 8.0：http://tomcat.apache.org/download-80.cgi6.2 配置 tomcat 服务器：点击Edit Configurations点击+,并选择Tomcat Server中local选项添加启动任务名称，默认为unnamed配置Application Server装载开发版(exploded)应用war包,此步骤有两种方式：第一种方式：选择Deploy at the server startup下方的+，入下图所示： 接下来在Select Artifacts Deploy 弹出框中 选择 exploded 属性的war包 接下来选择apply－&gt; ok ，最终的结果是： 最终点击启动按钮启动应用最终的启动效果如下所示 模板代码地址：https://coding.net/u/zongyuan/p/Java-backend-template/git关于项目中应用到的JNI技术，会在后面讲解，主要侧重点是在代码层面解决JNI link library的问题。]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>编程实操</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java web 项目中使用JNI技术（如何在程序运行期间改变 java.library.path并生效）]]></title>
    <url>%2F2017%2F11%2F14%2Fjava-jni%2F</url>
    <content type="text"><![CDATA[记录结构:JNI技术入门详解，参照刚哥的手记：http://www.jianshu.com/p/fe42aa3150a0注意：刚哥手记与接下来要记录的web项目中使用JNI技术是无缝连接的。应用场景：当我们根据不同的平台生成不同的JNI libaray时，例如：linux .so、mac jnilib、windows .dll。我们想在打包web 应用时让程序动态调用c,或者c++对Java Native Inteface 的具体底层实现时，有一种方法是借助配置在idea中的vm option中设置库文件所在的路径，即-Djava.path.library，刚哥手记最后一部分有说明。精准定位问题： 1.那么有没有另外一种方式使得Java 程序在调用native inteface 中抽象本地方法自动加载所需要的代码呢？也就是说应用程序自动加载.so || (或).jnilib || .dll?。 2.我们知道Java 应用程序在调用底层代码生成的库文件时，需要指定库文件所在的path。那么我们的问题就清晰了，问题的痛点在于如何让应用程序在程序运行期间动态加载库文件所在的路径，进而加载所需的库文件。网上的一种说法是：在使用System.loadLibrary(“具体库文件所在的路径的相对路径”)，之前使用System.load(“具体库文件所在的根目录的全路径”)，本人试了一下，发现并不起作用。 继续找解决方案，无意中发现了一篇博客，博客地址是：http://ju.outofmemory.cn/entry/150717这篇文章讲述的是如何在运行时改变 java.library.path并生效。我想这正是我要的答案，无奈是英文的，还是硬着头皮看吧首先开篇很简明扼要说明问题： The java.library.path system property instructs the JVM where to search for native libraries. You have to specify it as a JVM argument using -Djava.library.path=/path/to/lib and then when you try to load a library using System.loadLibrary(“foo”), the JVM will search the library path for the specified library. If it cannot be found you will get an exception which looks like: 大致的意思是： 系统属性－ java.library.path指引JVM去寻找底层的库文件，你必须为JVM声明一个属性，类似于Djava.library.path=/path/to/lib ,当你需要使用System.loadLibrary(“foo”)加载底层foo库文件的时候，jvm会按照你声明的path去加载这个库文件，如果你不声明的话，会出现下面错误： 1234Exception in thread "main" java.lang.UnsatisfiedLinkError: no foo in java.library.path at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1734) at java.lang.Runtime.loadLibrary0(Runtime.java:823) at java.lang.System.loadLibrary(System.java:1028) 这个错告诉我们foo库并不在我们所要加载的路径下面。接下来说明原因： The java.library.path is read only once when the JVM starts up. If you change this property usingSystem.setProperty, it won’t make any difference. 意思是：java.library.path 只会在JVM启动的时候被都到，如果你直接使用System.setProperty(“java.path.libarary”,”库所在路径”)这样是不起作用的，因为JVM已经启动了。所以这个JVM后期不能找到这个库文件所在的路径，所以就报如上错误。源码中ClassLoader.loadLibrary有这样一句代码：1234if (sys_paths == null) &#123; usr_paths = initializePath("java.library.path"); sys_paths = initializePath("sun.boot.library.path");&#125; 为什么就定位问题到上述几行代码，我们得从源码的角度来分析，看下源码：首先是System.loadLibaray()，借助idea看下源码：1234567891011121314151617181920212223242526272829303132333435 /** * Loads the native library specified by the &lt;code&gt;libname&lt;/code&gt; * argument. The &lt;code&gt;libname&lt;/code&gt; argument must not contain any platform * specific prefix, file extension or path. If a native library * called &lt;code&gt;libname&lt;/code&gt; is statically linked with the VM, then the * JNI_OnLoad_&lt;code&gt;libname&lt;/code&gt; function exported by the library is invoked. * See the JNI Specification for more details. * * Otherwise, the libname argument is loaded from a system library * location and mapped to a native library image in an implementation- * dependent manner. * &lt;p&gt; * The call &lt;code&gt;System.loadLibrary(name)&lt;/code&gt; is effectively * equivalent to the call * &lt;blockquote&gt;&lt;pre&gt; * Runtime.getRuntime().loadLibrary(name) * &lt;/pre&gt;&lt;/blockquote&gt; * * @param libname the name of the library. * @exception SecurityException if a security manager exists and its * &lt;code&gt;checkLink&lt;/code&gt; method doesn't allow * loading of the specified dynamic library * @exception UnsatisfiedLinkError if either the libname argument * contains a file path, the native library is not statically * linked with the VM, or the library cannot be mapped to a * native library image by the host system. * @exception NullPointerException if &lt;code&gt;libname&lt;/code&gt; is * &lt;code&gt;null&lt;/code&gt; * @see java.lang.Runtime#loadLibrary(java.lang.String) * @see java.lang.SecurityManager#checkLink(java.lang.String) */ @CallerSensitive public static void loadLibrary(String libname) &#123; Runtime.getRuntime().loadLibrary0(Reflection.getCallerClass(), libname); &#125; 可以看到 方法调用中出现Runtime.getRuntime().loadLibrary0(), 从这行代码我们知道库文件是在运行时被加载起作用的。我们继续看loadLibrary0()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960 /** * Loads the native library specified by the &lt;code&gt;libname&lt;/code&gt; * argument. The &lt;code&gt;libname&lt;/code&gt; argument must not contain any platform * specific prefix, file extension or path. If a native library * called &lt;code&gt;libname&lt;/code&gt; is statically linked with the VM, then the * JNI_OnLoad_&lt;code&gt;libname&lt;/code&gt; function exported by the library is invoked. * See the JNI Specification for more details. * * Otherwise, the libname argument is loaded from a system library * location and mapped to a native library image in an implementation- * dependent manner. * &lt;p&gt; * First, if there is a security manager, its &lt;code&gt;checkLink&lt;/code&gt; * method is called with the &lt;code&gt;libname&lt;/code&gt; as its argument. * This may result in a security exception. * &lt;p&gt; * The method &#123;@link System#loadLibrary(String)&#125; is the conventional * and convenient means of invoking this method. If native * methods are to be used in the implementation of a class, a standard * strategy is to put the native code in a library file (call it * &lt;code&gt;LibFile&lt;/code&gt;) and then to put a static initializer: * &lt;blockquote&gt;&lt;pre&gt; * static &#123; System.loadLibrary("LibFile"); &#125; * &lt;/pre&gt;&lt;/blockquote&gt; * within the class declaration. When the class is loaded and * initialized, the necessary native code implementation for the native * methods will then be loaded as well. * &lt;p&gt; * If this method is called more than once with the same library * name, the second and subsequent calls are ignored. * * @param libname the name of the library. * @exception SecurityException if a security manager exists and its * &lt;code&gt;checkLink&lt;/code&gt; method doesn't allow * loading of the specified dynamic library * @exception UnsatisfiedLinkError if either the libname argument * contains a file path, the native library is not statically * linked with the VM, or the library cannot be mapped to a * native library image by the host system. * @exception NullPointerException if &lt;code&gt;libname&lt;/code&gt; is * &lt;code&gt;null&lt;/code&gt; * @see java.lang.SecurityException * @see java.lang.SecurityManager#checkLink(java.lang.String) */ @CallerSensitive public void loadLibrary(String libname) &#123; loadLibrary0(Reflection.getCallerClass(), libname); &#125; synchronized void loadLibrary0(Class&lt;?&gt; fromClass, String libname) &#123; SecurityManager security = System.getSecurityManager(); if (security != null) &#123; security.checkLink(libname); &#125; if (libname.indexOf((int)File.separatorChar) != -1) &#123; throw new UnsatisfiedLinkError( "Directory separator should not appear in library name: " + libname); &#125; ClassLoader.loadLibrary(fromClass, libname, false); &#125; 题外话：loadLibrary(),loadLibrary0()这两个方法的命名还是挺不符合规范的，历史遗留问题吧。在loadLibrary中我们看到了ClassLoader.loadLibrary(fromClass, libname, false);方法继续追溯12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 // Invoked in the java.lang.Runtime class to implement load and loadLibrary. static void loadLibrary(Class&lt;?&gt; fromClass, String name, boolean isAbsolute) &#123; ClassLoader loader = (fromClass == null) ? null : fromClass.getClassLoader(); if (sys_paths == null) &#123; usr_paths = initializePath("java.library.path"); sys_paths = initializePath("sun.boot.library.path"); &#125; if (isAbsolute) &#123; if (loadLibrary0(fromClass, new File(name))) &#123; return; &#125; throw new UnsatisfiedLinkError("Can't load library: " + name); &#125; if (loader != null) &#123; String libfilename = loader.findLibrary(name); if (libfilename != null) &#123; File libfile = new File(libfilename); if (!libfile.isAbsolute()) &#123; throw new UnsatisfiedLinkError( "ClassLoader.findLibrary failed to return an absolute path: " + libfilename); &#125; if (loadLibrary0(fromClass, libfile)) &#123; return; &#125; throw new UnsatisfiedLinkError("Can't load " + libfilename); &#125; &#125; for (int i = 0 ; i &lt; sys_paths.length ; i++) &#123; File libfile = new File(sys_paths[i], System.mapLibraryName(name)); if (loadLibrary0(fromClass, libfile)) &#123; return; &#125; libfile = ClassLoaderHelper.mapAlternativeName(libfile); if (libfile != null &amp;&amp; loadLibrary0(fromClass, libfile)) &#123; return; &#125; &#125; if (loader != null) &#123; for (int i = 0 ; i &lt; usr_paths.length ; i++) &#123; File libfile = new File(usr_paths[i], System.mapLibraryName(name)); if (loadLibrary0(fromClass, libfile)) &#123; return; &#125; libfile = ClassLoaderHelper.mapAlternativeName(libfile); if (libfile != null &amp;&amp; loadLibrary0(fromClass, libfile)) &#123; return; &#125; &#125; &#125; // Oops, it failed throw new UnsatisfiedLinkError("no " + name + " in java.library.path"); &#125; 这其中有段代码很重要：1234 if (sys_paths == null) &#123; usr_paths = initializePath("java.library.path"); sys_paths = initializePath("sun.boot.library.path"); &#125; 对于上述代码的解释我们可以从这篇博客中获取到答案： if you set sys_paths to null, the library path will be re-initialised when you try to load a library. 意思是说，如果我们通过代码将sys_paths，设置为null,那么java.library.path将被重新加载一次。那么问题来了，通过刚才的源代码追溯，我们知道System.loadLibray()调用ClassLoader.loadLibrary()方法，我们应该如何将sys_paths设置为空？通过上述情景描述，我们要更改sys_paths的值为null,只能在sys_paths初始化之前做手脚（反射在程序动态运行期间更改程序中的属性值）。代码如下：12345678910111213/** * Sets the java library path to the specified path * * @param path the new library path * @throws Exception */public static void setLibraryPath(String path) throws Exception &#123; System.setProperty("java.library.path", path); //set sys_paths to null final Field sysPathsField = ClassLoader.class.getDeclaredField("sys_paths"); sysPathsField.setAccessible(true); sysPathsField.set(null, null);&#125; 追溯上述代码，debug结果如下图所示： 上图红色注释为java.library.path，注释有误特此说明。最终程序的正常运行。 在程序中实现了程序运行时动态更改java.library.path并生效的效果。我在web项目中的应用是这样的：程序封装，对JNI的使用封装成jniutil工具类： 代码如下：GetDownloadID.java 声明本地方法，依赖底层实现。1234package com.fxmms.common.jniutil;public class GetDownloadID&#123; public native String getDownloadID(String mac);&#125; GetDownloadIDUtil.java，工具类，调用上述GetDownloadID类的实例方法getDownloadID()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.fxmms.common.jniutil;import org.apache.http.util.Asserts;import java.lang.reflect.Field;/** * @usage JNI调用底层c算法将mac地址转化为downloadid */public class GetDownloadIDUtil &#123; static&#123; try&#123; setLibraryPath("/Users/mark/mms/src/main/java/com/fxmms/common/jniutil"); System.loadLibrary("GetDownloadID"); &#125;catch(Exception e)&#123; System.err.println("Native code library failed to load.\n" + e); System.exit(1); &#125; &#125; public static String getDownLoadId(String mac)&#123; GetDownloadID test = new GetDownloadID(); String downLoadId = test.getDownloadID(mac); return downLoadId; &#125; /** * Sets the java library path to the specified path * @usage 动态更改sys_paths,使得usr_paths 重新初始化 * @param path the new library path * @throws Exception */ public static void setLibraryPath(String path) throws Exception &#123; System.setProperty("java.library.path", path); //set sys_paths to null final Field sysPathsField = ClassLoader.class.getDeclaredField("sys_paths"); sysPathsField.setAccessible(true); sysPathsField.set(null, null); &#125; public static void main(String[] args)&#123; //-Djava.library.path="/Users/mark/mms/src/main/java/com/fxmms/common/jniutil" ///Users/mark/mms/src/main/java/com/fxmms/common/jniutil System.out.println(System.getProperty("java.library.path")); String mac = "CC:81:DA:86:42:E7"; Asserts.check(mac!=null,"mac null"); GetDownloadID test = new GetDownloadID(); System.out.println(test.getDownloadID(mac)); &#125;&#125; 注意：对库文件的加载放置在静态代码块中。记录完毕。]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>编程实操</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建型设计模式--建造者模式]]></title>
    <url>%2F2017%2F11%2F14%2FJava-Design-Pattern-Creator%2F</url>
    <content type="text"><![CDATA[记录结构： --1.前言 --2.实际问题引入（需求） --3.使用建造者模式解决问题 --3.1建造者模式简述 --3.2建造者模式类图 --3.3建造者模式完整解决方案 --4.建造者模式总结 1.前言 没有人买车会只买一个轮胎或者方向盘,大家买的都是一辆包含轮胎、方向盘和发动机等多个部件的完整汽车。如何将这些部件组装成一辆完整的汽车并返回给用户,这是建造者模式需要解决的问题。建造者模式又称为生成器模式,它是一种较为复杂、使用频率也相对较低的创建型模式。建造者模式为客户端返回的不是一个简单的产品,而是一个由多个部件组成的复杂产品。 2.实际问题引入（需求）游戏角色设计YY软件公司游戏开发小组决定开发一款名为《 YY群侠传》的网络游戏,该游戏采用主流的 RPG(Role Playing Game,角色扮演游戏)模式,玩家可以在游戏中扮演虚拟世界中的一个特定角色,角色根据不同的游戏情节和统计数据(如力量、魔法、技能等)具有不同的能力,角色也会随着不断升级而拥有更加强大的能力。作为 RPG 游戏的一个重要组成部分,需要对游戏角色进行设计,而且随着该游戏的升级将不断增加新的角色。不同类型的游戏角色,其性别、脸型、服装、发型等外部特性都有所差异,例如“天使”拥有美丽的面容和披肩的长发,并身穿一袭白裙;而“恶魔”极其丑陋,留着光头并穿一件刺眼的黑衣。YY公司决定开发一个小工具来创建游戏角色,可以创建不同类型的角色并可以灵活增加新的角色。 YY公司的开发人员通过分析发现,游戏角色是一个复杂对象,它包含性别、脸型等多个组成部分,不同的游戏角色其组成部分有所差异,如图所示: 3.使用建造者模式解决问题3.1.建造者模式简述： 建造者模式是较为复杂的创建型模式，它将客户端与包含多个组成部分（或部件）的复杂对象的创建过程分离，客户端无须知道复杂对象的内部组成部分与装配方式，只需要知道所需建造者的类型即可。它关注如何一步一步创建一个的复杂对象，不同的具体建造者定义了不同的创建过程，且具体建造者相互独立，增加新的建造者非常方便，无须修改已有代码，系统具有较好的扩展性。建造者模式（Builder Pattern）：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。建造者模式是一种对象创建型模式。 3.2.建造者模式类图：建造者模式一步一步创建一个复杂的对象，它允许用户只通过指定复杂对象的类型和内容就可以构建它们，用户不需要知道内部的具体构建细节。建造者模式结构如图所示：各组件详解： Builder（抽象建造者):它为创建一个产品 Product 对象的各个部件指定抽象接口，在该接口中一般声明两类方法，一类方法是 buildPartX()，它们用于创建复杂对象的各个部件；另一类方法是 getResult()，它们用于返回复杂对象。Builder 既可以是抽象类，也可以是接口。ConcreteBuilder（具体建造者):它实现了 Builder 接口，实现各个部件的具体构造和装配方法，定义并明确它所创建的复杂对象，也可以提供一个方法返回创建好的复杂产品对象。Product（产品角色）:它是被构建的复杂对象，包含多个组成部件，具体建造者创建该产品的内部表示并定义它的装配过程。Director（指挥者）:指挥者又称为导演类，它负责安排复杂对象的建造次序，指挥者与抽象建造者之间存在聚合关系，可以在其 construct() 建造方法中调用建造者对象(使用多态，其实调用的是具体建造者的对象)的部件构造与装配方法，完成复杂对象的建造。客户端一般只需要与指挥者进行交互，在客户端确定具体建造者的类型，并实例化具体建造者对象（也可以通过配置文件和反射机制），然后通过指挥者类的构造函数或者 Setter 方法将该对象（具体建造者）传入指挥者类中。 3.3建造者模式完整解决方案YY公司开发人员决定使用建造者模式来实现游戏角色的创建，其基本结构如图所示：在图中，ActorController 充当指挥者，ActorBuilder 充当抽象建造者，HeroBuilder、AngelBuilder 和 DevilBuilder 充当具体建造者，Actor 充当复杂产品。完整代码如下所示：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134//Actor角色类：复杂产品，考虑到代码的可读性，只列出部分成员属性，//且成员属性的类型均为String，真实情况下，有些成员属性的类型需自定义class Actor&#123; private String type; //角色类型 private String sex; //性别 private String face; //脸型 private String costume; //服装 private String hairstyle; //发型 public void setType(String type) &#123; this.type = type; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public void setFace(String face) &#123; this.face = face; &#125; public void setCostume(String costume) &#123; this.costume = costume; &#125; public void setHairstyle(String hairstyle) &#123; this.hairstyle = hairstyle; &#125; public String getType() &#123; return (this.type); &#125; public String getSex() &#123; return (this.sex); &#125; public String getFace() &#123; return (this.face); &#125; public String getCostume() &#123; return (this.costume); &#125; public String getHairstyle() &#123; return (this.hairstyle); &#125;&#125;//角色建造器：抽象建造者abstract class ActorBuilder&#123; protected Actor actor = new Actor(); public abstract void buildType(); public abstract void buildSex(); public abstract void buildFace(); public abstract void buildCostume(); public abstract void buildHairstyle(); //工厂方法，返回一个完整的游戏角色对象 public Actor createActor() &#123; return actor; &#125;&#125;//英雄角色建造器：具体建造者class HeroBuilder extends ActorBuilder&#123; public void buildType() &#123; actor.setType(&quot;英雄&quot;); &#125; public void buildSex() &#123; actor.setSex(&quot;男&quot;); &#125; public void buildFace() &#123; actor.setFace(&quot;英俊&quot;); &#125; public void buildCostume() &#123; actor.setCostume(&quot;盔甲&quot;); &#125; public void buildHairstyle() &#123; actor.setHairstyle(&quot;飘逸&quot;); &#125; &#125;//天使角色建造器：具体建造者class AngelBuilder extends ActorBuilder&#123; public void buildType() &#123; actor.setType(&quot;天使&quot;); &#125; public void buildSex() &#123; actor.setSex(&quot;女&quot;); &#125; public void buildFace() &#123; actor.setFace(&quot;漂亮&quot;); &#125; public void buildCostume() &#123; actor.setCostume(&quot;白裙&quot;); &#125; public void buildHairstyle() &#123; actor.setHairstyle(&quot;披肩长发&quot;); &#125; &#125;//恶魔角色建造器：具体建造者class DevilBuilder extends ActorBuilder&#123; public void buildType() &#123; actor.setType(&quot;恶魔&quot;); &#125; public void buildSex() &#123; actor.setSex(&quot;妖&quot;); &#125; public void buildFace() &#123; actor.setFace(&quot;丑陋&quot;); &#125; public void buildCostume() &#123; actor.setCostume(&quot;黑衣&quot;); &#125; public void buildHairstyle() &#123; actor.setHairstyle(&quot;光头&quot;); &#125; &#125; 指挥者类 ActorController 定义了 construct() 方法，该方法拥有一个抽象建造者 ActorBuilder 类型的参数，在该方法内部实现了游戏角色对象的逐步构建，代码如下所示：12345678910111213141516//游戏角色创建控制器：指挥者class ActorController&#123; //逐步构建复杂产品对象 public Actor construct(ActorBuilder ab) &#123; Actor actor; ab.buildType(); ab.buildSex(); ab.buildFace(); ab.buildCostume(); ab.buildHairstyle(); actor=ab.createActor(); return actor; &#125;&#125; 为了提高系统的灵活性和可扩展性，我们将具体建造者类的类名存储在配置文件中，并通过工具类 XMLUtil 来读取配置文件并反射生成对象，XMLUtil 类的代码如下所示：12345678910111213141516171819202122232425262728293031323334import javax.xml.parsers.*;import org.w3c.dom.*;import org.xml.sax.SAXException;import java.io.*;class XMLUtil&#123;//该方法用于从XML配置文件中提取具体类类名，并返回一个实例对象 public static Object getBean() &#123; try &#123; //创建文档对象 DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = dFactory.newDocumentBuilder(); Document doc; doc = builder.parse(new File(&quot;config.xml&quot;)); //获取包含类名的文本节点 NodeList nl = doc.getElementsByTagName(&quot;className&quot;); Node classNode=nl.item(0).getFirstChild(); String cName=classNode.getNodeValue(); //通过类名生成实例对象并将其返回 Class c=Class.forName(cName); Object obj=c.newInstance(); return obj; &#125; catch(Exception e) &#123; e.printStackTrace(); return null; &#125; &#125;&#125; 编写如下客户端测试代码：123456789101112131415161718class Client &#123; public static void main(String args[]) &#123; ActorBuilder ab; //针对抽象建造者编程 ab = (ActorBuilder)XMLUtil.getBean(); //反射生成具体建造者对象 ActorController ac = new ActorController(); Actor actor; actor = ac.construct(ab); //通过指挥者创建完整的建造者对象 String type = actor.getType(); System.out.println(type + &quot;的外观：&quot;); System.out.println(&quot;性别：&quot; + actor.getSex()); System.out.println(&quot;面容：&quot; + actor.getFace()); System.out.println(&quot;服装：&quot; + actor.getCostume()); System.out.println(&quot;发型：&quot; + actor.getHairstyle()); &#125;&#125; 编译并运行程序，输出结果如下：12345天使的外观：性别：女面容：漂亮服装：白裙发型：披肩长发 在建造者模式中，客户端只需实例化指挥者类，指挥者类针对抽象建造者编程，客户端根据需要传入具体的建造者类型，指挥者将指导具体建造者一步一步构造一个完整的产品（逐步调用具体建造者的 buildX() 方法），相同的构造过程可以创建完全不同的产品。在游戏角色实例中，如果需要更换角色，只需要修改配置文件，更换具体角色建造者类即可；如果需要增加新角色，可以增加一个新的具体角色建造者类作为抽象角色建造者的子类，再修改配置文件即可，原有代码无须修改，完全符合“开闭原则”。 4.建造者模式总结建造者模式的核心在于如何一步步构建一个包含多个组成部件的完整对象，使用相同的构建过程构建不同的产品，在软件开发中，如果我们需要创建复杂对象并希望系统具备很好的灵活性和可扩展性可以考虑使用建造者模式。 主要优点 建造者模式的主要优点如下： (1) 在建造者模式中，客户端不必知道产品内部组成的细节，将产品本身与产品的创建过程解耦，使得相同的创建过程可以创建不同的产品对象。 (2) 每一个具体建造者都相对独立，而与其他的具体建造者无关，因此可以很方便地替换具体建造者或增加新的具体建造者，用户使用不同的具体建造者即可得到不同的产品对象。由于指挥者类针对抽象建造者编程，增加新的具体建造者无须修改原有类库的代码，系统扩展方便，符合“开闭原则” (3) 可以更加精细地控制产品的创建过程。将复杂产品的创建步骤分解在不同的方法中，使得创建过程更加清晰，也更方便使用程序来控制创建过程。 主要缺点 建造者模式的主要缺点如下： (1) 建造者模式所创建的产品一般具有较多的共同点，其组成部分相似，如果产品之间的差异性很大，例如很多组成部分都不相同，不适合使用建造者模式，因此其使用范围受到一定的限制。 (2) 如果产品的内部变化复杂，可能会导致需要定义很多具体建造者类来实现这种变化，导致系统变得很庞大，增加系统的理解难度和运行成本。 适用场景 在以下情况下可以考虑使用建造者模式： (1) 需要生成的产品对象有复杂的内部结构，这些产品对象通常包含多个成员属性。 (2) 需要生成的产品对象的属性相互依赖，需要指定其生成顺序。 (3) 对象的创建过程独立于创建该对象的类。在建造者模式中通过引入了指挥者类，将创建过程封装在指挥者类中，而不在建造者类和客户类中。 (4) 隔离复杂对象的创建和使用，并使得相同的创建过程可以创建不同的产品。 特此说明：文章引用于极客学院－－创建型设计模式]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[结构型设计模式(一) --适配器模式]]></title>
    <url>%2F2017%2F11%2F14%2FJava-Design-Pattern-Adapter%2F</url>
    <content type="text"><![CDATA[前言：设计模式之结构型模式软件模式与具体的应用领域无关,也就是说无论你从事的是移动应用开发、桌面应用开发、Web 应用开发还是嵌入式软件的开发,都可以使用软件模式。在软件模式中,设计模式是研究最为深入的分支,设计模式用于在特定的条件下为一些重复出现的软件设计问题提供合理的、有效的解决方案,它融合了众多专家的设计经验,已经在成千上万的软件中得以应用。1995 年,GoF 将收集和整理好的 23 种设计模式汇编成《设计模式:可复用面向对象软件的基础》一书,该书的出版也标志着设计模式正式成为面向对象(Object Oriented)软件工程的一个重要研究分支。结构型设计模式统共七种:适配器模式、桥接模式、组合模式、装饰模式、外观模式、享元模式和代理模式。今天来记录适配器模式。记录结构 1.用例引入（要解决的问题) 2.采用适配器模式解决问题 2.1 适配器模式概念及类图表示（概念，UML类图表示 ） 2.2 适配器模式详细解决方案（代码层面） 3.适配器模式分类 3.1 对象适配器 3.2 类适配器 3.3 缺省适配器 4.适配器模式优缺点总结 1.用例引入（要解决的问题) 我的笔记本电脑的工作电压是 20 V,而我国的家庭用电是 220 V,如何让 20 V 的笔记本电脑能够在 220 V 的电压下工作?答案是引入一个电源适配器(AC Adapter),俗称充电器或变压器,有了这个电源适配器,生活用电和笔记本电脑即可兼容,如图所示: 简单来说： 在软件开发中,有时也存在类似这种不兼容的情况,我们也可以像引入一个电源适配器一样引入一个称之为适配器的角色来协调这些存在不兼容的结构,这种设计方案即为适配器模式。 要解决的问题：没有源码的算法库 YY软件公司在很久以前曾开发了一个算法库,里面包含了一些常用的算法,例如排序算法和查找算法,在进行各类软件开发时经常需要重用该算法库中的算法。在为某学校开发教务管理系统时,开发人员发现需要对学生成绩进行排序和查找,该系统的设计人员已经开发了一个成绩操作接口 ScoreOperation,在该接口中声明了排序方法 sort(int[]) 和查找方法 search(int[], int),为了提高排序和查找的效率,开发人员决定重用算法库中的快速排序算法类 QuickSort 和二分查找算法类 BinarySearch,其中 QuickSort 的 quickSort(int[]) 方法实现了快速排序,BinarySearch 的 binarySearch (int[], int) 方法实现了二分查找。由于某些原因,现在 Y Y公司开发人员已经找不到该算法库的源代码,无法直接通过复制和粘贴操作来重用其中的代码;部分开发人员已经针对 ScoreOperation 接口编程,如果再要求对该接口进行修改或要求大家直接使用 QuickSort 类和 BinarySearch 类将导致大量代码需要修改。Sunny 软件公司开发人员面对这个没有源码的算法库,遇到一个幸福而又烦恼的问题:如何在既不修改现有接口又不需要任何算法库代码的基础上能够实现算法库的重用? 通过分析,我们不难得知,现在 Sunny 软件公司面对的问题有点类似本章最开始所提到的电压问题,成绩操作接口 ScoreOperation 好比只支持 20 V 电压的笔记本,而算法库好比 220 V 的家庭用电,这两部分都没有办法再进行修改,而且它们原本是两个完全不相关的结构,如图所示: 现在我们需要 ScoreOperation 接口能够和已有算法库一起工作,让它们在同一个系统中能够兼容,最好的实现方法是增加一个类似电源适配器一样的适配器角色,通过适配器来协调这两个原本不兼容的结构。如何在软件开发中设计和实现适配器是本章我们将要解决的核心问题,下面就让我们正式开始学习这种用于解决不兼容结构问题的适配器模式。 2.采用适配器模式解决问题 2.1 适配器模式概念及类图表示（概念，UML类图表示 )与电源适配器相似,在适配器模式中引入了一个被称为适配器(Adapter)的包装类,而它所包装的对象称为适配者(Adaptee),即被适配的类。适配器的实现就是把客户类的请求转化为对适配者的相应接口的调用。也就是说:当客户类调用适配器的方法时,其实在适配器类的内部将调用适配者类的方法,而这个过程对客户类是透明的,客户类并不直接访问适配者类。因此,适配器让那些由于接口不兼容而不能交互的类可以一起工作。 适配器模式可以将一个类的接口和另一个类的接口匹配起来,而无须修改原来的适配者接口和抽象目标类接口。适配器模式定义如下:适配器模式(Adapter Pattern):将一个接口转换成客户希望的另一个接口,使接口不兼容的那些类可以一起工作,其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式,也可以作为对象结构型模式。适配器模式类图表示：在适配器模式中,我们通过增加一个新的适配器类来解决接口不兼容的问题,使得原本没有任何关系的类可以协同工作。根据适配器类与适配者类的关系不同,适配器模式可分为对象适配器和类适配器两种,在对象适配器模式中,适配器与适配者之间是关联关系;在类适配器模式中,适配器与适配者之间是继承(或实现)关系。在实际开发中,对象适配器的使用频率更高,对象适配器模式结构如图所示:在对象适配器模式结构图中包含如下几个角色:Target(目标抽象类):目标抽象类定义客户所需接口,可以是一个抽象类或接口,也可以是具体类。 Target(目标抽象类):目标抽象类定义客户所需接口,可以是一个抽象类或接口,也可以是具体类。 Adapter(适配器类):适配器可以调用另一个接口,作为一个转换器,对Adaptee和Target进行适配,适配器类是适配器模式的核心,在对象适配器中,它通过继承Target并关联一个Adaptee对象使二者产生联系。 Adaptee(适配者类):适配者即被适配的角色,它定义了一个已经存在的接口,这个接口需要适配,适配者类一般是一个具体类,包含了客户希望使用的业务方法,在某些情况下可能没有适配者类的源代码。 根据对象适配器模式结构图,在对象适配器中,客户端需要调用 request() 方法,而适配者类 Adaptee 没有该方法,但是它所提供的 specificRequest() 方法却是客户端所需要的。为了使客户端能够使用适配者类,需要提供一个包装类 Adapter,即适配器类。这个包装类包装了一个适配者的实例,从而将客户端与适配者衔接起来,在适配器的 request() 方法中调用适配者的 specificRequest() 方法。因为适配器类与适配者类是关联关系(也可称之为委派关系),所以这种适配器模式称为对象适配器模式。 2.2 适配器模式详细解决方案（代码层面）YY软件公司开发人员决定使用适配器模式来重用算法库中的算法,其基本结构如图 9-4 所示: 在图中,ScoreOperation 接口充当抽象目标,QuickSort 和 BinarySearch 类充当适配者,OperationAdapter 充当适配器。完整代码如下所示:抽象成绩操作类:目标接口1234interface ScoreOperation &#123; public int[] sort(int array[]); //成绩排序 public int search(int array[],int key); //成绩查找&#125; 快速排序类:适配者= 被适配的类12345678910111213141516171819202122232425262728class QuickSort &#123; public int[] quickSort(int array[]) &#123; sort(array,0,array.length-1); return array; &#125; public void sort(int array[],int p, int r) &#123; int q=0; if(p&lt;r) &#123; q=partition(array,p,r); sort(array,p,q-1); sort(array,q+1,r);&#125; &#125; public int partition(int[] a, int p, int r) &#123; int x=a[r]; int j=p-1; for (int i=p;i&lt;=r-1;i++) &#123; if (a[i]&lt;=x) &#123; j++; swap(a,j,i);&#125; &#125; swap(a,j+1,r);return j+1; &#125; public void swap(int[] a, int i, int j) &#123; int t = a[i]; a[i] = a[j]; a[j] = t; &#125;&#125; 二分查找类:适配者=被适配的类12345678910111213141516class BinarySearch &#123; public int binarySearch(int array[],int key) &#123; int low = 0; int high = array.length -1; while(low &lt;= high) &#123; int mid = (low + high) / 2; int midVal = array[mid]; if(midVal &lt; key) &#123; low = mid +1; &#125;else if (midVal &gt; key) &#123; high = mid -1; &#125;else &#123; return 1; //找到元素返回1&#125; &#125; return -1; //未找到元素返回-1&#125;&#125; 操作适配器:适配器123456789101112131415class OperationAdapter implements ScoreOperation &#123; private QuickSort sortObj; //定义适配者QuickSort对象private BinarySearch searchObj; //定义适配者BinarySearch对象 public OperationAdapter() &#123; sortObj = new QuickSort(); searchObj = new BinarySearch(); &#125; public int[] sort(int array[]) &#123; //调用适配者类QuickSort的排序方 法 return sortObj.quickSort(array); &#125; public int search(int array[],int key) &#123; return searchObj.binarySearch(array,key); //调用适配者类BinarySearch的查找方法 &#125;&#125; 为了让系统具备良好的灵活性和可扩展性,我们引入了工具类 XMLUtil 和配置文件,其中,XMLUtil 类的代码如下所示:12345678910111213141516171819202122import javax.xml.parsers.*;import org.w3c.dom.*;import org.xml.sax.SAXException;import java.io.*;class XMLUtil &#123; public static Object getBean() &#123;try &#123; //创建文档对象DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = dFactory.newDocumentBuilder(); Document doc; doc = builder.parse(new File(&quot;config.xml&quot;)); //获取包含类名的文本节点 NodeList nl = doc.getElementsByTagName(&quot;className&quot;); Node classNode=nl.item(0).getFirstChild(); String cName=classNode.getNodeValue(); //通过类名生成实例对象并将其返回Class c=Class.forName(cName); Object obj=c.newInstance(); return obj; &#125;catch(Exception e) &#123; e.printStackTrace(); return null; &#125;&#125; 配置文件 config.xml 中存储了适配器类的类名,代码如下所示:1234&lt;?xml version="1.0"?&gt;&lt;config&gt; &lt;className&gt;OperationAdapter&lt;/className&gt;&lt;/config&gt; 编写如下客户端测试代码:1234567891011121314151617181920212223242526272829303132class Client &#123; public static void main(String args[]) &#123; ScoreOperation operation; //针对抽象目标接口编程 operation = (ScoreOperation)XMLUtil.getBean(); //读取配置文件，反射生成对象 int scores[] = &#123;84,76,50,69,90,91,88,96&#125;; //定义成绩数组 int result[]; int score; System.out.println(&quot;成绩排序结果：&quot;); result = operation.sort(scores); //遍历输出成绩 for(int i : scores) &#123; System.out.print(i + &quot;,&quot;); &#125; System.out.println(); System.out.println(&quot;查找成绩90：&quot;); score = operation.search(result,90); if (score != -1) &#123; System.out.println(&quot;找到成绩90。&quot;); &#125; else &#123; System.out.println(&quot;没有找到成绩90。&quot;); &#125; System.out.println(&quot;查找成绩92：&quot;); score = operation.search(result,92); if (score != -1) &#123; System.out.println(&quot;找到成绩92。&quot;); &#125; else &#123; System.out.println(&quot;没有找到成绩92。&quot;); &#125; &#125;&#125; 运行结果如下：123456成绩排序结果：50,69,76,84,88,90,91,96,查找成绩90：找到成绩90。查找成绩92：没有找到成绩92。 在本实例中使用了对象适配器模式，同时引入了配置文件，将适配器类的类名存储在配置文件中。如果需要使用其他排序算法类和查找算法类，可以增加一个新的适配器类，使用新的适配器来适配新的算法，原有代码无须修改。通过引入配置文件和反射机制，可以在不修改客户端代码的情况下使用新的适配器，无须修改源代码，符合“开闭原则”。 3.适配器模式分类 3.1 对象适配器 上文中记录的便是对象适配器，可以参照上问来进行强化记忆。3.2 类适配器 除了对象适配器模式之外，适配器模式还有一种形式，那就是类适配器模式，类适配器模式和对象适配器模式最大的区别在于适配器和适配者之间的关系不同，对象适配器模式中适配器和适配者之间是关联关系，而类适配器模式中适配器和适配者是继承关系，类适配器模式结构如图所示： 根据类适配器模式结构图，适配器类实现了抽象目标类接口 Target，并继承了适配者类，在适配器类的 request() 方法中调用所继承的适配者类的 specificRequest() 方法，实现了适配。典型的类适配器代码如下所示：12345class Adapter extends Adaptee implements Target &#123; public void request() &#123; specificRequest(); //此方法是Adaptee类中定义的实例方法 &#125; &#125; 由于Java、C#等语言不支持多重类继承，因此类适配器的使用受到很多限制，例如如果目标抽象类Target不是接口，而是一个类，就无法使用类适配器；此外，如果适配者Adapter为最终(Final)类，也无法使用类适配器。在Java等面向对象编程语言中，大部分情况下我们使用的是对象适配器，类适配器较少使用。 3.3 缺省适配器 缺省适配器模式是适配器模式的一种变体，其应用也较为广泛。缺省适配器模式的定义如下： 缺省适配器模式(Default Adapter Pattern)：当不需要实现一个接口所提供的所有方法时，可先设计一个抽象类实现该接口，并为接口中每个方法提供一个默认实现（空方法），那么该抽象类的子类可以选择性地覆盖父类的某些方法来实现需求，它适用于不想使用一个接口中的所有方法的情况，又称为单接口适配器模式。缺省适配器模式结构如图所示：在缺省适配器模式中，包含如下三个角色： ServiceInterface（适配者接口）：它是一个接口，通常在该接口中声明了大量的方法。 AbstractServiceClass（缺省适配器类）：它是缺省适配器模式的核心类，使用空方法的形式实现了在 ServiceInterface 接口中声明的方法。通常将它定义为抽象类，因为对它进行实例化没有任何意义。 ConcreteServiceClass（具体业务类）：它是缺省适配器类的子类，在没有引入适配器之前，它需要实现适配者接口，因此需要实现在适配者接口中定义的所有方法，而对于一些无须使用的方法也不得不提供空实现。在有了缺省适配器之后，可以直接继承该适配器类，根据需要有选择性地覆盖在适配器类中定义的方法。 4.适配器模式优缺点总结 无论是对象适配器模式还是类适配器模式都具有如下优点: 将目标类和适配者类解耦，通过引入一个适配器类来重用现有的适配者类，无须修改原有结构。 增加了类的透明性和复用性，将具体的业务实现过程封装在适配者类中，对于客户端类而言是透明的，而且提高了适配者的复用性，同一个适配者类可以在多个不同的系统中复用。 灵活性和扩展性都非常好，通过使用配置文件，可以很方便地更换适配器，也可以在不修改原有代码的基础上增加新的适配器类，完全符合“开闭原则”。 类适配器模式还有如下优点： 由于适配器类是适配者类的子类，因此可以在适配器类中置换一些适配者的方法，使得适配器的灵活性更强。 对象适配器模式还有如下优点: 一个对象适配器可以把多个不同的适配者适配到同一个目标； 可以适配一个适配者的子类，由于适配器和适配者之间是关联关系，根据“里氏代换原则”，适配者的子类也可通过该适配器进行适配。 类适配器模式的缺点： 对于 Java、C# 等不支持多重类继承的语言，一次最多只能适配一个适配者类，不能同时适配多个适配者； 适配者类不能为最终类，如在 Java 中不能为 final 类，C# 中不能为 sealed 类； 在 Java、C# 等语言中，类适配器模式中的目标抽象类只能为接口，不能为类，其使用有一定的局限性。 对象适配器模式的缺点: 与类适配器模式相比，要在适配器中置换适配者类的某些方法比较麻烦。如果一定要置换掉适配者类的一个或多个方法，可以先做一个适配者类的子类，将适配者类的方法置换掉，然后再把适配者类的子类当做真正的适配者进行适配，实现过程较为复杂。 适用场景在以下情况下可以考虑使用适配器模式： 系统需要使用一些现有的类，而这些类的接口（如方法名）不符合系统的需要，甚至没有这些类的源代码。 想创建一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作。]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[结构型设计模式--代理模式（静态与动态）]]></title>
    <url>%2F2017%2F11%2F14%2FJava-Design-Patter-proxy%2F</url>
    <content type="text"><![CDATA[代理简述： 代理是一个动词，动词之间会有产生关系两者。代理这个词产生关系的两者就是：realSubject(被代理者)，proxySubject（代理者）。举个例子：火车站，与火车站代售点。火车站可以进行售票工作，而火车站代售点可以实现代售车票。但是代售点还有其他的功能，比如说支持预约。这个是火车站所不具有的功能。简单理解代理模式就是：代理者代替被代理者去完成一些功能，在完成一些功能之前可以做一些预处理，完成之后可以做一些后置处理。再看一个程序中的例子：AOP就是建立在代理的思想之上的，AOP面向切面编程，何为切面，就是你程序中的主要逻辑，在这些主要逻辑产生的地方设置切点，在切点的地方设置一个注入一些非主要功能，这个就是面向切面编程。面向切面编程是以动态代理为底层实现的 java代理模式应用 &lt;1.静态代理–继承实现：java中静态代理的实现方式有两种：一种基于继承思想，一种基于聚合。首先描述基于继承思想的静态代理：（每段代码下方会有讲解，代码内会有注释）代码如下：1.定义一个接口：Moveable12345package com.feixun.designerpattern.proxy.static_proxy;public interface Moveable &#123; void move(); //定义抽象方法 move()，表示移动功能&#125; 2.定义一个被代理类Car类实现这个Moveable接口12345678910111213141516package com.feixun.designerpattern.proxy.static_proxy;import java.util.Random;public class Car implements Moveable&#123; //实现move方法 @Override public void move() &#123; try &#123; Thread.sleep(new Random().nextInt(1000)); System.out.println(&quot;汽车行驶中&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 3.在定义一个代理类Car2继承自Car123456789101112131415161718package com.feixun.designerpattern.proxy.static_proxy;/** * @author tao.liu * 通过继承实现静态代理 丰富RealSubject的功能，Car2相当于ProxySubject * */public class Car2 extends Car&#123; @Override public void move() &#123; long starttime = System.currentTimeMillis(); System.out.println(&quot;汽车开始行驶&quot;); super.move(); long endtime = System.currentTimeMillis(); System.out.println(&quot;汽车行驶结束，行驶了&quot;+(endtime-starttime)+&quot; 毫秒&quot;); &#125;&#125; 解释：此程序在调用真实被代理类之前，对move花费的时间进行记录。 4.客户端调用1234567891011package com.feixun.designerpattern.proxy.static_proxy;public class Client &#123; public static void main(String[] args) &#123; /*采用car2继承car 的方式实现代理 *随着功能的增加会出现更多的继承才能满足需求 */ Moveable moveable = new Car2(); moveable.move(); &#125;&#125; 程序输出结果：123汽车开始行驶汽车行驶中汽车行驶结束，行驶了287 毫秒 此种静态代理采用的是代理类（proxySubject）继承被代理类（realSubject）而实现的。分析弊端：1.假设现在我需要在汽车运行前后加上日志记录的功能，在这种方式（继承）下，我需要新建一个（Car3继承Car）的代理类完成这件事情。2.再假设我现在还需要在运行前加上启动汽车的功能，我们需要再建立一个（Car4继承Car）的代理类来完成这个事情。3.再假设，我需要在汽车运行之前先启动汽车，再进行日志记录，我们需要再建立一个Car5来继承Car3.综上所述，随着功能的叠加，类的数量也会呈爆炸式增长。解决这个问题就需要用聚合来实现类的代理 &lt;2.静态代理–聚合实现：代码如下：建立move功能定义接口12345package com.feixun.designerpattern.proxy.static_proxy;public interface Moveable &#123; void move();&#125; 建立实现move功能的Car类12345678910111213141516package com.feixun.designerpattern.proxy.static_proxy;import java.util.Random;public class Car implements Moveable&#123; @Override public void move() &#123; try &#123; Thread.sleep(new Random().nextInt(1000)); System.out.println(&quot;汽车行驶中&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 建立日志代理类CarLogProxy1234567891011121314151617package com.feixun.designerpattern.proxy.static_proxy;public class CarLogProxy implements Moveable &#123; private Moveable moveable;//将movable 类型的对象聚合进来，其实movable是一个接口，这里用到了多态的概念。 public CarLogProxy(Moveable moveable) &#123; super(); this.moveable = moveable; &#125; @Override public void move() &#123; System.out.println(&quot;日志开始...&quot;); moveable.move(); System.out.println(&quot;日志结束...&quot;); &#125;&#125; 接着建立行驶时间CarTimeProxy代理类1234567891011121314151617181920package com.feixun.designerpattern.proxy.static_proxy;//CarTimeProxy 为 属于Moveable 的类型对象的代理类//基于聚合的方式public class CarTimeProxy implements Moveable&#123; private Moveable moveable;//同上所示 public CarTimeProxy(Moveable moveable) &#123; super(); this.moveable = moveable; &#125; @Override public void move() &#123; long starttime = System.currentTimeMillis(); System.out.println(&quot;汽车开始行驶&quot;); moveable.move(); long endtime = System.currentTimeMillis(); System.out.println(&quot;汽车行驶结束，行驶了&quot;+(endtime-starttime)+&quot; 毫秒&quot;); &#125;&#125; 测试类123456789101112131415package com.feixun.designerpattern.proxy.static_proxy;public class Client &#123; public static void main(String[] args) &#123; Car car1 = new Car(); CarLogProxy carLogProxy = new CarLogProxy(car1); CarTimeProxy carTimeProxy = new CarTimeProxy(carLogProxy); carTimeProxy.move(); &#125; //引入问题:如果现在更多的realsubject 需要事件代理，那么现在需要新建多个代理类吗？类膨胀。 //动态产生代理，实现对不同类，不同方法的代理。 &#125; 运行结果：12345汽车开始行驶日志开始...汽车行驶中日志结束...汽车行驶结束，行驶了529 毫秒 现在我们这样测试：（请注意如下程序与上方程序的不同点：）12345678910111213141516package com.feixun.designerpattern.proxy.static_proxy;public class Client &#123; public static void main(String[] args) &#123; //采用聚合的方式实现的代理，代理之间也可以互相调用 Car car1 = new Car(); CarTimeProxy carTimeProxy = new CarTimeProxy(car1); CarLogProxy carLogProxy = new CarLogProxy(carTimeProxy); carLogProxy.move(); &#125; //引入问题，如果现在更多的不同类型的realsubject：比如或火车的，汽车的类 需要被代理，那么现在需要新建多个代理类吗？类膨胀。 //动态产生代理，实现对不同类，不同方法的代理。 &#125; 运行结果：12345日志开始...汽车开始行驶汽车行驶中汽车行驶结束，行驶了649 毫秒日志结束... 优点：这样的话就可以实现多个代理对象之间的相互调用相互聚合。从而比用继承方式实现的静态代理更优。减少了一个维度。 引入问题，如果现在更多的不同类型的realsubject：比如或火车的，汽车的类 需要被代理，那么现在需要新建多个代理类吗？类膨胀问题产生。 动态产生代理，实现对不同类，不同方法的代理。 动态代理直接上代码：首先建立定义接口的Moveable:12345package com.feixun.designerpattern.proxy.dynamic_proxy;public interface Moveable &#123; void move();&#125; 接着定义realsubject（被代理类）：泛指所有类型的被代理类。可以是Car,Subway，etc.12345678910111213141516package com.feixun.designerpattern.proxy.dynamic_proxy;import java.util.Random;public class Car implements Moveable &#123; @Override public void move() &#123; try &#123; Thread.sleep(new Random().nextInt(1000)); System.out.println(&quot;汽车行驶中&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 接着建立实现（implements）InvocationHandler接口的类：InvocationHandler,中定义了Object invoke(Object proxy, Method method, Object[] args) 方法。参数解释如下图代码中注释123456789101112131415161718192021222324252627package com.feixun.designerpattern.proxy.dynamic_proxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;public class MyHandler implements InvocationHandler &#123; private Object target;//被代理对象 public MyHandler(Object target) &#123; this.target = target; &#125; /* (non-Javadoc) * @see java.lang.reflect.InvocationHandler#invoke(java.lang.Object, java.lang.reflect.Method, java.lang.Object[]) * proxy--指被代理的对象（感觉java这个参数的名字并不是很好） * method--被代理对象的方法 * args:被代理对象的方法参数 */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;汽车开始运行了...&quot;); method.invoke(target, args);//运行被代理对象的方法，采用反射的机制。 System.out.println(&quot;汽车运行结束...&quot;); return null; &#125;&#125; 这一步只是完成了被代理对象方法的扩充，还没有产生真实的代理对象。再看测试类：1234567891011121314151617181920package com.feixun.designerpattern.proxy.dynamic_proxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Proxy;public class TestDynamicProxy &#123; public static void main(String[] args) &#123; Car car = new Car(); InvocationHandler handler = new MyHandler(car); Class&lt;?&gt; cs = car.getClass(); /* * @param ： classloader 被代理对象的类加载器 * @param : interfaces 被代理对象实现的接口 * @param ： Invocationhandler handler /子类 */ Moveable moveable=(Moveable)Proxy.newProxyInstance(cs.getClassLoader(), cs.getInterfaces(), handler);//这一步动态生成代理对象 moveable moveable.move(); &#125;&#125; 运行结果：123汽车开始运行了...汽车行驶中汽车运行结束... 可以看出：动态代理解决了对不同委托类产生代理对象的问题，假设现在我有Subway类，我要实现被代理，我只需要Subway实现Moveable，然后在测试类中更改几行代码就好，所以解决了聚合静态代理产生的问题,又将问题复杂度减少了一个维度。但是jdk动态代理也有问题：委托类想要实现自己的代理类，必须实现接口，如果有类没有实现接口，就不能使用JDK代理。完]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 深克隆与浅克隆]]></title>
    <url>%2F2017%2F11%2F14%2Fjava-clone%2F</url>
    <content type="text"><![CDATA[Java 深克隆(DeepClone)与浅克隆(ShallowClone)是原型设计模式的灵魂。12345记录结构： --什么是浅克隆？ --实现浅克隆 --什么是深克隆？ --实现深克隆 需求 Sunny 软件公司 OA 系统支持工作周报的快速克隆，极大提高了工作周报的编写效率，受到员工的一致好评。但有员工又发现一个问题，有些工作周报带有附件，例如经理助理“小龙女”的周报通常附有本周项目进展报告汇总表、本周客户反馈信息汇总表等，如果使用上述原型模式来复制周报，周报虽然可以复制，但是周报的附件并不能复制，这是由于什么原因导致的呢？如何才能实现周报和附件的同时复制呢？在解决问题之前了解一下浅克隆与深克隆。 浅克隆 浅克隆在浅克隆中,如果原型对象的成员变量是值类型,将复制一份给克隆对象;如果原型对象的成员变量是引用类型,则将引用对象的地址复制一份给克隆对象,也就是说原型对象和克隆对象的成员变量指向相同的内存地址。简单来说,在浅克隆中,当对象被复制时只复制它本身和其中包含的值类型的成员变量,而引用类型的成员对象并没有复制,如图所示: ##实现浅克隆 在 Java 语言中，通过覆盖 Object 类的 clone() 方法可以实现浅克隆。为了让大家更好地理解浅克隆和深克隆的区别，我们首先使用浅克隆来实现工作周报和附件类的复制，其结构如图所示： 代码如下所示：Attachement.java(附件实体类)123456789101112public class Attachement &#123; private String name; //附件名称 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public void downLoad() &#123; System.out.println(name+&quot;被下载&quot;); &#125;&#125; WeeklyLog.java(周报类)聚合了Attachement对象1234567891011121314151617181920212223242526272829303132333435363738394041/** * Created by mark on 16/10/19. * @usage 实现浅复制 * 浅复制 实现的是对对象中值类型(基本数据类型)引用类型的复制 * 基本数据类型 全复制 * 引用数据类型 对引用类型对象的地址的复制 * 这样两个对象之间会有关联，没有实现完全的分离，一旦当中的某个引用类型对象发生变化， * 那么这两个对象都会发生变化 */public class WeeklyLog implements Cloneable &#123; private Attachement attachment; private String date; private String content; public Attachement getAttachment() &#123; return attachment; &#125; public void setAttachment(Attachement attachment) &#123; this.attachment = attachment; &#125; public String getDate() &#123; return date; &#125; public void setDate(String date) &#123; this.date = date; &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; this.content = content; &#125; public WeeklyLog clone() &#123; Object object = null; try &#123; object = super.clone();//调用Object clone方法 return (WeeklyLog)object; &#125;catch (CloneNotSupportedException e) &#123; e.printStackTrace(); return null; &#125; &#125;&#125; 客户端代码如下所示：12345678910111213class Client &#123; public static void main(String args[]) &#123; WeeklyLog log_previous, log_new; log_previous = new WeeklyLog(); //创建原型对象 Attachment attachment = new Attachment(); //创建附件对象 log_previous.setAttachment(attachment); //将附件添加到周报中 log_new = log_previous.clone(); //调用克隆方法创建克隆对象 //比较周报 System.out.println(&quot;周报是否相同？ &quot; + (log_previous == log_new)); //比较附件 System.out.println(&quot;附件是否相同？ &quot; + (log_previous.getAttachment() == log_new.getAttachment())); &#125;&#125; 编译并运行程序，输出结果如下：12周报是否相同？ false附件是否相同？ true 由于使用的是浅克隆技术，因此工作周报对象复制成功，通过“==”比较原型对象和克隆对象的内存地址时输出 false；但是比较附件对象的内存地址时输出 true，说明它们在内存中是同一个对象。 什么是深克隆？ 在深克隆中，无论原型对象的成员变量是值类型还是引用类型，都将复制一份给克隆对象，深克隆将原型对象的所有引用对象也复制一份给克隆对象。简单来说，在深克隆中，除了对象本身被复制外，对象所包含的所有成员变量也将复制，如图所示： 在 Java 语言中，如果需要实现深克隆，可以通过序列化（Serialization）等方式来实现。序列化就是将对象写到流的过程，写到流中的对象是原有对象的一个拷贝，而原对象仍然存在于内存中。通过序列化实现的拷贝不仅可以复制对象本身，而且可以复制其引用的成员对象，因此通过序列化将对象写到一个流中，再从流里将其读出来，可以实现深克隆。需要注意的是能够实现序列化的对象其类必须实现 Serializable 接口，否则无法实现序列化操作。下面我们使用深克隆技术来实现工作周报和附件对象的复制，由于要将附件对象和工作周报对象都写入流中，因此两个类均需要实现 Serializable 接口，其结构如图所示： 修改后的附件类 Attachment 代码如下：1234567891011121314import java.io.*;//附件类class Attachment implements Serializable &#123; private String name; //附件名 public void setName(String name) &#123; this.name = name; &#125; public String getName() &#123; return this.name; &#125; public void download() &#123; System.out.println(&quot;下载附件，文件名为&quot; + name); &#125;&#125; 工作周报类 WeeklyLog 不再使用 Java 自带的克隆机制，而是通过序列化来从头实现对象的深克隆，我们需要重新编写 clone() 方法，修改后的代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.io.*;//工作周报类class WeeklyLog implements Serializable &#123; private Attachment attachment; private String name; private String date; private String content; public void setAttachment(Attachment attachment) &#123; this.attachment = attachment; &#125; public void setName(String name) &#123; this.name = name; &#125; public void setDate(String date) &#123; this.date = date; &#125; public void setContent(String content) &#123; this.content = content; &#125; public Attachment getAttachment()&#123; return (this.attachment); &#125; public String getName() &#123; return (this.name); &#125; public String getDate() &#123; return (this.date); &#125; public String getContent() &#123; return (this.content); &#125; //使用序列化技术实现深克隆 public WeeklyLog deepClone() throws IOException, ClassNotFoundException, OptionalDataException &#123; //将对象写入流中 使用了装饰器模式 ByteArrayOutputStream bao=new ByteArrayOutputStream(); ObjectOutputStream oos=new ObjectOutputStream(bao); oos.writeObject(this); //将对象从流中取出 ByteArrayInputStream bis=new ByteArrayInputStream(bao.toByteArray()); ObjectInputStream ois=new ObjectInputStream(bis); return (WeeklyLog)ois.readObject(); &#125;&#125; 重新编译程序，得到如下结果：12周报是否相同？ false附件是否相同？ false 从输出结果可以看出，由于使用了深克隆技术，附件对象也得以复制，因此用“==”比较原型对象的附件和克隆对象的附件时输出结果均为 false。深克隆技术实现了原型对象和克隆对象的完全独立，对任意克隆对象的修改都不会给其他对象产生影响，是一种更为理想的克隆实现方式。 拓展：Java 语言提供的 Cloneable 接口和 Serializable 接口的代码非常简单，它们都是空接口，这种空接口也称为标识接口，标识接口中没有任何方法的定义，其作用是告诉 JRE 这些接口的实现类是否具有某个功能，如是否支持克隆、是否支持序列化等。]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Node.js EventEmitter (触发器)]]></title>
    <url>%2F2017%2F11%2F14%2FEventEmitter%2F</url>
    <content type="text"><![CDATA[Node.js EventEmitter Node.js 所有的异步 I/O 操作在完成时都会发送一个事件到事件队列.Node.js里面的许多对象都会分发事件：一个net.Server对象会在每次有新连接时分发一个事件， 一个fs.readStream对象会在文件被打开的时候发出一个事件。 所有这些产生事件的对象都是 events.EventEmitter 的实例。 EventEmitter 类 events 模块只提供了一个内部类： events.EventEmitter。EventEmitter 的核心就是事件触发与事件监听器功能的封装。你可以通过require(“events”);来访问该模块。创建一个文件叫做emitter.js:12345678910111213//创建EventEmitter类var EventEmitter = require(&apos;events&apos;).EventEmitter();//创建eventEmitter对象var eventEmitter = new EventEmitter();eventEmitter.on(&apos;bomb&apos;,function()&#123; //观察者为匿名函数，事件为bomb console.log(&apos;bomb已经引爆&apos;);&#125;)//创建bomb之后就是要引爆它了，这里牵扯到事件的触发setTimeout(function()&#123; eventEmitter.emit(&apos;bomb&apos;);&#125;,1000)； 执行结果如下：运行这段代码，1 秒后控制台输出了 ‘事件触发’。其原理是 event 对象注册了事件 bomb 的一个监听器，然后我们通过 setTimeout 在 1000 毫秒以后 event 对象触发事件bomb，此时会调用bomb的监听器(匿名函数)。12$ node emitter.jsbomb已经引爆 eventEmitter 的每个事件由一个事件名和若干个参数组成，事件名是一个字符串，通常表达一定的语义。对于每个事件，EventEmitter 支持 若干个事件监听器。当事件触发时，注册到这个事件的事件监听器被依次调用，事件参数作为回调函数参数传递。让我们以下面的例子解释这个过程：12345678910 var event = require(&apos;events&apos;); var eventEmitter = new event.EventEmitter(); eventEmitter.on(&apos;bobm&apos;,function(args1,args2)&#123; console.log(&apos;bomb引燃，引燃使用的是:&apos;+args1+&quot; 和&quot;+arg2)； &#125;);eventEmitter.on(&apos;bobm&apos;,function(args1,args2)&#123; console.log(&apos;bomb引燃，使用的是:&apos;+args1+&quot;或者 &quot;+arg2)； &#125;); 执行以上代码，运行的结果如下：123$ node event.jslistener1 arg1 参数 arg2 参数listener2 arg1 参数 arg2 参数 以上例子中，emitter 为事件 someEvent 注册了两个事件监听器，然后触发了 someEvent 事件。运行结果中可以看到两个事件监听器回调函数被先后调用。 这就是EventEmitter最简单的用法。EventEmitter 提供了多个属性，如 on 和 emit。on 函数用于绑定事件函数，emit 属性用于触发一个事件。]]></content>
      <categories>
        <category>Node.js</category>
      </categories>
      <tags>
        <tag>Node</tag>
        <tag>触发器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一致性哈希算法在分布式缓存中的应用]]></title>
    <url>%2F2017%2F11%2F14%2F%E4%B8%80%E8%87%B4%E6%80%A7hash%E9%97%AD%E7%8E%AF%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[目的 介绍一致性hash算法（Consistent Hashing）及其在分布式缓存中的应用，以及对一致性hash算法原理的介绍。 应用场景 假设我们有一个网站，最近发现随着流量增加，服务器压力越来越大，之前直接读写数据库的方式不太给力了，于是我们想引入Redis作为缓存机制。现在我们一共有三台机器可以作为Redis服务器，如下图所示。 要解决的问题 一般来说我们在大规模访问，大并发流量下都会使用到分布式缓存，即将廉价机器部署在同一个子网内，形成多机器集群，然后通过负载均衡以及一定的路由规则进行读请求的分流，将请求映射到对应的缓存服务器上。如何对请求与缓存服务器之间进行精准映射,以及优雅的扩展，剔除缓存服务器是分布式缓存部署的痛点。接下来我们会对解决以上问题的一些传统做法进行分析。 1.请求与缓存服务器之间精准映射问题. 最简策略-随机选取：含义：将每一次Redis请求随机发送到一台Redis服务器.产生的问题： 1231.同一份数据可能被存在不同的机器上而造成数据冗余。2.有可能某数据已经被缓存但是访问却没有命中，因为无法保证对相同key的所有访问都被发送到相同的服务器。 因此，随机策略无论是时间效率还是空间效率都非常不好。 解决保证相同key每次访问同一台Redis服务器-计算哈希：含义：保证对相同key的访问会被发送到相同的服务器。方案描述：对于每次访问，可以按如下算法计算其哈希值：h = Hash(key) % 3其中Hash是一个从字符串到正整数的哈希映射函数。这样，如果我们将Redis Server分别编号为0、1、2，那么就可以根据上式和key计算出服务器编号h，然后去访问。这个方法虽然解决了上面提到的两个问题，但是存在一些其它的问题。如果将上述方法抽象，可以认为通过：h = Hash(key) % N这个算式计算每个key的请求应该被发送到哪台服务器，其中N为服务器的台数，并且服务器按照0 – (N-1)编号。 2.优雅的扩展，剔除缓存服务器问题 对于根据请求的key进行hash 运算定位Redis缓存服务器产生的问题： 容错性和扩展性将会变得极差. 容错性：指当系统中某一个或几个服务器变得不可用时，整个系统是否可以正确高效运行； 扩展性：指当加入新的服务器后，整个系统是否可以正确高效运行。现假设有一台服务器宕机了，那么为了填补空缺，要将宕机的服务器从编号列表中移除，后面的服务器按顺序前移一位并将其编号值减一，此时每个key就要按h = Hash(key) % (N-1)重新计算；同样，如果新增了一台服务器，虽然原有服务器编号不用改变，但是要按h = Hash(key) % (N+1)重新计算哈希值。因此系统中一旦有服务器变更，大量的key会被重定位到不同的服务器从而造成大量的缓存不命中。而这种情况在分布式系统中是非常糟糕的。 一个设计良好的分布式哈希方案应该具有良好的单调性，即服务节点的增减不会造成大量哈希重定位。一致性hash算法就是这样一种hash方案。 解决方法－一致性hash算法 算法简述一致性哈希算法（Consistent Hashing）最早在论文《Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web》中被提出。简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0 - 2的32次方-1（即哈希值是一个32位无符号整形），整个哈希空间环如下： 整个空间按顺时针方向组织。0和232-1在零点中方向重合。 下一步将各个服务器使用H进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中三台服务器使用ip地址哈希后在环空间的位置如下： 接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数H计算出哈希值h，通根据h确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。 例如我们缓存服务器中有A、B、C、D四个key对应的数据对象，经过哈希计算后，在环空间上的位置如下： 截止到现在似乎还没有什么觉得神奇的地方，请往下看：容错性与可扩展性分析下面分析一致性哈希算法的容错性和可扩展性。现假设Redis-2宕机了：我们可以看到ACD节点并不受影响，只有B节点被重定向至Redis-0。 下面考虑另外一种情况，如果我们在系统中增加一台服务器Redis-3 Server： 可以发现对于C这个key，重新定位至Redis-3 服务器，其他非C的key均不受影响。 综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 数据倾斜问题 解决办法-虚拟节点一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。例如我们的系统中有两台服务器，其环分布如下： 此时必然造成大量数据集中到Redis-1上，而只有极少量会定位到Redis-0上。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，我们决定为每台服务器计算三个虚拟节点，于是可以分别计算“Redis-1 #1”、“Redis-1 #2”、“Redis-1 #3”、“Redis-0 #1”、“Redis-0 #2”、“Redis-0 #3”的哈希值，于是形成六个虚拟节点： 同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Redis-1#1”、“Redis-1#2”、“Redis-1#3”三个虚拟节点的数据均定位到Redis-1上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。 总结目前一致性哈希基本成为了分布式系统组件的标准配置，例如Redis的各种客户端都提供内置的一致性哈希支持。本文只是简要介绍了这个算法的思想，以及在分布式应用中的应用场景。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>缓存</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoSQL－Redis入门(二)]]></title>
    <url>%2F2017%2F11%2F04%2FNoSql-Redis-2%2F</url>
    <content type="text"><![CDATA[Redis要点： 1.关键字(keys)用于标识一段数据的字符串2.值(values)是一段任意的字节序列，Redis不会关注他们实质是什么3.Redis展示了5种专门的数据结构4.上面几点使得Redis快速而且容易使用，但Redis不适用于所有的应用场景 1.Redis的数据结构 每种数据结构的要点包括： 1.是什么？2.包含的有效方法3.使用这些数据结构能处理哪些类型的特性和数据1.1 字符串(String)在Redis里,字符串是最基本的数据结构。for example1set users:leto &quot;&#123;name: leto, planet: dune, likes: [spice]&#125;&quot; Redis是怎么知道我们是在使用哪个数据结构?其解决方法是,每个命令都相对应于一种特定的数据结构。例如,当你使用 set 命令,你就是将值存储到一个字符串数据结构里。而当你使用 hset 命令,你就是将值存储到一个散列数据结构里。考虑到Redis的关键字集很小,这样的机制具有相当的可管理性。正如上述：我们已经看到了一个常见的字符串使用案例,即通过关键字存储对象的实例。我们可以通过下面的命令进行实操：1234567891011127.0.0.1:6379&gt; set user:liutao &quot;&#123;name:liutao,age:23,likes[ad,dd]&#125;&quot;OK127.0.0.1:6379&gt; get user:liutao&quot;&#123;name:liutao,age:23,likes[ad,dd]&#125;&quot;127.0.0.1:6379&gt; strlen user:liutao(integer) 33127.0.0.1:6379&gt; getrange user:liutao 27 40&quot;d,dd]&#125;&quot;127.0.0.1:6379&gt; append user:liutao &quot;,sex:male&quot;(integer) 42127.0.0.1:6379&gt; get: 根据关键字获取关键字对应的值strlen：获取关键字对应的值的长度getrange：获取关键字对应的值从起始索引到末尾索引的值append： 在关键字对应值末尾添加新的字符串 string类型是Redis最基本的数据类型，一个键最大能存储512MB。 1.2 Hash（哈希）Redis hash 是一个键值对集合Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 for example12345678910127.0.0.1:6379&gt; hmset user name zhangxiao age 23 sex famaleOK127.0.0.1:6379&gt; hgetall user1) &quot;name&quot;2) &quot;zhangxiao&quot;3) &quot;age&quot;4) &quot;23&quot;5) &quot;sex&quot;6) &quot;famale&quot;127.0.0.1:6379&gt; 以上实例中 hash 数据类型存储了包含用户脚本信息的用户对象。 实例中我们使用了 Redis hmset,hgetall 命令，user 为键值。每个 hash 可以存储 232 -1 键值对（40多亿）。 1.3 List(列表)Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。for example123456127.0.0.1:6379&gt; lpush zhangxiao 13 175cm(integer) 4127.0.0.1:6379&gt; lrange zhangxiao 0 11) &quot;175cm&quot;2) &quot;13&quot;127.0.0.1:6379&gt; lpush 向redis集合中存储一系列字符串，使用lrange ［start］［end］ 获取相应的元素值。列表最多可存储 232 1 元素 (4294967295, 每个列表可存储40多亿)。 1.4 Set（集合）Redis的Set是string类型的无序集合。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。for example123456789101112131415127.0.0.1:6379&gt; sadd ages 11(integer) 1127.0.0.1:6379&gt; add ages 12(error) ERR unknown command &apos;add&apos;127.0.0.1:6379&gt; sadd ages 14(integer) 1127.0.0.1:6379&gt; sadd ages 14(integer) 0127.0.0.1:6379&gt; sadd ages 15(integer) 1127.0.0.1:6379&gt; smembers ages1) &quot;11&quot;2) &quot;14&quot;3) &quot;15&quot;127.0.0.1:6379&gt; 可以看到我们为ages集合添加了两次14 ，但是最终set集合中只存在一个14,这是因为set集合中的元素唯一性导致的，第二次插入的元素将被忽略。集合中最大的成员数为 2的32次方 - 1(4294967295, 每个集合可存储40多亿个成员)。 1.5 zset(sorted set：有序集合)Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。for example12345678910127.0.0.1:6379&gt; zadd nums 0 11(integer) 0127.0.0.1:6379&gt; zadd nums 1 12(integer) 1127.0.0.1:6379&gt; zadd nums 2 13(integer) 1127.0.0.1:6379&gt; zrangebyscore nums 0 21) &quot;11&quot;2) &quot;12&quot;3) &quot;13&quot; Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。基本的数据结构就是这些，接下来我会更加详细的来进行记录。]]></content>
  </entry>
</search>
